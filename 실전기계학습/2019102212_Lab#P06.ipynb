{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAwAUStmOtXa",
        "outputId": "403e8831-2e0c-44b9-a09d-ed34ff791b2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_epochs = 80\n",
        "learning_rate = 0.001\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root = '../../data/',\n",
        "                                             train = True,\n",
        "                                             transform = transform,\n",
        "                                             download = True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root = '../../data/',\n",
        "                                            train = False,\n",
        "                                            transform = transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = 100,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = 100,\n",
        "                                          shuffle = False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "  def __init__(self, in_channels, out_channels, stride = 1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.residual_function = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = 1, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "    )\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "\n",
        "    if stride != 1 or in_channels != out_channels:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = stride, bias = False),\n",
        "          nn.BatchNorm2d(out_channels)\n",
        "      )\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.residual_function(x) + self.shortcut(x)\n",
        "    x = self.relu(x)\n",
        "    return x\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes = 10, init_weights = True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels = 64\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "    )\n",
        "\n",
        "    self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "    self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "    self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "    self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    if init_weights:\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "     strides = [stride] + [1] * (num_blocks - 1)\n",
        "     layers = []\n",
        "     for stride in strides:\n",
        "       layers.append(block(self.in_channels, out_channels, stride))\n",
        "       self.in_channels = out_channels * block.expansion\n",
        "\n",
        "     return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x = self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity = 'relu')\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "          nn.init.constant_(m.weight, 1)\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "          nn.init.normal_(m.weight, 0, 0.01)\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def update_lr(optimizer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = lr\n",
        "\n",
        "def train(epoch):\n",
        "  total_step = len(train_loader)\n",
        "  curr_lr = learning_rate\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if(batch_idx + 1) % 100 == 0:\n",
        "      print(\"Epoch [{} / {}], Step [{} / {}], Loss : {:4f}\".format(epoch + 1, num_epochs, batch_idx + 1, total_step, loss.item()))\n",
        "\n",
        "  if(epoch + 1) % 20 == 0:\n",
        "    curr_lr /= 3\n",
        "    update_lr(optimizer, curr_lr)\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  for data, target in test_loader:\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    test_loss += criterion(output, target)\n",
        "    pred = output.data.max(1, keepdim = True)[1]\n",
        "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print('\\nTest Set : Average Loss : {:4f}, Accuracy : {} / {} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BatchNorm (2)\n",
        "\n",
        "#1 - 2 LayerNorm\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes = 10, init_weights = True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels = 64\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n",
        "        nn.LayerNorm([64, 16, 16]),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "    )\n",
        "\n",
        "    self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "    self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "    self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "    self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    if init_weights:\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "     strides = [stride] + [1] * (num_blocks - 1)\n",
        "     layers = []\n",
        "     for stride in strides:\n",
        "       layers.append(block(self.in_channels, out_channels, stride))\n",
        "       self.in_channels = out_channels * block.expansion\n",
        "\n",
        "     return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x = self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity = 'relu')\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "          nn.init.constant_(m.weight, 1)\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "          nn.init.normal_(m.weight, 0, 0.01)\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "\n",
        "model = ResNet(BasicBlock, [2, 2, 2, 2]).cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range (0, num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5t17g4s8q1E",
        "outputId": "d1e2da20-d715-490d-fed2-28ea904fe7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 80], Step [100 / 500], Loss : 1.868051\n",
            "Epoch [1 / 80], Step [200 / 500], Loss : 1.614345\n",
            "Epoch [1 / 80], Step [300 / 500], Loss : 1.587963\n",
            "Epoch [1 / 80], Step [400 / 500], Loss : 1.281564\n",
            "Epoch [1 / 80], Step [500 / 500], Loss : 1.320653\n",
            "\n",
            "Test Set : Average Loss : 0.026877, Accuracy : 2803 / 10000 (28%)\n",
            "\n",
            "Epoch [2 / 80], Step [100 / 500], Loss : 1.396630\n",
            "Epoch [2 / 80], Step [200 / 500], Loss : 1.278137\n",
            "Epoch [2 / 80], Step [300 / 500], Loss : 1.228327\n",
            "Epoch [2 / 80], Step [400 / 500], Loss : 1.206281\n",
            "Epoch [2 / 80], Step [500 / 500], Loss : 1.110727\n",
            "\n",
            "Test Set : Average Loss : 0.014288, Accuracy : 5294 / 10000 (53%)\n",
            "\n",
            "Epoch [3 / 80], Step [100 / 500], Loss : 1.089255\n",
            "Epoch [3 / 80], Step [200 / 500], Loss : 1.119950\n",
            "Epoch [3 / 80], Step [300 / 500], Loss : 0.953267\n",
            "Epoch [3 / 80], Step [400 / 500], Loss : 0.967906\n",
            "Epoch [3 / 80], Step [500 / 500], Loss : 0.964563\n",
            "\n",
            "Test Set : Average Loss : 0.012624, Accuracy : 5592 / 10000 (56%)\n",
            "\n",
            "Epoch [4 / 80], Step [100 / 500], Loss : 0.990112\n",
            "Epoch [4 / 80], Step [200 / 500], Loss : 0.924680\n",
            "Epoch [4 / 80], Step [300 / 500], Loss : 0.886987\n",
            "Epoch [4 / 80], Step [400 / 500], Loss : 0.761072\n",
            "Epoch [4 / 80], Step [500 / 500], Loss : 0.904701\n",
            "\n",
            "Test Set : Average Loss : 0.012546, Accuracy : 5758 / 10000 (58%)\n",
            "\n",
            "Epoch [5 / 80], Step [100 / 500], Loss : 0.749512\n",
            "Epoch [5 / 80], Step [200 / 500], Loss : 0.937804\n",
            "Epoch [5 / 80], Step [300 / 500], Loss : 0.893380\n",
            "Epoch [5 / 80], Step [400 / 500], Loss : 1.013878\n",
            "Epoch [5 / 80], Step [500 / 500], Loss : 0.997294\n",
            "\n",
            "Test Set : Average Loss : 0.012227, Accuracy : 6080 / 10000 (61%)\n",
            "\n",
            "Epoch [6 / 80], Step [100 / 500], Loss : 0.811485\n",
            "Epoch [6 / 80], Step [200 / 500], Loss : 1.060711\n",
            "Epoch [6 / 80], Step [300 / 500], Loss : 1.002850\n",
            "Epoch [6 / 80], Step [400 / 500], Loss : 0.937627\n",
            "Epoch [6 / 80], Step [500 / 500], Loss : 0.660133\n",
            "\n",
            "Test Set : Average Loss : 0.019088, Accuracy : 4693 / 10000 (47%)\n",
            "\n",
            "Epoch [7 / 80], Step [100 / 500], Loss : 0.591312\n",
            "Epoch [7 / 80], Step [200 / 500], Loss : 0.720507\n",
            "Epoch [7 / 80], Step [300 / 500], Loss : 0.792301\n",
            "Epoch [7 / 80], Step [400 / 500], Loss : 1.048099\n",
            "Epoch [7 / 80], Step [500 / 500], Loss : 0.756342\n",
            "\n",
            "Test Set : Average Loss : 0.008521, Accuracy : 7042 / 10000 (70%)\n",
            "\n",
            "Epoch [8 / 80], Step [100 / 500], Loss : 0.663096\n",
            "Epoch [8 / 80], Step [200 / 500], Loss : 0.696602\n",
            "Epoch [8 / 80], Step [300 / 500], Loss : 0.764516\n",
            "Epoch [8 / 80], Step [400 / 500], Loss : 0.546916\n",
            "Epoch [8 / 80], Step [500 / 500], Loss : 0.679918\n",
            "\n",
            "Test Set : Average Loss : 0.007978, Accuracy : 7230 / 10000 (72%)\n",
            "\n",
            "Epoch [9 / 80], Step [100 / 500], Loss : 0.791132\n",
            "Epoch [9 / 80], Step [200 / 500], Loss : 0.691594\n",
            "Epoch [9 / 80], Step [300 / 500], Loss : 0.597869\n",
            "Epoch [9 / 80], Step [400 / 500], Loss : 0.613589\n",
            "Epoch [9 / 80], Step [500 / 500], Loss : 0.567725\n",
            "\n",
            "Test Set : Average Loss : 0.008210, Accuracy : 7105 / 10000 (71%)\n",
            "\n",
            "Epoch [10 / 80], Step [100 / 500], Loss : 0.723657\n",
            "Epoch [10 / 80], Step [200 / 500], Loss : 0.640758\n",
            "Epoch [10 / 80], Step [300 / 500], Loss : 0.571305\n",
            "Epoch [10 / 80], Step [400 / 500], Loss : 0.724123\n",
            "Epoch [10 / 80], Step [500 / 500], Loss : 0.524722\n",
            "\n",
            "Test Set : Average Loss : 0.009851, Accuracy : 6718 / 10000 (67%)\n",
            "\n",
            "Epoch [11 / 80], Step [100 / 500], Loss : 0.636121\n",
            "Epoch [11 / 80], Step [200 / 500], Loss : 0.696953\n",
            "Epoch [11 / 80], Step [300 / 500], Loss : 0.609101\n",
            "Epoch [11 / 80], Step [400 / 500], Loss : 0.673909\n",
            "Epoch [11 / 80], Step [500 / 500], Loss : 0.727760\n",
            "\n",
            "Test Set : Average Loss : 0.007687, Accuracy : 7304 / 10000 (73%)\n",
            "\n",
            "Epoch [12 / 80], Step [100 / 500], Loss : 0.710531\n",
            "Epoch [12 / 80], Step [200 / 500], Loss : 0.526260\n",
            "Epoch [12 / 80], Step [300 / 500], Loss : 0.714871\n",
            "Epoch [12 / 80], Step [400 / 500], Loss : 0.608871\n",
            "Epoch [12 / 80], Step [500 / 500], Loss : 0.816488\n",
            "\n",
            "Test Set : Average Loss : 0.008114, Accuracy : 7403 / 10000 (74%)\n",
            "\n",
            "Epoch [13 / 80], Step [100 / 500], Loss : 0.577482\n",
            "Epoch [13 / 80], Step [200 / 500], Loss : 0.708638\n",
            "Epoch [13 / 80], Step [300 / 500], Loss : 0.732417\n",
            "Epoch [13 / 80], Step [400 / 500], Loss : 0.504949\n",
            "Epoch [13 / 80], Step [500 / 500], Loss : 0.535716\n",
            "\n",
            "Test Set : Average Loss : 0.008737, Accuracy : 7036 / 10000 (70%)\n",
            "\n",
            "Epoch [14 / 80], Step [100 / 500], Loss : 0.603917\n",
            "Epoch [14 / 80], Step [200 / 500], Loss : 0.548679\n",
            "Epoch [14 / 80], Step [300 / 500], Loss : 0.696036\n",
            "Epoch [14 / 80], Step [400 / 500], Loss : 0.502865\n",
            "Epoch [14 / 80], Step [500 / 500], Loss : 0.699861\n",
            "\n",
            "Test Set : Average Loss : 0.006552, Accuracy : 7757 / 10000 (78%)\n",
            "\n",
            "Epoch [15 / 80], Step [100 / 500], Loss : 0.395961\n",
            "Epoch [15 / 80], Step [200 / 500], Loss : 0.455182\n",
            "Epoch [15 / 80], Step [300 / 500], Loss : 0.653521\n",
            "Epoch [15 / 80], Step [400 / 500], Loss : 0.706912\n",
            "Epoch [15 / 80], Step [500 / 500], Loss : 0.554670\n",
            "\n",
            "Test Set : Average Loss : 0.008147, Accuracy : 7339 / 10000 (73%)\n",
            "\n",
            "Epoch [16 / 80], Step [100 / 500], Loss : 0.581992\n",
            "Epoch [16 / 80], Step [200 / 500], Loss : 0.494722\n",
            "Epoch [16 / 80], Step [300 / 500], Loss : 0.417375\n",
            "Epoch [16 / 80], Step [400 / 500], Loss : 0.536636\n",
            "Epoch [16 / 80], Step [500 / 500], Loss : 0.512858\n",
            "\n",
            "Test Set : Average Loss : 0.007114, Accuracy : 7653 / 10000 (77%)\n",
            "\n",
            "Epoch [17 / 80], Step [100 / 500], Loss : 0.343586\n",
            "Epoch [17 / 80], Step [200 / 500], Loss : 0.617366\n",
            "Epoch [17 / 80], Step [300 / 500], Loss : 0.490533\n",
            "Epoch [17 / 80], Step [400 / 500], Loss : 0.471536\n",
            "Epoch [17 / 80], Step [500 / 500], Loss : 0.644333\n",
            "\n",
            "Test Set : Average Loss : 0.008402, Accuracy : 7247 / 10000 (72%)\n",
            "\n",
            "Epoch [18 / 80], Step [100 / 500], Loss : 0.544967\n",
            "Epoch [18 / 80], Step [200 / 500], Loss : 0.549471\n",
            "Epoch [18 / 80], Step [300 / 500], Loss : 0.551849\n",
            "Epoch [18 / 80], Step [400 / 500], Loss : 0.558516\n",
            "Epoch [18 / 80], Step [500 / 500], Loss : 0.405779\n",
            "\n",
            "Test Set : Average Loss : 0.009340, Accuracy : 7036 / 10000 (70%)\n",
            "\n",
            "Epoch [19 / 80], Step [100 / 500], Loss : 0.466990\n",
            "Epoch [19 / 80], Step [200 / 500], Loss : 0.606851\n",
            "Epoch [19 / 80], Step [300 / 500], Loss : 0.382106\n",
            "Epoch [19 / 80], Step [400 / 500], Loss : 0.581713\n",
            "Epoch [19 / 80], Step [500 / 500], Loss : 0.429340\n",
            "\n",
            "Test Set : Average Loss : 0.007040, Accuracy : 7716 / 10000 (77%)\n",
            "\n",
            "Epoch [20 / 80], Step [100 / 500], Loss : 0.447660\n",
            "Epoch [20 / 80], Step [200 / 500], Loss : 0.416531\n",
            "Epoch [20 / 80], Step [300 / 500], Loss : 0.417507\n",
            "Epoch [20 / 80], Step [400 / 500], Loss : 0.433766\n",
            "Epoch [20 / 80], Step [500 / 500], Loss : 0.572692\n",
            "\n",
            "Test Set : Average Loss : 0.005976, Accuracy : 8015 / 10000 (80%)\n",
            "\n",
            "Epoch [21 / 80], Step [100 / 500], Loss : 0.371129\n",
            "Epoch [21 / 80], Step [200 / 500], Loss : 0.331338\n",
            "Epoch [21 / 80], Step [300 / 500], Loss : 0.431066\n",
            "Epoch [21 / 80], Step [400 / 500], Loss : 0.284722\n",
            "Epoch [21 / 80], Step [500 / 500], Loss : 0.405179\n",
            "\n",
            "Test Set : Average Loss : 0.005187, Accuracy : 8303 / 10000 (83%)\n",
            "\n",
            "Epoch [22 / 80], Step [100 / 500], Loss : 0.373734\n",
            "Epoch [22 / 80], Step [200 / 500], Loss : 0.375501\n",
            "Epoch [22 / 80], Step [300 / 500], Loss : 0.415635\n",
            "Epoch [22 / 80], Step [400 / 500], Loss : 0.357765\n",
            "Epoch [22 / 80], Step [500 / 500], Loss : 0.274587\n",
            "\n",
            "Test Set : Average Loss : 0.005125, Accuracy : 8343 / 10000 (83%)\n",
            "\n",
            "Epoch [23 / 80], Step [100 / 500], Loss : 0.337364\n",
            "Epoch [23 / 80], Step [200 / 500], Loss : 0.276100\n",
            "Epoch [23 / 80], Step [300 / 500], Loss : 0.361893\n",
            "Epoch [23 / 80], Step [400 / 500], Loss : 0.329917\n",
            "Epoch [23 / 80], Step [500 / 500], Loss : 0.374618\n",
            "\n",
            "Test Set : Average Loss : 0.004919, Accuracy : 8404 / 10000 (84%)\n",
            "\n",
            "Epoch [24 / 80], Step [100 / 500], Loss : 0.323587\n",
            "Epoch [24 / 80], Step [200 / 500], Loss : 0.280138\n",
            "Epoch [24 / 80], Step [300 / 500], Loss : 0.290374\n",
            "Epoch [24 / 80], Step [400 / 500], Loss : 0.227170\n",
            "Epoch [24 / 80], Step [500 / 500], Loss : 0.454963\n",
            "\n",
            "Test Set : Average Loss : 0.005365, Accuracy : 8263 / 10000 (83%)\n",
            "\n",
            "Epoch [25 / 80], Step [100 / 500], Loss : 0.204668\n",
            "Epoch [25 / 80], Step [200 / 500], Loss : 0.350090\n",
            "Epoch [25 / 80], Step [300 / 500], Loss : 0.342376\n",
            "Epoch [25 / 80], Step [400 / 500], Loss : 0.404498\n",
            "Epoch [25 / 80], Step [500 / 500], Loss : 0.325999\n",
            "\n",
            "Test Set : Average Loss : 0.005403, Accuracy : 8258 / 10000 (83%)\n",
            "\n",
            "Epoch [26 / 80], Step [100 / 500], Loss : 0.266281\n",
            "Epoch [26 / 80], Step [200 / 500], Loss : 0.269178\n",
            "Epoch [26 / 80], Step [300 / 500], Loss : 0.346133\n",
            "Epoch [26 / 80], Step [400 / 500], Loss : 0.343109\n",
            "Epoch [26 / 80], Step [500 / 500], Loss : 0.163011\n",
            "\n",
            "Test Set : Average Loss : 0.005143, Accuracy : 8374 / 10000 (84%)\n",
            "\n",
            "Epoch [27 / 80], Step [100 / 500], Loss : 0.197477\n",
            "Epoch [27 / 80], Step [200 / 500], Loss : 0.332106\n",
            "Epoch [27 / 80], Step [300 / 500], Loss : 0.203071\n",
            "Epoch [27 / 80], Step [400 / 500], Loss : 0.268825\n",
            "Epoch [27 / 80], Step [500 / 500], Loss : 0.208068\n",
            "\n",
            "Test Set : Average Loss : 0.005167, Accuracy : 8349 / 10000 (83%)\n",
            "\n",
            "Epoch [28 / 80], Step [100 / 500], Loss : 0.366406\n",
            "Epoch [28 / 80], Step [200 / 500], Loss : 0.227650\n",
            "Epoch [28 / 80], Step [300 / 500], Loss : 0.254446\n",
            "Epoch [28 / 80], Step [400 / 500], Loss : 0.260198\n",
            "Epoch [28 / 80], Step [500 / 500], Loss : 0.322725\n",
            "\n",
            "Test Set : Average Loss : 0.005691, Accuracy : 8199 / 10000 (82%)\n",
            "\n",
            "Epoch [29 / 80], Step [100 / 500], Loss : 0.537030\n",
            "Epoch [29 / 80], Step [200 / 500], Loss : 0.279416\n",
            "Epoch [29 / 80], Step [300 / 500], Loss : 0.281597\n",
            "Epoch [29 / 80], Step [400 / 500], Loss : 0.371130\n",
            "Epoch [29 / 80], Step [500 / 500], Loss : 0.409682\n",
            "\n",
            "Test Set : Average Loss : 0.005211, Accuracy : 8374 / 10000 (84%)\n",
            "\n",
            "Epoch [30 / 80], Step [100 / 500], Loss : 0.266095\n",
            "Epoch [30 / 80], Step [200 / 500], Loss : 0.354952\n",
            "Epoch [30 / 80], Step [300 / 500], Loss : 0.278803\n",
            "Epoch [30 / 80], Step [400 / 500], Loss : 0.335110\n",
            "Epoch [30 / 80], Step [500 / 500], Loss : 0.226154\n",
            "\n",
            "Test Set : Average Loss : 0.005419, Accuracy : 8332 / 10000 (83%)\n",
            "\n",
            "Epoch [31 / 80], Step [100 / 500], Loss : 0.221504\n",
            "Epoch [31 / 80], Step [200 / 500], Loss : 0.282181\n",
            "Epoch [31 / 80], Step [300 / 500], Loss : 0.287437\n",
            "Epoch [31 / 80], Step [400 / 500], Loss : 0.417619\n",
            "Epoch [31 / 80], Step [500 / 500], Loss : 0.341926\n",
            "\n",
            "Test Set : Average Loss : 0.005201, Accuracy : 8403 / 10000 (84%)\n",
            "\n",
            "Epoch [32 / 80], Step [100 / 500], Loss : 0.256835\n",
            "Epoch [32 / 80], Step [200 / 500], Loss : 0.203115\n",
            "Epoch [32 / 80], Step [300 / 500], Loss : 0.302347\n",
            "Epoch [32 / 80], Step [400 / 500], Loss : 0.349804\n",
            "Epoch [32 / 80], Step [500 / 500], Loss : 0.285433\n",
            "\n",
            "Test Set : Average Loss : 0.005250, Accuracy : 8336 / 10000 (83%)\n",
            "\n",
            "Epoch [33 / 80], Step [100 / 500], Loss : 0.336674\n",
            "Epoch [33 / 80], Step [200 / 500], Loss : 0.359371\n",
            "Epoch [33 / 80], Step [300 / 500], Loss : 0.275378\n",
            "Epoch [33 / 80], Step [400 / 500], Loss : 0.237841\n",
            "Epoch [33 / 80], Step [500 / 500], Loss : 0.182463\n",
            "\n",
            "Test Set : Average Loss : 0.005734, Accuracy : 8265 / 10000 (83%)\n",
            "\n",
            "Epoch [34 / 80], Step [100 / 500], Loss : 0.268165\n",
            "Epoch [34 / 80], Step [200 / 500], Loss : 0.221967\n",
            "Epoch [34 / 80], Step [300 / 500], Loss : 0.288587\n",
            "Epoch [34 / 80], Step [400 / 500], Loss : 0.367219\n",
            "Epoch [34 / 80], Step [500 / 500], Loss : 0.196686\n",
            "\n",
            "Test Set : Average Loss : 0.005371, Accuracy : 8341 / 10000 (83%)\n",
            "\n",
            "Epoch [35 / 80], Step [100 / 500], Loss : 0.210831\n",
            "Epoch [35 / 80], Step [200 / 500], Loss : 0.268811\n",
            "Epoch [35 / 80], Step [300 / 500], Loss : 0.329115\n",
            "Epoch [35 / 80], Step [400 / 500], Loss : 0.158493\n",
            "Epoch [35 / 80], Step [500 / 500], Loss : 0.323490\n",
            "\n",
            "Test Set : Average Loss : 0.005601, Accuracy : 8350 / 10000 (84%)\n",
            "\n",
            "Epoch [36 / 80], Step [100 / 500], Loss : 0.233181\n",
            "Epoch [36 / 80], Step [200 / 500], Loss : 0.287198\n",
            "Epoch [36 / 80], Step [300 / 500], Loss : 0.236495\n",
            "Epoch [36 / 80], Step [400 / 500], Loss : 0.167684\n",
            "Epoch [36 / 80], Step [500 / 500], Loss : 0.348884\n",
            "\n",
            "Test Set : Average Loss : 0.005433, Accuracy : 8443 / 10000 (84%)\n",
            "\n",
            "Epoch [37 / 80], Step [100 / 500], Loss : 0.298795\n",
            "Epoch [37 / 80], Step [200 / 500], Loss : 0.345643\n",
            "Epoch [37 / 80], Step [300 / 500], Loss : 0.298362\n",
            "Epoch [37 / 80], Step [400 / 500], Loss : 0.334685\n",
            "Epoch [37 / 80], Step [500 / 500], Loss : 0.211528\n",
            "\n",
            "Test Set : Average Loss : 0.005405, Accuracy : 8399 / 10000 (84%)\n",
            "\n",
            "Epoch [38 / 80], Step [100 / 500], Loss : 0.331650\n",
            "Epoch [38 / 80], Step [200 / 500], Loss : 0.268051\n",
            "Epoch [38 / 80], Step [300 / 500], Loss : 0.220536\n",
            "Epoch [38 / 80], Step [400 / 500], Loss : 0.188111\n",
            "Epoch [38 / 80], Step [500 / 500], Loss : 0.323474\n",
            "\n",
            "Test Set : Average Loss : 0.005957, Accuracy : 8303 / 10000 (83%)\n",
            "\n",
            "Epoch [39 / 80], Step [100 / 500], Loss : 0.164510\n",
            "Epoch [39 / 80], Step [200 / 500], Loss : 0.271135\n",
            "Epoch [39 / 80], Step [300 / 500], Loss : 0.177038\n",
            "Epoch [39 / 80], Step [400 / 500], Loss : 0.275044\n",
            "Epoch [39 / 80], Step [500 / 500], Loss : 0.217093\n",
            "\n",
            "Test Set : Average Loss : 0.006006, Accuracy : 8261 / 10000 (83%)\n",
            "\n",
            "Epoch [40 / 80], Step [100 / 500], Loss : 0.131630\n",
            "Epoch [40 / 80], Step [200 / 500], Loss : 0.217003\n",
            "Epoch [40 / 80], Step [300 / 500], Loss : 0.090877\n",
            "Epoch [40 / 80], Step [400 / 500], Loss : 0.173250\n",
            "Epoch [40 / 80], Step [500 / 500], Loss : 0.175097\n",
            "\n",
            "Test Set : Average Loss : 0.005603, Accuracy : 8373 / 10000 (84%)\n",
            "\n",
            "Epoch [41 / 80], Step [100 / 500], Loss : 0.196657\n",
            "Epoch [41 / 80], Step [200 / 500], Loss : 0.137054\n",
            "Epoch [41 / 80], Step [300 / 500], Loss : 0.243930\n",
            "Epoch [41 / 80], Step [400 / 500], Loss : 0.247716\n",
            "Epoch [41 / 80], Step [500 / 500], Loss : 0.286341\n",
            "\n",
            "Test Set : Average Loss : 0.005872, Accuracy : 8366 / 10000 (84%)\n",
            "\n",
            "Epoch [42 / 80], Step [100 / 500], Loss : 0.276028\n",
            "Epoch [42 / 80], Step [200 / 500], Loss : 0.265392\n",
            "Epoch [42 / 80], Step [300 / 500], Loss : 0.151210\n",
            "Epoch [42 / 80], Step [400 / 500], Loss : 0.203515\n",
            "Epoch [42 / 80], Step [500 / 500], Loss : 0.158163\n",
            "\n",
            "Test Set : Average Loss : 0.005987, Accuracy : 8369 / 10000 (84%)\n",
            "\n",
            "Epoch [43 / 80], Step [100 / 500], Loss : 0.208340\n",
            "Epoch [43 / 80], Step [200 / 500], Loss : 0.201914\n",
            "Epoch [43 / 80], Step [300 / 500], Loss : 0.111576\n",
            "Epoch [43 / 80], Step [400 / 500], Loss : 0.194465\n",
            "Epoch [43 / 80], Step [500 / 500], Loss : 0.209689\n",
            "\n",
            "Test Set : Average Loss : 0.006240, Accuracy : 8298 / 10000 (83%)\n",
            "\n",
            "Epoch [44 / 80], Step [100 / 500], Loss : 0.132621\n",
            "Epoch [44 / 80], Step [200 / 500], Loss : 0.244729\n",
            "Epoch [44 / 80], Step [300 / 500], Loss : 0.158672\n",
            "Epoch [44 / 80], Step [400 / 500], Loss : 0.284788\n",
            "Epoch [44 / 80], Step [500 / 500], Loss : 0.235573\n",
            "\n",
            "Test Set : Average Loss : 0.005717, Accuracy : 8386 / 10000 (84%)\n",
            "\n",
            "Epoch [45 / 80], Step [100 / 500], Loss : 0.207433\n",
            "Epoch [45 / 80], Step [200 / 500], Loss : 0.211367\n",
            "Epoch [45 / 80], Step [300 / 500], Loss : 0.370201\n",
            "Epoch [45 / 80], Step [400 / 500], Loss : 0.236109\n",
            "Epoch [45 / 80], Step [500 / 500], Loss : 0.150288\n",
            "\n",
            "Test Set : Average Loss : 0.005676, Accuracy : 8410 / 10000 (84%)\n",
            "\n",
            "Epoch [46 / 80], Step [100 / 500], Loss : 0.182091\n",
            "Epoch [46 / 80], Step [200 / 500], Loss : 0.119282\n",
            "Epoch [46 / 80], Step [300 / 500], Loss : 0.166015\n",
            "Epoch [46 / 80], Step [400 / 500], Loss : 0.130230\n",
            "Epoch [46 / 80], Step [500 / 500], Loss : 0.242771\n",
            "\n",
            "Test Set : Average Loss : 0.006741, Accuracy : 8271 / 10000 (83%)\n",
            "\n",
            "Epoch [47 / 80], Step [100 / 500], Loss : 0.161424\n",
            "Epoch [47 / 80], Step [200 / 500], Loss : 0.230554\n",
            "Epoch [47 / 80], Step [300 / 500], Loss : 0.226778\n",
            "Epoch [47 / 80], Step [400 / 500], Loss : 0.201545\n",
            "Epoch [47 / 80], Step [500 / 500], Loss : 0.235368\n",
            "\n",
            "Test Set : Average Loss : 0.006085, Accuracy : 8343 / 10000 (83%)\n",
            "\n",
            "Epoch [48 / 80], Step [100 / 500], Loss : 0.212731\n",
            "Epoch [48 / 80], Step [200 / 500], Loss : 0.106922\n",
            "Epoch [48 / 80], Step [300 / 500], Loss : 0.245811\n",
            "Epoch [48 / 80], Step [400 / 500], Loss : 0.161977\n",
            "Epoch [48 / 80], Step [500 / 500], Loss : 0.232594\n",
            "\n",
            "Test Set : Average Loss : 0.006057, Accuracy : 8352 / 10000 (84%)\n",
            "\n",
            "Epoch [49 / 80], Step [100 / 500], Loss : 0.083596\n",
            "Epoch [49 / 80], Step [200 / 500], Loss : 0.231473\n",
            "Epoch [49 / 80], Step [300 / 500], Loss : 0.230213\n",
            "Epoch [49 / 80], Step [400 / 500], Loss : 0.184961\n",
            "Epoch [49 / 80], Step [500 / 500], Loss : 0.131851\n",
            "\n",
            "Test Set : Average Loss : 0.005768, Accuracy : 8431 / 10000 (84%)\n",
            "\n",
            "Epoch [50 / 80], Step [100 / 500], Loss : 0.148947\n",
            "Epoch [50 / 80], Step [200 / 500], Loss : 0.310381\n",
            "Epoch [50 / 80], Step [300 / 500], Loss : 0.134005\n",
            "Epoch [50 / 80], Step [400 / 500], Loss : 0.191977\n",
            "Epoch [50 / 80], Step [500 / 500], Loss : 0.213624\n",
            "\n",
            "Test Set : Average Loss : 0.005793, Accuracy : 8424 / 10000 (84%)\n",
            "\n",
            "Epoch [51 / 80], Step [100 / 500], Loss : 0.231878\n",
            "Epoch [51 / 80], Step [200 / 500], Loss : 0.235342\n",
            "Epoch [51 / 80], Step [300 / 500], Loss : 0.130332\n",
            "Epoch [51 / 80], Step [400 / 500], Loss : 0.300311\n",
            "Epoch [51 / 80], Step [500 / 500], Loss : 0.171995\n",
            "\n",
            "Test Set : Average Loss : 0.006472, Accuracy : 8259 / 10000 (83%)\n",
            "\n",
            "Epoch [52 / 80], Step [100 / 500], Loss : 0.147468\n",
            "Epoch [52 / 80], Step [200 / 500], Loss : 0.161013\n",
            "Epoch [52 / 80], Step [300 / 500], Loss : 0.112390\n",
            "Epoch [52 / 80], Step [400 / 500], Loss : 0.261401\n",
            "Epoch [52 / 80], Step [500 / 500], Loss : 0.182107\n",
            "\n",
            "Test Set : Average Loss : 0.005997, Accuracy : 8402 / 10000 (84%)\n",
            "\n",
            "Epoch [53 / 80], Step [100 / 500], Loss : 0.119190\n",
            "Epoch [53 / 80], Step [200 / 500], Loss : 0.171408\n",
            "Epoch [53 / 80], Step [300 / 500], Loss : 0.232795\n",
            "Epoch [53 / 80], Step [400 / 500], Loss : 0.283491\n",
            "Epoch [53 / 80], Step [500 / 500], Loss : 0.249983\n",
            "\n",
            "Test Set : Average Loss : 0.006289, Accuracy : 8354 / 10000 (84%)\n",
            "\n",
            "Epoch [54 / 80], Step [100 / 500], Loss : 0.194586\n",
            "Epoch [54 / 80], Step [200 / 500], Loss : 0.195322\n",
            "Epoch [54 / 80], Step [300 / 500], Loss : 0.145890\n",
            "Epoch [54 / 80], Step [400 / 500], Loss : 0.131174\n",
            "Epoch [54 / 80], Step [500 / 500], Loss : 0.221365\n",
            "\n",
            "Test Set : Average Loss : 0.006090, Accuracy : 8437 / 10000 (84%)\n",
            "\n",
            "Epoch [55 / 80], Step [100 / 500], Loss : 0.178099\n",
            "Epoch [55 / 80], Step [200 / 500], Loss : 0.169539\n",
            "Epoch [55 / 80], Step [300 / 500], Loss : 0.135273\n",
            "Epoch [55 / 80], Step [400 / 500], Loss : 0.188231\n",
            "Epoch [55 / 80], Step [500 / 500], Loss : 0.120661\n",
            "\n",
            "Test Set : Average Loss : 0.006047, Accuracy : 8413 / 10000 (84%)\n",
            "\n",
            "Epoch [56 / 80], Step [100 / 500], Loss : 0.098721\n",
            "Epoch [56 / 80], Step [200 / 500], Loss : 0.133037\n",
            "Epoch [56 / 80], Step [300 / 500], Loss : 0.197000\n",
            "Epoch [56 / 80], Step [400 / 500], Loss : 0.168341\n",
            "Epoch [56 / 80], Step [500 / 500], Loss : 0.155979\n",
            "\n",
            "Test Set : Average Loss : 0.006499, Accuracy : 8396 / 10000 (84%)\n",
            "\n",
            "Epoch [57 / 80], Step [100 / 500], Loss : 0.188865\n",
            "Epoch [57 / 80], Step [200 / 500], Loss : 0.194906\n",
            "Epoch [57 / 80], Step [300 / 500], Loss : 0.235737\n",
            "Epoch [57 / 80], Step [400 / 500], Loss : 0.213056\n",
            "Epoch [57 / 80], Step [500 / 500], Loss : 0.060292\n",
            "\n",
            "Test Set : Average Loss : 0.006647, Accuracy : 8366 / 10000 (84%)\n",
            "\n",
            "Epoch [58 / 80], Step [100 / 500], Loss : 0.299624\n",
            "Epoch [58 / 80], Step [200 / 500], Loss : 0.111932\n",
            "Epoch [58 / 80], Step [300 / 500], Loss : 0.070077\n",
            "Epoch [58 / 80], Step [400 / 500], Loss : 0.218941\n",
            "Epoch [58 / 80], Step [500 / 500], Loss : 0.148569\n",
            "\n",
            "Test Set : Average Loss : 0.006866, Accuracy : 8305 / 10000 (83%)\n",
            "\n",
            "Epoch [59 / 80], Step [100 / 500], Loss : 0.170330\n",
            "Epoch [59 / 80], Step [200 / 500], Loss : 0.237609\n",
            "Epoch [59 / 80], Step [300 / 500], Loss : 0.107590\n",
            "Epoch [59 / 80], Step [400 / 500], Loss : 0.066468\n",
            "Epoch [59 / 80], Step [500 / 500], Loss : 0.226261\n",
            "\n",
            "Test Set : Average Loss : 0.006638, Accuracy : 8359 / 10000 (84%)\n",
            "\n",
            "Epoch [60 / 80], Step [100 / 500], Loss : 0.087405\n",
            "Epoch [60 / 80], Step [200 / 500], Loss : 0.084217\n",
            "Epoch [60 / 80], Step [300 / 500], Loss : 0.119664\n",
            "Epoch [60 / 80], Step [400 / 500], Loss : 0.130804\n",
            "Epoch [60 / 80], Step [500 / 500], Loss : 0.129557\n",
            "\n",
            "Test Set : Average Loss : 0.006553, Accuracy : 8418 / 10000 (84%)\n",
            "\n",
            "Epoch [61 / 80], Step [100 / 500], Loss : 0.120124\n",
            "Epoch [61 / 80], Step [200 / 500], Loss : 0.128129\n",
            "Epoch [61 / 80], Step [300 / 500], Loss : 0.161954\n",
            "Epoch [61 / 80], Step [400 / 500], Loss : 0.143767\n",
            "Epoch [61 / 80], Step [500 / 500], Loss : 0.228735\n",
            "\n",
            "Test Set : Average Loss : 0.006507, Accuracy : 8378 / 10000 (84%)\n",
            "\n",
            "Epoch [62 / 80], Step [100 / 500], Loss : 0.144663\n",
            "Epoch [62 / 80], Step [200 / 500], Loss : 0.089538\n",
            "Epoch [62 / 80], Step [300 / 500], Loss : 0.197264\n",
            "Epoch [62 / 80], Step [400 / 500], Loss : 0.192272\n",
            "Epoch [62 / 80], Step [500 / 500], Loss : 0.134481\n",
            "\n",
            "Test Set : Average Loss : 0.006492, Accuracy : 8452 / 10000 (85%)\n",
            "\n",
            "Epoch [63 / 80], Step [100 / 500], Loss : 0.167279\n",
            "Epoch [63 / 80], Step [200 / 500], Loss : 0.198586\n",
            "Epoch [63 / 80], Step [300 / 500], Loss : 0.105555\n",
            "Epoch [63 / 80], Step [400 / 500], Loss : 0.126079\n",
            "Epoch [63 / 80], Step [500 / 500], Loss : 0.247792\n",
            "\n",
            "Test Set : Average Loss : 0.006703, Accuracy : 8366 / 10000 (84%)\n",
            "\n",
            "Epoch [64 / 80], Step [100 / 500], Loss : 0.208547\n",
            "Epoch [64 / 80], Step [200 / 500], Loss : 0.202601\n",
            "Epoch [64 / 80], Step [300 / 500], Loss : 0.223398\n",
            "Epoch [64 / 80], Step [400 / 500], Loss : 0.065421\n",
            "Epoch [64 / 80], Step [500 / 500], Loss : 0.182661\n",
            "\n",
            "Test Set : Average Loss : 0.006991, Accuracy : 8372 / 10000 (84%)\n",
            "\n",
            "Epoch [65 / 80], Step [100 / 500], Loss : 0.094154\n",
            "Epoch [65 / 80], Step [200 / 500], Loss : 0.157388\n",
            "Epoch [65 / 80], Step [300 / 500], Loss : 0.083511\n",
            "Epoch [65 / 80], Step [400 / 500], Loss : 0.151472\n",
            "Epoch [65 / 80], Step [500 / 500], Loss : 0.208059\n",
            "\n",
            "Test Set : Average Loss : 0.007412, Accuracy : 8304 / 10000 (83%)\n",
            "\n",
            "Epoch [66 / 80], Step [100 / 500], Loss : 0.103498\n",
            "Epoch [66 / 80], Step [200 / 500], Loss : 0.097857\n",
            "Epoch [66 / 80], Step [300 / 500], Loss : 0.075804\n",
            "Epoch [66 / 80], Step [400 / 500], Loss : 0.127280\n",
            "Epoch [66 / 80], Step [500 / 500], Loss : 0.320388\n",
            "\n",
            "Test Set : Average Loss : 0.006481, Accuracy : 8433 / 10000 (84%)\n",
            "\n",
            "Epoch [67 / 80], Step [100 / 500], Loss : 0.147399\n",
            "Epoch [67 / 80], Step [200 / 500], Loss : 0.107154\n",
            "Epoch [67 / 80], Step [300 / 500], Loss : 0.196490\n",
            "Epoch [67 / 80], Step [400 / 500], Loss : 0.126022\n",
            "Epoch [67 / 80], Step [500 / 500], Loss : 0.109030\n",
            "\n",
            "Test Set : Average Loss : 0.007192, Accuracy : 8346 / 10000 (83%)\n",
            "\n",
            "Epoch [68 / 80], Step [100 / 500], Loss : 0.096257\n",
            "Epoch [68 / 80], Step [200 / 500], Loss : 0.188994\n",
            "Epoch [68 / 80], Step [300 / 500], Loss : 0.085994\n",
            "Epoch [68 / 80], Step [400 / 500], Loss : 0.210523\n",
            "Epoch [68 / 80], Step [500 / 500], Loss : 0.118974\n",
            "\n",
            "Test Set : Average Loss : 0.006550, Accuracy : 8397 / 10000 (84%)\n",
            "\n",
            "Epoch [69 / 80], Step [100 / 500], Loss : 0.152227\n",
            "Epoch [69 / 80], Step [200 / 500], Loss : 0.157295\n",
            "Epoch [69 / 80], Step [300 / 500], Loss : 0.185613\n",
            "Epoch [69 / 80], Step [400 / 500], Loss : 0.101563\n",
            "Epoch [69 / 80], Step [500 / 500], Loss : 0.234043\n",
            "\n",
            "Test Set : Average Loss : 0.007155, Accuracy : 8356 / 10000 (84%)\n",
            "\n",
            "Epoch [70 / 80], Step [100 / 500], Loss : 0.203112\n",
            "Epoch [70 / 80], Step [200 / 500], Loss : 0.110093\n",
            "Epoch [70 / 80], Step [300 / 500], Loss : 0.069298\n",
            "Epoch [70 / 80], Step [400 / 500], Loss : 0.070766\n",
            "Epoch [70 / 80], Step [500 / 500], Loss : 0.164183\n",
            "\n",
            "Test Set : Average Loss : 0.006726, Accuracy : 8405 / 10000 (84%)\n",
            "\n",
            "Epoch [71 / 80], Step [100 / 500], Loss : 0.072687\n",
            "Epoch [71 / 80], Step [200 / 500], Loss : 0.172920\n",
            "Epoch [71 / 80], Step [300 / 500], Loss : 0.107630\n",
            "Epoch [71 / 80], Step [400 / 500], Loss : 0.091610\n",
            "Epoch [71 / 80], Step [500 / 500], Loss : 0.080091\n",
            "\n",
            "Test Set : Average Loss : 0.006646, Accuracy : 8432 / 10000 (84%)\n",
            "\n",
            "Epoch [72 / 80], Step [100 / 500], Loss : 0.145605\n",
            "Epoch [72 / 80], Step [200 / 500], Loss : 0.100987\n",
            "Epoch [72 / 80], Step [300 / 500], Loss : 0.079646\n",
            "Epoch [72 / 80], Step [400 / 500], Loss : 0.166042\n",
            "Epoch [72 / 80], Step [500 / 500], Loss : 0.108592\n",
            "\n",
            "Test Set : Average Loss : 0.007253, Accuracy : 8328 / 10000 (83%)\n",
            "\n",
            "Epoch [73 / 80], Step [100 / 500], Loss : 0.175333\n",
            "Epoch [73 / 80], Step [200 / 500], Loss : 0.168019\n",
            "Epoch [73 / 80], Step [300 / 500], Loss : 0.096457\n",
            "Epoch [73 / 80], Step [400 / 500], Loss : 0.114649\n",
            "Epoch [73 / 80], Step [500 / 500], Loss : 0.080013\n",
            "\n",
            "Test Set : Average Loss : 0.007085, Accuracy : 8356 / 10000 (84%)\n",
            "\n",
            "Epoch [74 / 80], Step [100 / 500], Loss : 0.077819\n",
            "Epoch [74 / 80], Step [200 / 500], Loss : 0.075619\n",
            "Epoch [74 / 80], Step [300 / 500], Loss : 0.094259\n",
            "Epoch [74 / 80], Step [400 / 500], Loss : 0.071904\n",
            "Epoch [74 / 80], Step [500 / 500], Loss : 0.161300\n",
            "\n",
            "Test Set : Average Loss : 0.007139, Accuracy : 8381 / 10000 (84%)\n",
            "\n",
            "Epoch [75 / 80], Step [100 / 500], Loss : 0.119352\n",
            "Epoch [75 / 80], Step [200 / 500], Loss : 0.047669\n",
            "Epoch [75 / 80], Step [300 / 500], Loss : 0.095920\n",
            "Epoch [75 / 80], Step [400 / 500], Loss : 0.071533\n",
            "Epoch [75 / 80], Step [500 / 500], Loss : 0.171000\n",
            "\n",
            "Test Set : Average Loss : 0.007540, Accuracy : 8348 / 10000 (83%)\n",
            "\n",
            "Epoch [76 / 80], Step [100 / 500], Loss : 0.123436\n",
            "Epoch [76 / 80], Step [200 / 500], Loss : 0.157069\n",
            "Epoch [76 / 80], Step [300 / 500], Loss : 0.174466\n",
            "Epoch [76 / 80], Step [400 / 500], Loss : 0.095186\n",
            "Epoch [76 / 80], Step [500 / 500], Loss : 0.131328\n",
            "\n",
            "Test Set : Average Loss : 0.007939, Accuracy : 8247 / 10000 (82%)\n",
            "\n",
            "Epoch [77 / 80], Step [100 / 500], Loss : 0.196531\n",
            "Epoch [77 / 80], Step [200 / 500], Loss : 0.083879\n",
            "Epoch [77 / 80], Step [300 / 500], Loss : 0.061045\n",
            "Epoch [77 / 80], Step [400 / 500], Loss : 0.111253\n",
            "Epoch [77 / 80], Step [500 / 500], Loss : 0.109928\n",
            "\n",
            "Test Set : Average Loss : 0.007344, Accuracy : 8322 / 10000 (83%)\n",
            "\n",
            "Epoch [78 / 80], Step [100 / 500], Loss : 0.213246\n",
            "Epoch [78 / 80], Step [200 / 500], Loss : 0.063952\n",
            "Epoch [78 / 80], Step [300 / 500], Loss : 0.071645\n",
            "Epoch [78 / 80], Step [400 / 500], Loss : 0.123685\n",
            "Epoch [78 / 80], Step [500 / 500], Loss : 0.165546\n",
            "\n",
            "Test Set : Average Loss : 0.006839, Accuracy : 8431 / 10000 (84%)\n",
            "\n",
            "Epoch [79 / 80], Step [100 / 500], Loss : 0.129872\n",
            "Epoch [79 / 80], Step [200 / 500], Loss : 0.072248\n",
            "Epoch [79 / 80], Step [300 / 500], Loss : 0.121435\n",
            "Epoch [79 / 80], Step [400 / 500], Loss : 0.122940\n",
            "Epoch [79 / 80], Step [500 / 500], Loss : 0.105252\n",
            "\n",
            "Test Set : Average Loss : 0.007317, Accuracy : 8372 / 10000 (84%)\n",
            "\n",
            "Epoch [80 / 80], Step [100 / 500], Loss : 0.129693\n",
            "Epoch [80 / 80], Step [200 / 500], Loss : 0.082177\n",
            "Epoch [80 / 80], Step [300 / 500], Loss : 0.080315\n",
            "Epoch [80 / 80], Step [400 / 500], Loss : 0.107359\n",
            "Epoch [80 / 80], Step [500 / 500], Loss : 0.175667\n",
            "\n",
            "Test Set : Average Loss : 0.007545, Accuracy : 8374 / 10000 (84%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 - 3\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes = 10, init_weights = True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels = 64\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n",
        "        nn.InstanceNorm2d([64, 16, 16]),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "    )\n",
        "\n",
        "    self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "    self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "    self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "    self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    if init_weights:\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "     strides = [stride] + [1] * (num_blocks - 1)\n",
        "     layers = []\n",
        "     for stride in strides:\n",
        "       layers.append(block(self.in_channels, out_channels, stride))\n",
        "       self.in_channels = out_channels * block.expansion\n",
        "\n",
        "     return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x = self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity = 'relu')\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "          nn.init.constant_(m.weight, 1)\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "          nn.init.normal_(m.weight, 0, 0.01)\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "\n",
        "model = ResNet(BasicBlock, [2, 2, 2, 2]).cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range (0, num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UhxFcMFkgAM",
        "outputId": "f40447aa-3b34-4695-b933-b5b87e9af506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 80], Step [100 / 500], Loss : 1.756659\n",
            "Epoch [1 / 80], Step [200 / 500], Loss : 1.470392\n",
            "Epoch [1 / 80], Step [300 / 500], Loss : 1.553804\n",
            "Epoch [1 / 80], Step [400 / 500], Loss : 1.317049\n",
            "Epoch [1 / 80], Step [500 / 500], Loss : 1.507332\n",
            "\n",
            "Test Set : Average Loss : 0.013745, Accuracy : 5081 / 10000 (51%)\n",
            "\n",
            "Epoch [2 / 80], Step [100 / 500], Loss : 1.179566\n",
            "Epoch [2 / 80], Step [200 / 500], Loss : 1.305919\n",
            "Epoch [2 / 80], Step [300 / 500], Loss : 1.314830\n",
            "Epoch [2 / 80], Step [400 / 500], Loss : 1.106212\n",
            "Epoch [2 / 80], Step [500 / 500], Loss : 1.125040\n",
            "\n",
            "Test Set : Average Loss : 0.011429, Accuracy : 5980 / 10000 (60%)\n",
            "\n",
            "Epoch [3 / 80], Step [100 / 500], Loss : 1.118409\n",
            "Epoch [3 / 80], Step [200 / 500], Loss : 0.900647\n",
            "Epoch [3 / 80], Step [300 / 500], Loss : 0.954486\n",
            "Epoch [3 / 80], Step [400 / 500], Loss : 0.876627\n",
            "Epoch [3 / 80], Step [500 / 500], Loss : 1.148413\n",
            "\n",
            "Test Set : Average Loss : 0.010831, Accuracy : 6248 / 10000 (62%)\n",
            "\n",
            "Epoch [4 / 80], Step [100 / 500], Loss : 1.079449\n",
            "Epoch [4 / 80], Step [200 / 500], Loss : 0.841466\n",
            "Epoch [4 / 80], Step [300 / 500], Loss : 1.056525\n",
            "Epoch [4 / 80], Step [400 / 500], Loss : 0.827474\n",
            "Epoch [4 / 80], Step [500 / 500], Loss : 1.092267\n",
            "\n",
            "Test Set : Average Loss : 0.009246, Accuracy : 6806 / 10000 (68%)\n",
            "\n",
            "Epoch [5 / 80], Step [100 / 500], Loss : 0.838777\n",
            "Epoch [5 / 80], Step [200 / 500], Loss : 0.935914\n",
            "Epoch [5 / 80], Step [300 / 500], Loss : 0.901675\n",
            "Epoch [5 / 80], Step [400 / 500], Loss : 0.690192\n",
            "Epoch [5 / 80], Step [500 / 500], Loss : 0.974340\n",
            "\n",
            "Test Set : Average Loss : 0.008615, Accuracy : 7063 / 10000 (71%)\n",
            "\n",
            "Epoch [6 / 80], Step [100 / 500], Loss : 0.855611\n",
            "Epoch [6 / 80], Step [200 / 500], Loss : 0.748662\n",
            "Epoch [6 / 80], Step [300 / 500], Loss : 0.901702\n",
            "Epoch [6 / 80], Step [400 / 500], Loss : 0.812020\n",
            "Epoch [6 / 80], Step [500 / 500], Loss : 0.957345\n",
            "\n",
            "Test Set : Average Loss : 0.008914, Accuracy : 6901 / 10000 (69%)\n",
            "\n",
            "Epoch [7 / 80], Step [100 / 500], Loss : 0.787122\n",
            "Epoch [7 / 80], Step [200 / 500], Loss : 0.671750\n",
            "Epoch [7 / 80], Step [300 / 500], Loss : 0.690994\n",
            "Epoch [7 / 80], Step [400 / 500], Loss : 0.708618\n",
            "Epoch [7 / 80], Step [500 / 500], Loss : 0.611854\n",
            "\n",
            "Test Set : Average Loss : 0.007994, Accuracy : 7308 / 10000 (73%)\n",
            "\n",
            "Epoch [8 / 80], Step [100 / 500], Loss : 0.719366\n",
            "Epoch [8 / 80], Step [200 / 500], Loss : 0.788493\n",
            "Epoch [8 / 80], Step [300 / 500], Loss : 0.901410\n",
            "Epoch [8 / 80], Step [400 / 500], Loss : 0.843604\n",
            "Epoch [8 / 80], Step [500 / 500], Loss : 0.774199\n",
            "\n",
            "Test Set : Average Loss : 0.007528, Accuracy : 7374 / 10000 (74%)\n",
            "\n",
            "Epoch [9 / 80], Step [100 / 500], Loss : 0.773078\n",
            "Epoch [9 / 80], Step [200 / 500], Loss : 0.647807\n",
            "Epoch [9 / 80], Step [300 / 500], Loss : 0.713887\n",
            "Epoch [9 / 80], Step [400 / 500], Loss : 0.675800\n",
            "Epoch [9 / 80], Step [500 / 500], Loss : 0.805386\n",
            "\n",
            "Test Set : Average Loss : 0.007644, Accuracy : 7458 / 10000 (75%)\n",
            "\n",
            "Epoch [10 / 80], Step [100 / 500], Loss : 0.522015\n",
            "Epoch [10 / 80], Step [200 / 500], Loss : 0.553624\n",
            "Epoch [10 / 80], Step [300 / 500], Loss : 0.679750\n",
            "Epoch [10 / 80], Step [400 / 500], Loss : 0.683953\n",
            "Epoch [10 / 80], Step [500 / 500], Loss : 0.696094\n",
            "\n",
            "Test Set : Average Loss : 0.006830, Accuracy : 7666 / 10000 (77%)\n",
            "\n",
            "Epoch [11 / 80], Step [100 / 500], Loss : 0.704491\n",
            "Epoch [11 / 80], Step [200 / 500], Loss : 0.679670\n",
            "Epoch [11 / 80], Step [300 / 500], Loss : 0.533891\n",
            "Epoch [11 / 80], Step [400 / 500], Loss : 0.526435\n",
            "Epoch [11 / 80], Step [500 / 500], Loss : 0.752839\n",
            "\n",
            "Test Set : Average Loss : 0.006854, Accuracy : 7710 / 10000 (77%)\n",
            "\n",
            "Epoch [12 / 80], Step [100 / 500], Loss : 0.536724\n",
            "Epoch [12 / 80], Step [200 / 500], Loss : 0.481495\n",
            "Epoch [12 / 80], Step [300 / 500], Loss : 0.777140\n",
            "Epoch [12 / 80], Step [400 / 500], Loss : 0.639850\n",
            "Epoch [12 / 80], Step [500 / 500], Loss : 0.837526\n",
            "\n",
            "Test Set : Average Loss : 0.006596, Accuracy : 7758 / 10000 (78%)\n",
            "\n",
            "Epoch [13 / 80], Step [100 / 500], Loss : 0.559105\n",
            "Epoch [13 / 80], Step [200 / 500], Loss : 0.784699\n",
            "Epoch [13 / 80], Step [300 / 500], Loss : 0.670258\n",
            "Epoch [13 / 80], Step [400 / 500], Loss : 0.592102\n",
            "Epoch [13 / 80], Step [500 / 500], Loss : 0.412439\n",
            "\n",
            "Test Set : Average Loss : 0.006694, Accuracy : 7703 / 10000 (77%)\n",
            "\n",
            "Epoch [14 / 80], Step [100 / 500], Loss : 0.510999\n",
            "Epoch [14 / 80], Step [200 / 500], Loss : 0.610824\n",
            "Epoch [14 / 80], Step [300 / 500], Loss : 0.665293\n",
            "Epoch [14 / 80], Step [400 / 500], Loss : 0.527284\n",
            "Epoch [14 / 80], Step [500 / 500], Loss : 0.499727\n",
            "\n",
            "Test Set : Average Loss : 0.007189, Accuracy : 7672 / 10000 (77%)\n",
            "\n",
            "Epoch [15 / 80], Step [100 / 500], Loss : 0.423958\n",
            "Epoch [15 / 80], Step [200 / 500], Loss : 0.532651\n",
            "Epoch [15 / 80], Step [300 / 500], Loss : 0.595742\n",
            "Epoch [15 / 80], Step [400 / 500], Loss : 0.811493\n",
            "Epoch [15 / 80], Step [500 / 500], Loss : 0.533993\n",
            "\n",
            "Test Set : Average Loss : 0.006384, Accuracy : 7895 / 10000 (79%)\n",
            "\n",
            "Epoch [16 / 80], Step [100 / 500], Loss : 0.607203\n",
            "Epoch [16 / 80], Step [200 / 500], Loss : 0.646644\n",
            "Epoch [16 / 80], Step [300 / 500], Loss : 0.566663\n",
            "Epoch [16 / 80], Step [400 / 500], Loss : 0.590373\n",
            "Epoch [16 / 80], Step [500 / 500], Loss : 0.543101\n",
            "\n",
            "Test Set : Average Loss : 0.006209, Accuracy : 7926 / 10000 (79%)\n",
            "\n",
            "Epoch [17 / 80], Step [100 / 500], Loss : 0.544525\n",
            "Epoch [17 / 80], Step [200 / 500], Loss : 0.426814\n",
            "Epoch [17 / 80], Step [300 / 500], Loss : 0.426152\n",
            "Epoch [17 / 80], Step [400 / 500], Loss : 0.674622\n",
            "Epoch [17 / 80], Step [500 / 500], Loss : 0.592742\n",
            "\n",
            "Test Set : Average Loss : 0.006180, Accuracy : 7913 / 10000 (79%)\n",
            "\n",
            "Epoch [18 / 80], Step [100 / 500], Loss : 0.349500\n",
            "Epoch [18 / 80], Step [200 / 500], Loss : 0.554909\n",
            "Epoch [18 / 80], Step [300 / 500], Loss : 0.529128\n",
            "Epoch [18 / 80], Step [400 / 500], Loss : 0.490741\n",
            "Epoch [18 / 80], Step [500 / 500], Loss : 0.417942\n",
            "\n",
            "Test Set : Average Loss : 0.006123, Accuracy : 7968 / 10000 (80%)\n",
            "\n",
            "Epoch [19 / 80], Step [100 / 500], Loss : 0.548935\n",
            "Epoch [19 / 80], Step [200 / 500], Loss : 0.460704\n",
            "Epoch [19 / 80], Step [300 / 500], Loss : 0.461915\n",
            "Epoch [19 / 80], Step [400 / 500], Loss : 0.702393\n",
            "Epoch [19 / 80], Step [500 / 500], Loss : 0.682487\n",
            "\n",
            "Test Set : Average Loss : 0.005856, Accuracy : 7993 / 10000 (80%)\n",
            "\n",
            "Epoch [20 / 80], Step [100 / 500], Loss : 0.520392\n",
            "Epoch [20 / 80], Step [200 / 500], Loss : 0.659305\n",
            "Epoch [20 / 80], Step [300 / 500], Loss : 0.371273\n",
            "Epoch [20 / 80], Step [400 / 500], Loss : 0.420898\n",
            "Epoch [20 / 80], Step [500 / 500], Loss : 0.729129\n",
            "\n",
            "Test Set : Average Loss : 0.005994, Accuracy : 7994 / 10000 (80%)\n",
            "\n",
            "Epoch [21 / 80], Step [100 / 500], Loss : 0.450416\n",
            "Epoch [21 / 80], Step [200 / 500], Loss : 0.303777\n",
            "Epoch [21 / 80], Step [300 / 500], Loss : 0.395107\n",
            "Epoch [21 / 80], Step [400 / 500], Loss : 0.409576\n",
            "Epoch [21 / 80], Step [500 / 500], Loss : 0.431301\n",
            "\n",
            "Test Set : Average Loss : 0.005229, Accuracy : 8272 / 10000 (83%)\n",
            "\n",
            "Epoch [22 / 80], Step [100 / 500], Loss : 0.285311\n",
            "Epoch [22 / 80], Step [200 / 500], Loss : 0.486582\n",
            "Epoch [22 / 80], Step [300 / 500], Loss : 0.374615\n",
            "Epoch [22 / 80], Step [400 / 500], Loss : 0.391277\n",
            "Epoch [22 / 80], Step [500 / 500], Loss : 0.328917\n",
            "\n",
            "Test Set : Average Loss : 0.005174, Accuracy : 8294 / 10000 (83%)\n",
            "\n",
            "Epoch [23 / 80], Step [100 / 500], Loss : 0.270924\n",
            "Epoch [23 / 80], Step [200 / 500], Loss : 0.344192\n",
            "Epoch [23 / 80], Step [300 / 500], Loss : 0.463744\n",
            "Epoch [23 / 80], Step [400 / 500], Loss : 0.310582\n",
            "Epoch [23 / 80], Step [500 / 500], Loss : 0.417978\n",
            "\n",
            "Test Set : Average Loss : 0.005131, Accuracy : 8313 / 10000 (83%)\n",
            "\n",
            "Epoch [24 / 80], Step [100 / 500], Loss : 0.348068\n",
            "Epoch [24 / 80], Step [200 / 500], Loss : 0.199359\n",
            "Epoch [24 / 80], Step [300 / 500], Loss : 0.324142\n",
            "Epoch [24 / 80], Step [400 / 500], Loss : 0.392932\n",
            "Epoch [24 / 80], Step [500 / 500], Loss : 0.347303\n",
            "\n",
            "Test Set : Average Loss : 0.005132, Accuracy : 8344 / 10000 (83%)\n",
            "\n",
            "Epoch [25 / 80], Step [100 / 500], Loss : 0.359244\n",
            "Epoch [25 / 80], Step [200 / 500], Loss : 0.358218\n",
            "Epoch [25 / 80], Step [300 / 500], Loss : 0.377110\n",
            "Epoch [25 / 80], Step [400 / 500], Loss : 0.419282\n",
            "Epoch [25 / 80], Step [500 / 500], Loss : 0.272559\n",
            "\n",
            "Test Set : Average Loss : 0.005092, Accuracy : 8324 / 10000 (83%)\n",
            "\n",
            "Epoch [26 / 80], Step [100 / 500], Loss : 0.294422\n",
            "Epoch [26 / 80], Step [200 / 500], Loss : 0.381115\n",
            "Epoch [26 / 80], Step [300 / 500], Loss : 0.346415\n",
            "Epoch [26 / 80], Step [400 / 500], Loss : 0.259030\n",
            "Epoch [26 / 80], Step [500 / 500], Loss : 0.300458\n",
            "\n",
            "Test Set : Average Loss : 0.005071, Accuracy : 8370 / 10000 (84%)\n",
            "\n",
            "Epoch [27 / 80], Step [100 / 500], Loss : 0.236136\n",
            "Epoch [27 / 80], Step [200 / 500], Loss : 0.384393\n",
            "Epoch [27 / 80], Step [300 / 500], Loss : 0.408094\n",
            "Epoch [27 / 80], Step [400 / 500], Loss : 0.293371\n",
            "Epoch [27 / 80], Step [500 / 500], Loss : 0.373258\n",
            "\n",
            "Test Set : Average Loss : 0.005050, Accuracy : 8391 / 10000 (84%)\n",
            "\n",
            "Epoch [28 / 80], Step [100 / 500], Loss : 0.358330\n",
            "Epoch [28 / 80], Step [200 / 500], Loss : 0.388434\n",
            "Epoch [28 / 80], Step [300 / 500], Loss : 0.373100\n",
            "Epoch [28 / 80], Step [400 / 500], Loss : 0.215637\n",
            "Epoch [28 / 80], Step [500 / 500], Loss : 0.544366\n",
            "\n",
            "Test Set : Average Loss : 0.005057, Accuracy : 8371 / 10000 (84%)\n",
            "\n",
            "Epoch [29 / 80], Step [100 / 500], Loss : 0.201733\n",
            "Epoch [29 / 80], Step [200 / 500], Loss : 0.298253\n",
            "Epoch [29 / 80], Step [300 / 500], Loss : 0.433233\n",
            "Epoch [29 / 80], Step [400 / 500], Loss : 0.344839\n",
            "Epoch [29 / 80], Step [500 / 500], Loss : 0.357464\n",
            "\n",
            "Test Set : Average Loss : 0.005224, Accuracy : 8317 / 10000 (83%)\n",
            "\n",
            "Epoch [30 / 80], Step [100 / 500], Loss : 0.251876\n",
            "Epoch [30 / 80], Step [200 / 500], Loss : 0.198045\n",
            "Epoch [30 / 80], Step [300 / 500], Loss : 0.191888\n",
            "Epoch [30 / 80], Step [400 / 500], Loss : 0.273979\n",
            "Epoch [30 / 80], Step [500 / 500], Loss : 0.326622\n",
            "\n",
            "Test Set : Average Loss : 0.005238, Accuracy : 8309 / 10000 (83%)\n",
            "\n",
            "Epoch [31 / 80], Step [100 / 500], Loss : 0.289899\n",
            "Epoch [31 / 80], Step [200 / 500], Loss : 0.339618\n",
            "Epoch [31 / 80], Step [300 / 500], Loss : 0.294834\n",
            "Epoch [31 / 80], Step [400 / 500], Loss : 0.300005\n",
            "Epoch [31 / 80], Step [500 / 500], Loss : 0.168368\n",
            "\n",
            "Test Set : Average Loss : 0.005166, Accuracy : 8351 / 10000 (84%)\n",
            "\n",
            "Epoch [32 / 80], Step [100 / 500], Loss : 0.290917\n",
            "Epoch [32 / 80], Step [200 / 500], Loss : 0.196245\n",
            "Epoch [32 / 80], Step [300 / 500], Loss : 0.355610\n",
            "Epoch [32 / 80], Step [400 / 500], Loss : 0.393887\n",
            "Epoch [32 / 80], Step [500 / 500], Loss : 0.236343\n",
            "\n",
            "Test Set : Average Loss : 0.005149, Accuracy : 8365 / 10000 (84%)\n",
            "\n",
            "Epoch [33 / 80], Step [100 / 500], Loss : 0.196431\n",
            "Epoch [33 / 80], Step [200 / 500], Loss : 0.330924\n",
            "Epoch [33 / 80], Step [300 / 500], Loss : 0.275754\n",
            "Epoch [33 / 80], Step [400 / 500], Loss : 0.285275\n",
            "Epoch [33 / 80], Step [500 / 500], Loss : 0.314996\n",
            "\n",
            "Test Set : Average Loss : 0.005231, Accuracy : 8366 / 10000 (84%)\n",
            "\n",
            "Epoch [34 / 80], Step [100 / 500], Loss : 0.221161\n",
            "Epoch [34 / 80], Step [200 / 500], Loss : 0.346818\n",
            "Epoch [34 / 80], Step [300 / 500], Loss : 0.206445\n",
            "Epoch [34 / 80], Step [400 / 500], Loss : 0.275707\n",
            "Epoch [34 / 80], Step [500 / 500], Loss : 0.563306\n",
            "\n",
            "Test Set : Average Loss : 0.005112, Accuracy : 8409 / 10000 (84%)\n",
            "\n",
            "Epoch [35 / 80], Step [100 / 500], Loss : 0.307462\n",
            "Epoch [35 / 80], Step [200 / 500], Loss : 0.213058\n",
            "Epoch [35 / 80], Step [300 / 500], Loss : 0.379457\n",
            "Epoch [35 / 80], Step [400 / 500], Loss : 0.307334\n",
            "Epoch [35 / 80], Step [500 / 500], Loss : 0.249343\n",
            "\n",
            "Test Set : Average Loss : 0.005235, Accuracy : 8394 / 10000 (84%)\n",
            "\n",
            "Epoch [36 / 80], Step [100 / 500], Loss : 0.301758\n",
            "Epoch [36 / 80], Step [200 / 500], Loss : 0.229800\n",
            "Epoch [36 / 80], Step [300 / 500], Loss : 0.290916\n",
            "Epoch [36 / 80], Step [400 / 500], Loss : 0.293964\n",
            "Epoch [36 / 80], Step [500 / 500], Loss : 0.296129\n",
            "\n",
            "Test Set : Average Loss : 0.005406, Accuracy : 8340 / 10000 (83%)\n",
            "\n",
            "Epoch [37 / 80], Step [100 / 500], Loss : 0.313442\n",
            "Epoch [37 / 80], Step [200 / 500], Loss : 0.182711\n",
            "Epoch [37 / 80], Step [300 / 500], Loss : 0.373710\n",
            "Epoch [37 / 80], Step [400 / 500], Loss : 0.325896\n",
            "Epoch [37 / 80], Step [500 / 500], Loss : 0.183444\n",
            "\n",
            "Test Set : Average Loss : 0.005260, Accuracy : 8390 / 10000 (84%)\n",
            "\n",
            "Epoch [38 / 80], Step [100 / 500], Loss : 0.307838\n",
            "Epoch [38 / 80], Step [200 / 500], Loss : 0.274928\n",
            "Epoch [38 / 80], Step [300 / 500], Loss : 0.345443\n",
            "Epoch [38 / 80], Step [400 / 500], Loss : 0.113621\n",
            "Epoch [38 / 80], Step [500 / 500], Loss : 0.140332\n",
            "\n",
            "Test Set : Average Loss : 0.005324, Accuracy : 8382 / 10000 (84%)\n",
            "\n",
            "Epoch [39 / 80], Step [100 / 500], Loss : 0.333241\n",
            "Epoch [39 / 80], Step [200 / 500], Loss : 0.293145\n",
            "Epoch [39 / 80], Step [300 / 500], Loss : 0.172880\n",
            "Epoch [39 / 80], Step [400 / 500], Loss : 0.291596\n",
            "Epoch [39 / 80], Step [500 / 500], Loss : 0.350186\n",
            "\n",
            "Test Set : Average Loss : 0.005287, Accuracy : 8409 / 10000 (84%)\n",
            "\n",
            "Epoch [40 / 80], Step [100 / 500], Loss : 0.401100\n",
            "Epoch [40 / 80], Step [200 / 500], Loss : 0.359916\n",
            "Epoch [40 / 80], Step [300 / 500], Loss : 0.186964\n",
            "Epoch [40 / 80], Step [400 / 500], Loss : 0.241797\n",
            "Epoch [40 / 80], Step [500 / 500], Loss : 0.318387\n",
            "\n",
            "Test Set : Average Loss : 0.005348, Accuracy : 8389 / 10000 (84%)\n",
            "\n",
            "Epoch [41 / 80], Step [100 / 500], Loss : 0.196673\n",
            "Epoch [41 / 80], Step [200 / 500], Loss : 0.119846\n",
            "Epoch [41 / 80], Step [300 / 500], Loss : 0.323236\n",
            "Epoch [41 / 80], Step [400 / 500], Loss : 0.170941\n",
            "Epoch [41 / 80], Step [500 / 500], Loss : 0.227224\n",
            "\n",
            "Test Set : Average Loss : 0.005307, Accuracy : 8408 / 10000 (84%)\n",
            "\n",
            "Epoch [42 / 80], Step [100 / 500], Loss : 0.159458\n",
            "Epoch [42 / 80], Step [200 / 500], Loss : 0.304409\n",
            "Epoch [42 / 80], Step [300 / 500], Loss : 0.313101\n",
            "Epoch [42 / 80], Step [400 / 500], Loss : 0.194719\n",
            "Epoch [42 / 80], Step [500 / 500], Loss : 0.318930\n",
            "\n",
            "Test Set : Average Loss : 0.005446, Accuracy : 8361 / 10000 (84%)\n",
            "\n",
            "Epoch [43 / 80], Step [100 / 500], Loss : 0.189059\n",
            "Epoch [43 / 80], Step [200 / 500], Loss : 0.242951\n",
            "Epoch [43 / 80], Step [300 / 500], Loss : 0.211559\n",
            "Epoch [43 / 80], Step [400 / 500], Loss : 0.216239\n",
            "Epoch [43 / 80], Step [500 / 500], Loss : 0.201531\n",
            "\n",
            "Test Set : Average Loss : 0.005505, Accuracy : 8348 / 10000 (83%)\n",
            "\n",
            "Epoch [44 / 80], Step [100 / 500], Loss : 0.348230\n",
            "Epoch [44 / 80], Step [200 / 500], Loss : 0.156469\n",
            "Epoch [44 / 80], Step [300 / 500], Loss : 0.209479\n",
            "Epoch [44 / 80], Step [400 / 500], Loss : 0.208565\n",
            "Epoch [44 / 80], Step [500 / 500], Loss : 0.291419\n",
            "\n",
            "Test Set : Average Loss : 0.005473, Accuracy : 8407 / 10000 (84%)\n",
            "\n",
            "Epoch [45 / 80], Step [100 / 500], Loss : 0.141242\n",
            "Epoch [45 / 80], Step [200 / 500], Loss : 0.243406\n",
            "Epoch [45 / 80], Step [300 / 500], Loss : 0.249439\n",
            "Epoch [45 / 80], Step [400 / 500], Loss : 0.208737\n",
            "Epoch [45 / 80], Step [500 / 500], Loss : 0.128452\n",
            "\n",
            "Test Set : Average Loss : 0.005388, Accuracy : 8418 / 10000 (84%)\n",
            "\n",
            "Epoch [46 / 80], Step [100 / 500], Loss : 0.185613\n",
            "Epoch [46 / 80], Step [200 / 500], Loss : 0.212785\n",
            "Epoch [46 / 80], Step [300 / 500], Loss : 0.269344\n",
            "Epoch [46 / 80], Step [400 / 500], Loss : 0.131166\n",
            "Epoch [46 / 80], Step [500 / 500], Loss : 0.155141\n",
            "\n",
            "Test Set : Average Loss : 0.005649, Accuracy : 8339 / 10000 (83%)\n",
            "\n",
            "Epoch [47 / 80], Step [100 / 500], Loss : 0.195060\n",
            "Epoch [47 / 80], Step [200 / 500], Loss : 0.234343\n",
            "Epoch [47 / 80], Step [300 / 500], Loss : 0.183075\n",
            "Epoch [47 / 80], Step [400 / 500], Loss : 0.161693\n",
            "Epoch [47 / 80], Step [500 / 500], Loss : 0.165667\n",
            "\n",
            "Test Set : Average Loss : 0.005495, Accuracy : 8396 / 10000 (84%)\n",
            "\n",
            "Epoch [48 / 80], Step [100 / 500], Loss : 0.149194\n",
            "Epoch [48 / 80], Step [200 / 500], Loss : 0.209686\n",
            "Epoch [48 / 80], Step [300 / 500], Loss : 0.216859\n",
            "Epoch [48 / 80], Step [400 / 500], Loss : 0.318345\n",
            "Epoch [48 / 80], Step [500 / 500], Loss : 0.152840\n",
            "\n",
            "Test Set : Average Loss : 0.005546, Accuracy : 8423 / 10000 (84%)\n",
            "\n",
            "Epoch [49 / 80], Step [100 / 500], Loss : 0.215678\n",
            "Epoch [49 / 80], Step [200 / 500], Loss : 0.191718\n",
            "Epoch [49 / 80], Step [300 / 500], Loss : 0.201949\n",
            "Epoch [49 / 80], Step [400 / 500], Loss : 0.146169\n",
            "Epoch [49 / 80], Step [500 / 500], Loss : 0.225664\n",
            "\n",
            "Test Set : Average Loss : 0.005726, Accuracy : 8401 / 10000 (84%)\n",
            "\n",
            "Epoch [50 / 80], Step [100 / 500], Loss : 0.243853\n",
            "Epoch [50 / 80], Step [200 / 500], Loss : 0.154486\n",
            "Epoch [50 / 80], Step [300 / 500], Loss : 0.215205\n",
            "Epoch [50 / 80], Step [400 / 500], Loss : 0.273873\n",
            "Epoch [50 / 80], Step [500 / 500], Loss : 0.148259\n",
            "\n",
            "Test Set : Average Loss : 0.005700, Accuracy : 8400 / 10000 (84%)\n",
            "\n",
            "Epoch [51 / 80], Step [100 / 500], Loss : 0.143257\n",
            "Epoch [51 / 80], Step [200 / 500], Loss : 0.246583\n",
            "Epoch [51 / 80], Step [300 / 500], Loss : 0.215493\n",
            "Epoch [51 / 80], Step [400 / 500], Loss : 0.292239\n",
            "Epoch [51 / 80], Step [500 / 500], Loss : 0.354849\n",
            "\n",
            "Test Set : Average Loss : 0.005932, Accuracy : 8368 / 10000 (84%)\n",
            "\n",
            "Epoch [52 / 80], Step [100 / 500], Loss : 0.205312\n",
            "Epoch [52 / 80], Step [200 / 500], Loss : 0.120661\n",
            "Epoch [52 / 80], Step [300 / 500], Loss : 0.150610\n",
            "Epoch [52 / 80], Step [400 / 500], Loss : 0.238620\n",
            "Epoch [52 / 80], Step [500 / 500], Loss : 0.111017\n",
            "\n",
            "Test Set : Average Loss : 0.005646, Accuracy : 8408 / 10000 (84%)\n",
            "\n",
            "Epoch [53 / 80], Step [100 / 500], Loss : 0.120218\n",
            "Epoch [53 / 80], Step [200 / 500], Loss : 0.179207\n",
            "Epoch [53 / 80], Step [300 / 500], Loss : 0.174561\n",
            "Epoch [53 / 80], Step [400 / 500], Loss : 0.148034\n",
            "Epoch [53 / 80], Step [500 / 500], Loss : 0.129439\n",
            "\n",
            "Test Set : Average Loss : 0.005752, Accuracy : 8430 / 10000 (84%)\n",
            "\n",
            "Epoch [54 / 80], Step [100 / 500], Loss : 0.158800\n",
            "Epoch [54 / 80], Step [200 / 500], Loss : 0.121877\n",
            "Epoch [54 / 80], Step [300 / 500], Loss : 0.203066\n",
            "Epoch [54 / 80], Step [400 / 500], Loss : 0.226501\n",
            "Epoch [54 / 80], Step [500 / 500], Loss : 0.199145\n",
            "\n",
            "Test Set : Average Loss : 0.005818, Accuracy : 8430 / 10000 (84%)\n",
            "\n",
            "Epoch [55 / 80], Step [100 / 500], Loss : 0.108795\n",
            "Epoch [55 / 80], Step [200 / 500], Loss : 0.260706\n",
            "Epoch [55 / 80], Step [300 / 500], Loss : 0.138392\n",
            "Epoch [55 / 80], Step [400 / 500], Loss : 0.186588\n",
            "Epoch [55 / 80], Step [500 / 500], Loss : 0.198422\n",
            "\n",
            "Test Set : Average Loss : 0.005809, Accuracy : 8391 / 10000 (84%)\n",
            "\n",
            "Epoch [56 / 80], Step [100 / 500], Loss : 0.134055\n",
            "Epoch [56 / 80], Step [200 / 500], Loss : 0.252921\n",
            "Epoch [56 / 80], Step [300 / 500], Loss : 0.176338\n",
            "Epoch [56 / 80], Step [400 / 500], Loss : 0.185072\n",
            "Epoch [56 / 80], Step [500 / 500], Loss : 0.145288\n",
            "\n",
            "Test Set : Average Loss : 0.005709, Accuracy : 8412 / 10000 (84%)\n",
            "\n",
            "Epoch [57 / 80], Step [100 / 500], Loss : 0.225532\n",
            "Epoch [57 / 80], Step [200 / 500], Loss : 0.097987\n",
            "Epoch [57 / 80], Step [300 / 500], Loss : 0.111359\n",
            "Epoch [57 / 80], Step [400 / 500], Loss : 0.185229\n",
            "Epoch [57 / 80], Step [500 / 500], Loss : 0.182287\n",
            "\n",
            "Test Set : Average Loss : 0.005948, Accuracy : 8399 / 10000 (84%)\n",
            "\n",
            "Epoch [58 / 80], Step [100 / 500], Loss : 0.129710\n",
            "Epoch [58 / 80], Step [200 / 500], Loss : 0.220627\n",
            "Epoch [58 / 80], Step [300 / 500], Loss : 0.325235\n",
            "Epoch [58 / 80], Step [400 / 500], Loss : 0.233440\n",
            "Epoch [58 / 80], Step [500 / 500], Loss : 0.114656\n",
            "\n",
            "Test Set : Average Loss : 0.006065, Accuracy : 8403 / 10000 (84%)\n",
            "\n",
            "Epoch [59 / 80], Step [100 / 500], Loss : 0.185839\n",
            "Epoch [59 / 80], Step [200 / 500], Loss : 0.202936\n",
            "Epoch [59 / 80], Step [300 / 500], Loss : 0.285623\n",
            "Epoch [59 / 80], Step [400 / 500], Loss : 0.155794\n",
            "Epoch [59 / 80], Step [500 / 500], Loss : 0.118524\n",
            "\n",
            "Test Set : Average Loss : 0.006208, Accuracy : 8391 / 10000 (84%)\n",
            "\n",
            "Epoch [60 / 80], Step [100 / 500], Loss : 0.128420\n",
            "Epoch [60 / 80], Step [200 / 500], Loss : 0.221847\n",
            "Epoch [60 / 80], Step [300 / 500], Loss : 0.111611\n",
            "Epoch [60 / 80], Step [400 / 500], Loss : 0.185998\n",
            "Epoch [60 / 80], Step [500 / 500], Loss : 0.146765\n",
            "\n",
            "Test Set : Average Loss : 0.006123, Accuracy : 8374 / 10000 (84%)\n",
            "\n",
            "Epoch [61 / 80], Step [100 / 500], Loss : 0.157642\n",
            "Epoch [61 / 80], Step [200 / 500], Loss : 0.193020\n",
            "Epoch [61 / 80], Step [300 / 500], Loss : 0.100632\n",
            "Epoch [61 / 80], Step [400 / 500], Loss : 0.210131\n",
            "Epoch [61 / 80], Step [500 / 500], Loss : 0.105564\n",
            "\n",
            "Test Set : Average Loss : 0.006067, Accuracy : 8389 / 10000 (84%)\n",
            "\n",
            "Epoch [62 / 80], Step [100 / 500], Loss : 0.121325\n",
            "Epoch [62 / 80], Step [200 / 500], Loss : 0.276651\n",
            "Epoch [62 / 80], Step [300 / 500], Loss : 0.100877\n",
            "Epoch [62 / 80], Step [400 / 500], Loss : 0.190050\n",
            "Epoch [62 / 80], Step [500 / 500], Loss : 0.119883\n",
            "\n",
            "Test Set : Average Loss : 0.006104, Accuracy : 8424 / 10000 (84%)\n",
            "\n",
            "Epoch [63 / 80], Step [100 / 500], Loss : 0.120116\n",
            "Epoch [63 / 80], Step [200 / 500], Loss : 0.123185\n",
            "Epoch [63 / 80], Step [300 / 500], Loss : 0.195926\n",
            "Epoch [63 / 80], Step [400 / 500], Loss : 0.233403\n",
            "Epoch [63 / 80], Step [500 / 500], Loss : 0.133792\n",
            "\n",
            "Test Set : Average Loss : 0.006257, Accuracy : 8365 / 10000 (84%)\n",
            "\n",
            "Epoch [64 / 80], Step [100 / 500], Loss : 0.159424\n",
            "Epoch [64 / 80], Step [200 / 500], Loss : 0.120207\n",
            "Epoch [64 / 80], Step [300 / 500], Loss : 0.151548\n",
            "Epoch [64 / 80], Step [400 / 500], Loss : 0.105128\n",
            "Epoch [64 / 80], Step [500 / 500], Loss : 0.142296\n",
            "\n",
            "Test Set : Average Loss : 0.006094, Accuracy : 8412 / 10000 (84%)\n",
            "\n",
            "Epoch [65 / 80], Step [100 / 500], Loss : 0.170679\n",
            "Epoch [65 / 80], Step [200 / 500], Loss : 0.111773\n",
            "Epoch [65 / 80], Step [300 / 500], Loss : 0.115170\n",
            "Epoch [65 / 80], Step [400 / 500], Loss : 0.173875\n",
            "Epoch [65 / 80], Step [500 / 500], Loss : 0.198789\n",
            "\n",
            "Test Set : Average Loss : 0.006141, Accuracy : 8412 / 10000 (84%)\n",
            "\n",
            "Epoch [66 / 80], Step [100 / 500], Loss : 0.152783\n",
            "Epoch [66 / 80], Step [200 / 500], Loss : 0.087238\n",
            "Epoch [66 / 80], Step [300 / 500], Loss : 0.087742\n",
            "Epoch [66 / 80], Step [400 / 500], Loss : 0.218053\n",
            "Epoch [66 / 80], Step [500 / 500], Loss : 0.141913\n",
            "\n",
            "Test Set : Average Loss : 0.006311, Accuracy : 8363 / 10000 (84%)\n",
            "\n",
            "Epoch [67 / 80], Step [100 / 500], Loss : 0.156134\n",
            "Epoch [67 / 80], Step [200 / 500], Loss : 0.170147\n",
            "Epoch [67 / 80], Step [300 / 500], Loss : 0.173984\n",
            "Epoch [67 / 80], Step [400 / 500], Loss : 0.253028\n",
            "Epoch [67 / 80], Step [500 / 500], Loss : 0.138158\n",
            "\n",
            "Test Set : Average Loss : 0.006184, Accuracy : 8376 / 10000 (84%)\n",
            "\n",
            "Epoch [68 / 80], Step [100 / 500], Loss : 0.132650\n",
            "Epoch [68 / 80], Step [200 / 500], Loss : 0.150057\n",
            "Epoch [68 / 80], Step [300 / 500], Loss : 0.108490\n",
            "Epoch [68 / 80], Step [400 / 500], Loss : 0.179349\n",
            "Epoch [68 / 80], Step [500 / 500], Loss : 0.263114\n",
            "\n",
            "Test Set : Average Loss : 0.006296, Accuracy : 8398 / 10000 (84%)\n",
            "\n",
            "Epoch [69 / 80], Step [100 / 500], Loss : 0.118917\n",
            "Epoch [69 / 80], Step [200 / 500], Loss : 0.136527\n",
            "Epoch [69 / 80], Step [300 / 500], Loss : 0.186551\n",
            "Epoch [69 / 80], Step [400 / 500], Loss : 0.101546\n",
            "Epoch [69 / 80], Step [500 / 500], Loss : 0.143539\n",
            "\n",
            "Test Set : Average Loss : 0.006190, Accuracy : 8406 / 10000 (84%)\n",
            "\n",
            "Epoch [70 / 80], Step [100 / 500], Loss : 0.102488\n",
            "Epoch [70 / 80], Step [200 / 500], Loss : 0.096798\n",
            "Epoch [70 / 80], Step [300 / 500], Loss : 0.152712\n",
            "Epoch [70 / 80], Step [400 / 500], Loss : 0.070304\n",
            "Epoch [70 / 80], Step [500 / 500], Loss : 0.096715\n",
            "\n",
            "Test Set : Average Loss : 0.006425, Accuracy : 8393 / 10000 (84%)\n",
            "\n",
            "Epoch [71 / 80], Step [100 / 500], Loss : 0.166568\n",
            "Epoch [71 / 80], Step [200 / 500], Loss : 0.158022\n",
            "Epoch [71 / 80], Step [300 / 500], Loss : 0.098839\n",
            "Epoch [71 / 80], Step [400 / 500], Loss : 0.078889\n",
            "Epoch [71 / 80], Step [500 / 500], Loss : 0.156844\n",
            "\n",
            "Test Set : Average Loss : 0.006468, Accuracy : 8397 / 10000 (84%)\n",
            "\n",
            "Epoch [72 / 80], Step [100 / 500], Loss : 0.208835\n",
            "Epoch [72 / 80], Step [200 / 500], Loss : 0.251046\n",
            "Epoch [72 / 80], Step [300 / 500], Loss : 0.077092\n",
            "Epoch [72 / 80], Step [400 / 500], Loss : 0.179939\n",
            "Epoch [72 / 80], Step [500 / 500], Loss : 0.110403\n",
            "\n",
            "Test Set : Average Loss : 0.006661, Accuracy : 8364 / 10000 (84%)\n",
            "\n",
            "Epoch [73 / 80], Step [100 / 500], Loss : 0.089224\n",
            "Epoch [73 / 80], Step [200 / 500], Loss : 0.159679\n",
            "Epoch [73 / 80], Step [300 / 500], Loss : 0.144803\n",
            "Epoch [73 / 80], Step [400 / 500], Loss : 0.142780\n",
            "Epoch [73 / 80], Step [500 / 500], Loss : 0.132685\n",
            "\n",
            "Test Set : Average Loss : 0.006487, Accuracy : 8402 / 10000 (84%)\n",
            "\n",
            "Epoch [74 / 80], Step [100 / 500], Loss : 0.309376\n",
            "Epoch [74 / 80], Step [200 / 500], Loss : 0.143959\n",
            "Epoch [74 / 80], Step [300 / 500], Loss : 0.174725\n",
            "Epoch [74 / 80], Step [400 / 500], Loss : 0.062715\n",
            "Epoch [74 / 80], Step [500 / 500], Loss : 0.115793\n",
            "\n",
            "Test Set : Average Loss : 0.006447, Accuracy : 8385 / 10000 (84%)\n",
            "\n",
            "Epoch [75 / 80], Step [100 / 500], Loss : 0.074964\n",
            "Epoch [75 / 80], Step [200 / 500], Loss : 0.121250\n",
            "Epoch [75 / 80], Step [300 / 500], Loss : 0.198491\n",
            "Epoch [75 / 80], Step [400 / 500], Loss : 0.052545\n",
            "Epoch [75 / 80], Step [500 / 500], Loss : 0.101618\n",
            "\n",
            "Test Set : Average Loss : 0.006518, Accuracy : 8421 / 10000 (84%)\n",
            "\n",
            "Epoch [76 / 80], Step [100 / 500], Loss : 0.097480\n",
            "Epoch [76 / 80], Step [200 / 500], Loss : 0.157278\n",
            "Epoch [76 / 80], Step [300 / 500], Loss : 0.190647\n",
            "Epoch [76 / 80], Step [400 / 500], Loss : 0.137200\n",
            "Epoch [76 / 80], Step [500 / 500], Loss : 0.126048\n",
            "\n",
            "Test Set : Average Loss : 0.006571, Accuracy : 8417 / 10000 (84%)\n",
            "\n",
            "Epoch [77 / 80], Step [100 / 500], Loss : 0.219880\n",
            "Epoch [77 / 80], Step [200 / 500], Loss : 0.160858\n",
            "Epoch [77 / 80], Step [300 / 500], Loss : 0.065701\n",
            "Epoch [77 / 80], Step [400 / 500], Loss : 0.111862\n",
            "Epoch [77 / 80], Step [500 / 500], Loss : 0.152156\n",
            "\n",
            "Test Set : Average Loss : 0.006631, Accuracy : 8395 / 10000 (84%)\n",
            "\n",
            "Epoch [78 / 80], Step [100 / 500], Loss : 0.063349\n",
            "Epoch [78 / 80], Step [200 / 500], Loss : 0.090543\n",
            "Epoch [78 / 80], Step [300 / 500], Loss : 0.048955\n",
            "Epoch [78 / 80], Step [400 / 500], Loss : 0.090282\n",
            "Epoch [78 / 80], Step [500 / 500], Loss : 0.116557\n",
            "\n",
            "Test Set : Average Loss : 0.006736, Accuracy : 8400 / 10000 (84%)\n",
            "\n",
            "Epoch [79 / 80], Step [100 / 500], Loss : 0.095295\n",
            "Epoch [79 / 80], Step [200 / 500], Loss : 0.084886\n",
            "Epoch [79 / 80], Step [300 / 500], Loss : 0.123472\n",
            "Epoch [79 / 80], Step [400 / 500], Loss : 0.185878\n",
            "Epoch [79 / 80], Step [500 / 500], Loss : 0.119697\n",
            "\n",
            "Test Set : Average Loss : 0.006815, Accuracy : 8404 / 10000 (84%)\n",
            "\n",
            "Epoch [80 / 80], Step [100 / 500], Loss : 0.046326\n",
            "Epoch [80 / 80], Step [200 / 500], Loss : 0.070283\n",
            "Epoch [80 / 80], Step [300 / 500], Loss : 0.092133\n",
            "Epoch [80 / 80], Step [400 / 500], Loss : 0.132720\n",
            "Epoch [80 / 80], Step [500 / 500], Loss : 0.099971\n",
            "\n",
            "Test Set : Average Loss : 0.006831, Accuracy : 8393 / 10000 (84%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1 - 4\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes = 10, init_weights = True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels = 64\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n",
        "        nn.GroupNorm(32, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "    )\n",
        "\n",
        "    self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "    self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "    self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "    self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    if init_weights:\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "     strides = [stride] + [1] * (num_blocks - 1)\n",
        "     layers = []\n",
        "     for stride in strides:\n",
        "       layers.append(block(self.in_channels, out_channels, stride))\n",
        "       self.in_channels = out_channels * block.expansion\n",
        "\n",
        "     return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x = self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode = 'fan_out', nonlinearity = 'relu')\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "          nn.init.constant_(m.weight, 1)\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "          nn.init.normal_(m.weight, 0, 0.01)\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "\n",
        "model = ResNet(BasicBlock, [2, 2, 2, 2]).cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range (0, num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaRI0AR90w17",
        "outputId": "d26a5ada-f6bd-4bd6-d1fe-44d30e4085b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 80], Step [100 / 500], Loss : 1.765405\n",
            "Epoch [1 / 80], Step [200 / 500], Loss : 1.435027\n",
            "Epoch [1 / 80], Step [300 / 500], Loss : 1.541980\n",
            "Epoch [1 / 80], Step [400 / 500], Loss : 1.283082\n",
            "Epoch [1 / 80], Step [500 / 500], Loss : 1.523031\n",
            "\n",
            "Test Set : Average Loss : 0.016112, Accuracy : 4534 / 10000 (45%)\n",
            "\n",
            "Epoch [2 / 80], Step [100 / 500], Loss : 1.319729\n",
            "Epoch [2 / 80], Step [200 / 500], Loss : 1.140185\n",
            "Epoch [2 / 80], Step [300 / 500], Loss : 1.347153\n",
            "Epoch [2 / 80], Step [400 / 500], Loss : 1.125389\n",
            "Epoch [2 / 80], Step [500 / 500], Loss : 1.439319\n",
            "\n",
            "Test Set : Average Loss : 0.015314, Accuracy : 5087 / 10000 (51%)\n",
            "\n",
            "Epoch [3 / 80], Step [100 / 500], Loss : 1.055007\n",
            "Epoch [3 / 80], Step [200 / 500], Loss : 1.063038\n",
            "Epoch [3 / 80], Step [300 / 500], Loss : 0.974091\n",
            "Epoch [3 / 80], Step [400 / 500], Loss : 1.159192\n",
            "Epoch [3 / 80], Step [500 / 500], Loss : 1.142780\n",
            "\n",
            "Test Set : Average Loss : 0.013272, Accuracy : 5523 / 10000 (55%)\n",
            "\n",
            "Epoch [4 / 80], Step [100 / 500], Loss : 0.916343\n",
            "Epoch [4 / 80], Step [200 / 500], Loss : 0.854946\n",
            "Epoch [4 / 80], Step [300 / 500], Loss : 1.119967\n",
            "Epoch [4 / 80], Step [400 / 500], Loss : 0.819366\n",
            "Epoch [4 / 80], Step [500 / 500], Loss : 0.948691\n",
            "\n",
            "Test Set : Average Loss : 0.009793, Accuracy : 6637 / 10000 (66%)\n",
            "\n",
            "Epoch [5 / 80], Step [100 / 500], Loss : 0.904805\n",
            "Epoch [5 / 80], Step [200 / 500], Loss : 0.875789\n",
            "Epoch [5 / 80], Step [300 / 500], Loss : 0.795808\n",
            "Epoch [5 / 80], Step [400 / 500], Loss : 0.780854\n",
            "Epoch [5 / 80], Step [500 / 500], Loss : 0.686340\n",
            "\n",
            "Test Set : Average Loss : 0.010642, Accuracy : 6504 / 10000 (65%)\n",
            "\n",
            "Epoch [6 / 80], Step [100 / 500], Loss : 0.772616\n",
            "Epoch [6 / 80], Step [200 / 500], Loss : 0.851560\n",
            "Epoch [6 / 80], Step [300 / 500], Loss : 0.704438\n",
            "Epoch [6 / 80], Step [400 / 500], Loss : 0.705379\n",
            "Epoch [6 / 80], Step [500 / 500], Loss : 0.956711\n",
            "\n",
            "Test Set : Average Loss : 0.011716, Accuracy : 6266 / 10000 (63%)\n",
            "\n",
            "Epoch [7 / 80], Step [100 / 500], Loss : 0.800313\n",
            "Epoch [7 / 80], Step [200 / 500], Loss : 0.829274\n",
            "Epoch [7 / 80], Step [300 / 500], Loss : 0.796394\n",
            "Epoch [7 / 80], Step [400 / 500], Loss : 0.727488\n",
            "Epoch [7 / 80], Step [500 / 500], Loss : 0.807553\n",
            "\n",
            "Test Set : Average Loss : 0.007989, Accuracy : 7264 / 10000 (73%)\n",
            "\n",
            "Epoch [8 / 80], Step [100 / 500], Loss : 0.864071\n",
            "Epoch [8 / 80], Step [200 / 500], Loss : 0.661044\n",
            "Epoch [8 / 80], Step [300 / 500], Loss : 0.809871\n",
            "Epoch [8 / 80], Step [400 / 500], Loss : 0.846002\n",
            "Epoch [8 / 80], Step [500 / 500], Loss : 0.745413\n",
            "\n",
            "Test Set : Average Loss : 0.009617, Accuracy : 6821 / 10000 (68%)\n",
            "\n",
            "Epoch [9 / 80], Step [100 / 500], Loss : 0.713429\n",
            "Epoch [9 / 80], Step [200 / 500], Loss : 0.753952\n",
            "Epoch [9 / 80], Step [300 / 500], Loss : 0.708836\n",
            "Epoch [9 / 80], Step [400 / 500], Loss : 0.598532\n",
            "Epoch [9 / 80], Step [500 / 500], Loss : 0.680966\n",
            "\n",
            "Test Set : Average Loss : 0.008587, Accuracy : 6987 / 10000 (70%)\n",
            "\n",
            "Epoch [10 / 80], Step [100 / 500], Loss : 0.492261\n",
            "Epoch [10 / 80], Step [200 / 500], Loss : 0.662722\n",
            "Epoch [10 / 80], Step [300 / 500], Loss : 0.821617\n",
            "Epoch [10 / 80], Step [400 / 500], Loss : 0.639561\n",
            "Epoch [10 / 80], Step [500 / 500], Loss : 0.584721\n",
            "\n",
            "Test Set : Average Loss : 0.008292, Accuracy : 7152 / 10000 (72%)\n",
            "\n",
            "Epoch [11 / 80], Step [100 / 500], Loss : 0.595811\n",
            "Epoch [11 / 80], Step [200 / 500], Loss : 0.586195\n",
            "Epoch [11 / 80], Step [300 / 500], Loss : 0.705803\n",
            "Epoch [11 / 80], Step [400 / 500], Loss : 0.764360\n",
            "Epoch [11 / 80], Step [500 / 500], Loss : 0.770405\n",
            "\n",
            "Test Set : Average Loss : 0.007656, Accuracy : 7400 / 10000 (74%)\n",
            "\n",
            "Epoch [12 / 80], Step [100 / 500], Loss : 0.772219\n",
            "Epoch [12 / 80], Step [200 / 500], Loss : 0.676497\n",
            "Epoch [12 / 80], Step [300 / 500], Loss : 0.568866\n",
            "Epoch [12 / 80], Step [400 / 500], Loss : 0.560298\n",
            "Epoch [12 / 80], Step [500 / 500], Loss : 0.565164\n",
            "\n",
            "Test Set : Average Loss : 0.006912, Accuracy : 7622 / 10000 (76%)\n",
            "\n",
            "Epoch [13 / 80], Step [100 / 500], Loss : 0.627106\n",
            "Epoch [13 / 80], Step [200 / 500], Loss : 0.548396\n",
            "Epoch [13 / 80], Step [300 / 500], Loss : 0.777658\n",
            "Epoch [13 / 80], Step [400 / 500], Loss : 0.524360\n",
            "Epoch [13 / 80], Step [500 / 500], Loss : 0.601919\n",
            "\n",
            "Test Set : Average Loss : 0.006458, Accuracy : 7792 / 10000 (78%)\n",
            "\n",
            "Epoch [14 / 80], Step [100 / 500], Loss : 0.594783\n",
            "Epoch [14 / 80], Step [200 / 500], Loss : 0.592780\n",
            "Epoch [14 / 80], Step [300 / 500], Loss : 0.638316\n",
            "Epoch [14 / 80], Step [400 / 500], Loss : 0.703355\n",
            "Epoch [14 / 80], Step [500 / 500], Loss : 0.725395\n",
            "\n",
            "Test Set : Average Loss : 0.007172, Accuracy : 7586 / 10000 (76%)\n",
            "\n",
            "Epoch [15 / 80], Step [100 / 500], Loss : 0.511503\n",
            "Epoch [15 / 80], Step [200 / 500], Loss : 0.445412\n",
            "Epoch [15 / 80], Step [300 / 500], Loss : 0.524565\n",
            "Epoch [15 / 80], Step [400 / 500], Loss : 0.562690\n",
            "Epoch [15 / 80], Step [500 / 500], Loss : 0.722951\n",
            "\n",
            "Test Set : Average Loss : 0.006364, Accuracy : 7839 / 10000 (78%)\n",
            "\n",
            "Epoch [16 / 80], Step [100 / 500], Loss : 0.463666\n",
            "Epoch [16 / 80], Step [200 / 500], Loss : 0.571481\n",
            "Epoch [16 / 80], Step [300 / 500], Loss : 0.669176\n",
            "Epoch [16 / 80], Step [400 / 500], Loss : 0.673575\n",
            "Epoch [16 / 80], Step [500 / 500], Loss : 0.529772\n",
            "\n",
            "Test Set : Average Loss : 0.006269, Accuracy : 7847 / 10000 (78%)\n",
            "\n",
            "Epoch [17 / 80], Step [100 / 500], Loss : 0.596056\n",
            "Epoch [17 / 80], Step [200 / 500], Loss : 0.483557\n",
            "Epoch [17 / 80], Step [300 / 500], Loss : 0.450878\n",
            "Epoch [17 / 80], Step [400 / 500], Loss : 0.662074\n",
            "Epoch [17 / 80], Step [500 / 500], Loss : 0.445229\n",
            "\n",
            "Test Set : Average Loss : 0.006356, Accuracy : 7875 / 10000 (79%)\n",
            "\n",
            "Epoch [18 / 80], Step [100 / 500], Loss : 0.322656\n",
            "Epoch [18 / 80], Step [200 / 500], Loss : 0.499986\n",
            "Epoch [18 / 80], Step [300 / 500], Loss : 0.523048\n",
            "Epoch [18 / 80], Step [400 / 500], Loss : 0.424814\n",
            "Epoch [18 / 80], Step [500 / 500], Loss : 0.413021\n",
            "\n",
            "Test Set : Average Loss : 0.006497, Accuracy : 7889 / 10000 (79%)\n",
            "\n",
            "Epoch [19 / 80], Step [100 / 500], Loss : 0.413689\n",
            "Epoch [19 / 80], Step [200 / 500], Loss : 0.429410\n",
            "Epoch [19 / 80], Step [300 / 500], Loss : 0.561922\n",
            "Epoch [19 / 80], Step [400 / 500], Loss : 0.327448\n",
            "Epoch [19 / 80], Step [500 / 500], Loss : 0.436322\n",
            "\n",
            "Test Set : Average Loss : 0.007061, Accuracy : 7722 / 10000 (77%)\n",
            "\n",
            "Epoch [20 / 80], Step [100 / 500], Loss : 0.344213\n",
            "Epoch [20 / 80], Step [200 / 500], Loss : 0.644598\n",
            "Epoch [20 / 80], Step [300 / 500], Loss : 0.313216\n",
            "Epoch [20 / 80], Step [400 / 500], Loss : 0.605005\n",
            "Epoch [20 / 80], Step [500 / 500], Loss : 0.480389\n",
            "\n",
            "Test Set : Average Loss : 0.005793, Accuracy : 8061 / 10000 (81%)\n",
            "\n",
            "Epoch [21 / 80], Step [100 / 500], Loss : 0.443738\n",
            "Epoch [21 / 80], Step [200 / 500], Loss : 0.433677\n",
            "Epoch [21 / 80], Step [300 / 500], Loss : 0.440964\n",
            "Epoch [21 / 80], Step [400 / 500], Loss : 0.461478\n",
            "Epoch [21 / 80], Step [500 / 500], Loss : 0.356808\n",
            "\n",
            "Test Set : Average Loss : 0.005143, Accuracy : 8323 / 10000 (83%)\n",
            "\n",
            "Epoch [22 / 80], Step [100 / 500], Loss : 0.356198\n",
            "Epoch [22 / 80], Step [200 / 500], Loss : 0.394844\n",
            "Epoch [22 / 80], Step [300 / 500], Loss : 0.375142\n",
            "Epoch [22 / 80], Step [400 / 500], Loss : 0.269491\n",
            "Epoch [22 / 80], Step [500 / 500], Loss : 0.331910\n",
            "\n",
            "Test Set : Average Loss : 0.005168, Accuracy : 8258 / 10000 (83%)\n",
            "\n",
            "Epoch [23 / 80], Step [100 / 500], Loss : 0.344281\n",
            "Epoch [23 / 80], Step [200 / 500], Loss : 0.381868\n",
            "Epoch [23 / 80], Step [300 / 500], Loss : 0.386422\n",
            "Epoch [23 / 80], Step [400 / 500], Loss : 0.352031\n",
            "Epoch [23 / 80], Step [500 / 500], Loss : 0.542236\n",
            "\n",
            "Test Set : Average Loss : 0.005098, Accuracy : 8317 / 10000 (83%)\n",
            "\n",
            "Epoch [24 / 80], Step [100 / 500], Loss : 0.447090\n",
            "Epoch [24 / 80], Step [200 / 500], Loss : 0.370540\n",
            "Epoch [24 / 80], Step [300 / 500], Loss : 0.356010\n",
            "Epoch [24 / 80], Step [400 / 500], Loss : 0.580494\n",
            "Epoch [24 / 80], Step [500 / 500], Loss : 0.307399\n",
            "\n",
            "Test Set : Average Loss : 0.005047, Accuracy : 8320 / 10000 (83%)\n",
            "\n",
            "Epoch [25 / 80], Step [100 / 500], Loss : 0.393267\n",
            "Epoch [25 / 80], Step [200 / 500], Loss : 0.308360\n",
            "Epoch [25 / 80], Step [300 / 500], Loss : 0.237532\n",
            "Epoch [25 / 80], Step [400 / 500], Loss : 0.301164\n",
            "Epoch [25 / 80], Step [500 / 500], Loss : 0.352785\n",
            "\n",
            "Test Set : Average Loss : 0.005245, Accuracy : 8306 / 10000 (83%)\n",
            "\n",
            "Epoch [26 / 80], Step [100 / 500], Loss : 0.354255\n",
            "Epoch [26 / 80], Step [200 / 500], Loss : 0.278365\n",
            "Epoch [26 / 80], Step [300 / 500], Loss : 0.261411\n",
            "Epoch [26 / 80], Step [400 / 500], Loss : 0.320871\n",
            "Epoch [26 / 80], Step [500 / 500], Loss : 0.307173\n",
            "\n",
            "Test Set : Average Loss : 0.005118, Accuracy : 8366 / 10000 (84%)\n",
            "\n",
            "Epoch [27 / 80], Step [100 / 500], Loss : 0.281462\n",
            "Epoch [27 / 80], Step [200 / 500], Loss : 0.317833\n",
            "Epoch [27 / 80], Step [300 / 500], Loss : 0.282780\n",
            "Epoch [27 / 80], Step [400 / 500], Loss : 0.247706\n",
            "Epoch [27 / 80], Step [500 / 500], Loss : 0.444238\n",
            "\n",
            "Test Set : Average Loss : 0.004965, Accuracy : 8405 / 10000 (84%)\n",
            "\n",
            "Epoch [28 / 80], Step [100 / 500], Loss : 0.456104\n",
            "Epoch [28 / 80], Step [200 / 500], Loss : 0.320347\n",
            "Epoch [28 / 80], Step [300 / 500], Loss : 0.258710\n",
            "Epoch [28 / 80], Step [400 / 500], Loss : 0.384272\n",
            "Epoch [28 / 80], Step [500 / 500], Loss : 0.412020\n",
            "\n",
            "Test Set : Average Loss : 0.005144, Accuracy : 8365 / 10000 (84%)\n",
            "\n",
            "Epoch [29 / 80], Step [100 / 500], Loss : 0.284939\n",
            "Epoch [29 / 80], Step [200 / 500], Loss : 0.358704\n",
            "Epoch [29 / 80], Step [300 / 500], Loss : 0.310613\n",
            "Epoch [29 / 80], Step [400 / 500], Loss : 0.426007\n",
            "Epoch [29 / 80], Step [500 / 500], Loss : 0.314365\n",
            "\n",
            "Test Set : Average Loss : 0.005188, Accuracy : 8321 / 10000 (83%)\n",
            "\n",
            "Epoch [30 / 80], Step [100 / 500], Loss : 0.231298\n",
            "Epoch [30 / 80], Step [200 / 500], Loss : 0.242582\n",
            "Epoch [30 / 80], Step [300 / 500], Loss : 0.334550\n",
            "Epoch [30 / 80], Step [400 / 500], Loss : 0.269354\n",
            "Epoch [30 / 80], Step [500 / 500], Loss : 0.239675\n",
            "\n",
            "Test Set : Average Loss : 0.005336, Accuracy : 8331 / 10000 (83%)\n",
            "\n",
            "Epoch [31 / 80], Step [100 / 500], Loss : 0.335626\n",
            "Epoch [31 / 80], Step [200 / 500], Loss : 0.273522\n",
            "Epoch [31 / 80], Step [300 / 500], Loss : 0.353983\n",
            "Epoch [31 / 80], Step [400 / 500], Loss : 0.295528\n",
            "Epoch [31 / 80], Step [500 / 500], Loss : 0.377251\n",
            "\n",
            "Test Set : Average Loss : 0.005448, Accuracy : 8304 / 10000 (83%)\n",
            "\n",
            "Epoch [32 / 80], Step [100 / 500], Loss : 0.323272\n",
            "Epoch [32 / 80], Step [200 / 500], Loss : 0.149625\n",
            "Epoch [32 / 80], Step [300 / 500], Loss : 0.378522\n",
            "Epoch [32 / 80], Step [400 / 500], Loss : 0.296317\n",
            "Epoch [32 / 80], Step [500 / 500], Loss : 0.238459\n",
            "\n",
            "Test Set : Average Loss : 0.005257, Accuracy : 8364 / 10000 (84%)\n",
            "\n",
            "Epoch [33 / 80], Step [100 / 500], Loss : 0.173830\n",
            "Epoch [33 / 80], Step [200 / 500], Loss : 0.185714\n",
            "Epoch [33 / 80], Step [300 / 500], Loss : 0.349461\n",
            "Epoch [33 / 80], Step [400 / 500], Loss : 0.183009\n",
            "Epoch [33 / 80], Step [500 / 500], Loss : 0.340972\n",
            "\n",
            "Test Set : Average Loss : 0.005404, Accuracy : 8342 / 10000 (83%)\n",
            "\n",
            "Epoch [34 / 80], Step [100 / 500], Loss : 0.264310\n",
            "Epoch [34 / 80], Step [200 / 500], Loss : 0.237844\n",
            "Epoch [34 / 80], Step [300 / 500], Loss : 0.200998\n",
            "Epoch [34 / 80], Step [400 / 500], Loss : 0.205378\n",
            "Epoch [34 / 80], Step [500 / 500], Loss : 0.336502\n",
            "\n",
            "Test Set : Average Loss : 0.005221, Accuracy : 8392 / 10000 (84%)\n",
            "\n",
            "Epoch [35 / 80], Step [100 / 500], Loss : 0.349116\n",
            "Epoch [35 / 80], Step [200 / 500], Loss : 0.232044\n",
            "Epoch [35 / 80], Step [300 / 500], Loss : 0.301348\n",
            "Epoch [35 / 80], Step [400 / 500], Loss : 0.252945\n",
            "Epoch [35 / 80], Step [500 / 500], Loss : 0.234778\n",
            "\n",
            "Test Set : Average Loss : 0.005311, Accuracy : 8407 / 10000 (84%)\n",
            "\n",
            "Epoch [36 / 80], Step [100 / 500], Loss : 0.315369\n",
            "Epoch [36 / 80], Step [200 / 500], Loss : 0.333798\n",
            "Epoch [36 / 80], Step [300 / 500], Loss : 0.234685\n",
            "Epoch [36 / 80], Step [400 / 500], Loss : 0.166789\n",
            "Epoch [36 / 80], Step [500 / 500], Loss : 0.237010\n",
            "\n",
            "Test Set : Average Loss : 0.005583, Accuracy : 8341 / 10000 (83%)\n",
            "\n",
            "Epoch [37 / 80], Step [100 / 500], Loss : 0.353531\n",
            "Epoch [37 / 80], Step [200 / 500], Loss : 0.226498\n",
            "Epoch [37 / 80], Step [300 / 500], Loss : 0.287824\n",
            "Epoch [37 / 80], Step [400 / 500], Loss : 0.383821\n",
            "Epoch [37 / 80], Step [500 / 500], Loss : 0.133488\n",
            "\n",
            "Test Set : Average Loss : 0.005451, Accuracy : 8365 / 10000 (84%)\n",
            "\n",
            "Epoch [38 / 80], Step [100 / 500], Loss : 0.187143\n",
            "Epoch [38 / 80], Step [200 / 500], Loss : 0.379827\n",
            "Epoch [38 / 80], Step [300 / 500], Loss : 0.334808\n",
            "Epoch [38 / 80], Step [400 / 500], Loss : 0.234190\n",
            "Epoch [38 / 80], Step [500 / 500], Loss : 0.380137\n",
            "\n",
            "Test Set : Average Loss : 0.005226, Accuracy : 8430 / 10000 (84%)\n",
            "\n",
            "Epoch [39 / 80], Step [100 / 500], Loss : 0.241875\n",
            "Epoch [39 / 80], Step [200 / 500], Loss : 0.236766\n",
            "Epoch [39 / 80], Step [300 / 500], Loss : 0.218873\n",
            "Epoch [39 / 80], Step [400 / 500], Loss : 0.287610\n",
            "Epoch [39 / 80], Step [500 / 500], Loss : 0.258343\n",
            "\n",
            "Test Set : Average Loss : 0.005357, Accuracy : 8417 / 10000 (84%)\n",
            "\n",
            "Epoch [40 / 80], Step [100 / 500], Loss : 0.113981\n",
            "Epoch [40 / 80], Step [200 / 500], Loss : 0.215056\n",
            "Epoch [40 / 80], Step [300 / 500], Loss : 0.164507\n",
            "Epoch [40 / 80], Step [400 / 500], Loss : 0.226491\n",
            "Epoch [40 / 80], Step [500 / 500], Loss : 0.186445\n",
            "\n",
            "Test Set : Average Loss : 0.005400, Accuracy : 8409 / 10000 (84%)\n",
            "\n",
            "Epoch [41 / 80], Step [100 / 500], Loss : 0.212317\n",
            "Epoch [41 / 80], Step [200 / 500], Loss : 0.265956\n",
            "Epoch [41 / 80], Step [300 / 500], Loss : 0.257917\n",
            "Epoch [41 / 80], Step [400 / 500], Loss : 0.250313\n",
            "Epoch [41 / 80], Step [500 / 500], Loss : 0.254389\n",
            "\n",
            "Test Set : Average Loss : 0.005646, Accuracy : 8309 / 10000 (83%)\n",
            "\n",
            "Epoch [42 / 80], Step [100 / 500], Loss : 0.138617\n",
            "Epoch [42 / 80], Step [200 / 500], Loss : 0.317415\n",
            "Epoch [42 / 80], Step [300 / 500], Loss : 0.180922\n",
            "Epoch [42 / 80], Step [400 / 500], Loss : 0.268651\n",
            "Epoch [42 / 80], Step [500 / 500], Loss : 0.201797\n",
            "\n",
            "Test Set : Average Loss : 0.005810, Accuracy : 8322 / 10000 (83%)\n",
            "\n",
            "Epoch [43 / 80], Step [100 / 500], Loss : 0.162961\n",
            "Epoch [43 / 80], Step [200 / 500], Loss : 0.223461\n",
            "Epoch [43 / 80], Step [300 / 500], Loss : 0.208055\n",
            "Epoch [43 / 80], Step [400 / 500], Loss : 0.114566\n",
            "Epoch [43 / 80], Step [500 / 500], Loss : 0.330869\n",
            "\n",
            "Test Set : Average Loss : 0.005473, Accuracy : 8398 / 10000 (84%)\n",
            "\n",
            "Epoch [44 / 80], Step [100 / 500], Loss : 0.308893\n",
            "Epoch [44 / 80], Step [200 / 500], Loss : 0.210155\n",
            "Epoch [44 / 80], Step [300 / 500], Loss : 0.191759\n",
            "Epoch [44 / 80], Step [400 / 500], Loss : 0.331842\n",
            "Epoch [44 / 80], Step [500 / 500], Loss : 0.309755\n",
            "\n",
            "Test Set : Average Loss : 0.005801, Accuracy : 8382 / 10000 (84%)\n",
            "\n",
            "Epoch [45 / 80], Step [100 / 500], Loss : 0.301756\n",
            "Epoch [45 / 80], Step [200 / 500], Loss : 0.227259\n",
            "Epoch [45 / 80], Step [300 / 500], Loss : 0.202822\n",
            "Epoch [45 / 80], Step [400 / 500], Loss : 0.319539\n",
            "Epoch [45 / 80], Step [500 / 500], Loss : 0.283123\n",
            "\n",
            "Test Set : Average Loss : 0.005616, Accuracy : 8356 / 10000 (84%)\n",
            "\n",
            "Epoch [46 / 80], Step [100 / 500], Loss : 0.232184\n",
            "Epoch [46 / 80], Step [200 / 500], Loss : 0.145869\n",
            "Epoch [46 / 80], Step [300 / 500], Loss : 0.174106\n",
            "Epoch [46 / 80], Step [400 / 500], Loss : 0.255227\n",
            "Epoch [46 / 80], Step [500 / 500], Loss : 0.245363\n",
            "\n",
            "Test Set : Average Loss : 0.005808, Accuracy : 8355 / 10000 (84%)\n",
            "\n",
            "Epoch [47 / 80], Step [100 / 500], Loss : 0.236827\n",
            "Epoch [47 / 80], Step [200 / 500], Loss : 0.271861\n",
            "Epoch [47 / 80], Step [300 / 500], Loss : 0.246435\n",
            "Epoch [47 / 80], Step [400 / 500], Loss : 0.203187\n",
            "Epoch [47 / 80], Step [500 / 500], Loss : 0.276178\n",
            "\n",
            "Test Set : Average Loss : 0.005698, Accuracy : 8407 / 10000 (84%)\n",
            "\n",
            "Epoch [48 / 80], Step [100 / 500], Loss : 0.176910\n",
            "Epoch [48 / 80], Step [200 / 500], Loss : 0.252408\n",
            "Epoch [48 / 80], Step [300 / 500], Loss : 0.209544\n",
            "Epoch [48 / 80], Step [400 / 500], Loss : 0.287438\n",
            "Epoch [48 / 80], Step [500 / 500], Loss : 0.269981\n",
            "\n",
            "Test Set : Average Loss : 0.005746, Accuracy : 8429 / 10000 (84%)\n",
            "\n",
            "Epoch [49 / 80], Step [100 / 500], Loss : 0.205131\n",
            "Epoch [49 / 80], Step [200 / 500], Loss : 0.163013\n",
            "Epoch [49 / 80], Step [300 / 500], Loss : 0.291376\n",
            "Epoch [49 / 80], Step [400 / 500], Loss : 0.188461\n",
            "Epoch [49 / 80], Step [500 / 500], Loss : 0.267237\n",
            "\n",
            "Test Set : Average Loss : 0.005848, Accuracy : 8391 / 10000 (84%)\n",
            "\n",
            "Epoch [50 / 80], Step [100 / 500], Loss : 0.234042\n",
            "Epoch [50 / 80], Step [200 / 500], Loss : 0.275714\n",
            "Epoch [50 / 80], Step [300 / 500], Loss : 0.191129\n",
            "Epoch [50 / 80], Step [400 / 500], Loss : 0.247975\n",
            "Epoch [50 / 80], Step [500 / 500], Loss : 0.263178\n",
            "\n",
            "Test Set : Average Loss : 0.005746, Accuracy : 8410 / 10000 (84%)\n",
            "\n",
            "Epoch [51 / 80], Step [100 / 500], Loss : 0.193328\n",
            "Epoch [51 / 80], Step [200 / 500], Loss : 0.202289\n",
            "Epoch [51 / 80], Step [300 / 500], Loss : 0.108554\n",
            "Epoch [51 / 80], Step [400 / 500], Loss : 0.156627\n",
            "Epoch [51 / 80], Step [500 / 500], Loss : 0.231128\n",
            "\n",
            "Test Set : Average Loss : 0.005895, Accuracy : 8386 / 10000 (84%)\n",
            "\n",
            "Epoch [52 / 80], Step [100 / 500], Loss : 0.166811\n",
            "Epoch [52 / 80], Step [200 / 500], Loss : 0.188000\n",
            "Epoch [52 / 80], Step [300 / 500], Loss : 0.256644\n",
            "Epoch [52 / 80], Step [400 / 500], Loss : 0.094738\n",
            "Epoch [52 / 80], Step [500 / 500], Loss : 0.119497\n",
            "\n",
            "Test Set : Average Loss : 0.005774, Accuracy : 8364 / 10000 (84%)\n",
            "\n",
            "Epoch [53 / 80], Step [100 / 500], Loss : 0.238481\n",
            "Epoch [53 / 80], Step [200 / 500], Loss : 0.257989\n",
            "Epoch [53 / 80], Step [300 / 500], Loss : 0.096578\n",
            "Epoch [53 / 80], Step [400 / 500], Loss : 0.240447\n",
            "Epoch [53 / 80], Step [500 / 500], Loss : 0.227490\n",
            "\n",
            "Test Set : Average Loss : 0.006041, Accuracy : 8375 / 10000 (84%)\n",
            "\n",
            "Epoch [54 / 80], Step [100 / 500], Loss : 0.198951\n",
            "Epoch [54 / 80], Step [200 / 500], Loss : 0.177962\n",
            "Epoch [54 / 80], Step [300 / 500], Loss : 0.231612\n",
            "Epoch [54 / 80], Step [400 / 500], Loss : 0.164991\n",
            "Epoch [54 / 80], Step [500 / 500], Loss : 0.143629\n",
            "\n",
            "Test Set : Average Loss : 0.005959, Accuracy : 8373 / 10000 (84%)\n",
            "\n",
            "Epoch [55 / 80], Step [100 / 500], Loss : 0.208477\n",
            "Epoch [55 / 80], Step [200 / 500], Loss : 0.073868\n",
            "Epoch [55 / 80], Step [300 / 500], Loss : 0.208163\n",
            "Epoch [55 / 80], Step [400 / 500], Loss : 0.196371\n",
            "Epoch [55 / 80], Step [500 / 500], Loss : 0.137568\n",
            "\n",
            "Test Set : Average Loss : 0.005876, Accuracy : 8402 / 10000 (84%)\n",
            "\n",
            "Epoch [56 / 80], Step [100 / 500], Loss : 0.139884\n",
            "Epoch [56 / 80], Step [200 / 500], Loss : 0.216021\n",
            "Epoch [56 / 80], Step [300 / 500], Loss : 0.174422\n",
            "Epoch [56 / 80], Step [400 / 500], Loss : 0.200989\n",
            "Epoch [56 / 80], Step [500 / 500], Loss : 0.162261\n",
            "\n",
            "Test Set : Average Loss : 0.005952, Accuracy : 8376 / 10000 (84%)\n",
            "\n",
            "Epoch [57 / 80], Step [100 / 500], Loss : 0.143421\n",
            "Epoch [57 / 80], Step [200 / 500], Loss : 0.169412\n",
            "Epoch [57 / 80], Step [300 / 500], Loss : 0.126832\n",
            "Epoch [57 / 80], Step [400 / 500], Loss : 0.326200\n",
            "Epoch [57 / 80], Step [500 / 500], Loss : 0.131142\n",
            "\n",
            "Test Set : Average Loss : 0.006142, Accuracy : 8354 / 10000 (84%)\n",
            "\n",
            "Epoch [58 / 80], Step [100 / 500], Loss : 0.194877\n",
            "Epoch [58 / 80], Step [200 / 500], Loss : 0.164078\n",
            "Epoch [58 / 80], Step [300 / 500], Loss : 0.187927\n",
            "Epoch [58 / 80], Step [400 / 500], Loss : 0.198475\n",
            "Epoch [58 / 80], Step [500 / 500], Loss : 0.256170\n",
            "\n",
            "Test Set : Average Loss : 0.006158, Accuracy : 8368 / 10000 (84%)\n",
            "\n",
            "Epoch [59 / 80], Step [100 / 500], Loss : 0.203083\n",
            "Epoch [59 / 80], Step [200 / 500], Loss : 0.122141\n",
            "Epoch [59 / 80], Step [300 / 500], Loss : 0.067699\n",
            "Epoch [59 / 80], Step [400 / 500], Loss : 0.138468\n",
            "Epoch [59 / 80], Step [500 / 500], Loss : 0.212529\n",
            "\n",
            "Test Set : Average Loss : 0.006058, Accuracy : 8372 / 10000 (84%)\n",
            "\n",
            "Epoch [60 / 80], Step [100 / 500], Loss : 0.136503\n",
            "Epoch [60 / 80], Step [200 / 500], Loss : 0.220035\n",
            "Epoch [60 / 80], Step [300 / 500], Loss : 0.271389\n",
            "Epoch [60 / 80], Step [400 / 500], Loss : 0.232456\n",
            "Epoch [60 / 80], Step [500 / 500], Loss : 0.193057\n",
            "\n",
            "Test Set : Average Loss : 0.006063, Accuracy : 8431 / 10000 (84%)\n",
            "\n",
            "Epoch [61 / 80], Step [100 / 500], Loss : 0.147612\n",
            "Epoch [61 / 80], Step [200 / 500], Loss : 0.131328\n",
            "Epoch [61 / 80], Step [300 / 500], Loss : 0.152339\n",
            "Epoch [61 / 80], Step [400 / 500], Loss : 0.115863\n",
            "Epoch [61 / 80], Step [500 / 500], Loss : 0.112997\n",
            "\n",
            "Test Set : Average Loss : 0.006082, Accuracy : 8417 / 10000 (84%)\n",
            "\n",
            "Epoch [62 / 80], Step [100 / 500], Loss : 0.100675\n",
            "Epoch [62 / 80], Step [200 / 500], Loss : 0.083417\n",
            "Epoch [62 / 80], Step [300 / 500], Loss : 0.213039\n",
            "Epoch [62 / 80], Step [400 / 500], Loss : 0.288580\n",
            "Epoch [62 / 80], Step [500 / 500], Loss : 0.129716\n",
            "\n",
            "Test Set : Average Loss : 0.006169, Accuracy : 8410 / 10000 (84%)\n",
            "\n",
            "Epoch [63 / 80], Step [100 / 500], Loss : 0.166219\n",
            "Epoch [63 / 80], Step [200 / 500], Loss : 0.145937\n",
            "Epoch [63 / 80], Step [300 / 500], Loss : 0.141740\n",
            "Epoch [63 / 80], Step [400 / 500], Loss : 0.130751\n",
            "Epoch [63 / 80], Step [500 / 500], Loss : 0.184708\n",
            "\n",
            "Test Set : Average Loss : 0.006345, Accuracy : 8383 / 10000 (84%)\n",
            "\n",
            "Epoch [64 / 80], Step [100 / 500], Loss : 0.068192\n",
            "Epoch [64 / 80], Step [200 / 500], Loss : 0.150479\n",
            "Epoch [64 / 80], Step [300 / 500], Loss : 0.101422\n",
            "Epoch [64 / 80], Step [400 / 500], Loss : 0.145925\n",
            "Epoch [64 / 80], Step [500 / 500], Loss : 0.216289\n",
            "\n",
            "Test Set : Average Loss : 0.006370, Accuracy : 8411 / 10000 (84%)\n",
            "\n",
            "Epoch [65 / 80], Step [100 / 500], Loss : 0.158474\n",
            "Epoch [65 / 80], Step [200 / 500], Loss : 0.058240\n",
            "Epoch [65 / 80], Step [300 / 500], Loss : 0.240073\n",
            "Epoch [65 / 80], Step [400 / 500], Loss : 0.118292\n",
            "Epoch [65 / 80], Step [500 / 500], Loss : 0.106916\n",
            "\n",
            "Test Set : Average Loss : 0.006384, Accuracy : 8354 / 10000 (84%)\n",
            "\n",
            "Epoch [66 / 80], Step [100 / 500], Loss : 0.075341\n",
            "Epoch [66 / 80], Step [200 / 500], Loss : 0.120652\n",
            "Epoch [66 / 80], Step [300 / 500], Loss : 0.178087\n",
            "Epoch [66 / 80], Step [400 / 500], Loss : 0.143851\n",
            "Epoch [66 / 80], Step [500 / 500], Loss : 0.068214\n",
            "\n",
            "Test Set : Average Loss : 0.006415, Accuracy : 8404 / 10000 (84%)\n",
            "\n",
            "Epoch [67 / 80], Step [100 / 500], Loss : 0.119277\n",
            "Epoch [67 / 80], Step [200 / 500], Loss : 0.110339\n",
            "Epoch [67 / 80], Step [300 / 500], Loss : 0.074047\n",
            "Epoch [67 / 80], Step [400 / 500], Loss : 0.098834\n",
            "Epoch [67 / 80], Step [500 / 500], Loss : 0.097350\n",
            "\n",
            "Test Set : Average Loss : 0.006210, Accuracy : 8414 / 10000 (84%)\n",
            "\n",
            "Epoch [68 / 80], Step [100 / 500], Loss : 0.125588\n",
            "Epoch [68 / 80], Step [200 / 500], Loss : 0.189095\n",
            "Epoch [68 / 80], Step [300 / 500], Loss : 0.154152\n",
            "Epoch [68 / 80], Step [400 / 500], Loss : 0.108325\n",
            "Epoch [68 / 80], Step [500 / 500], Loss : 0.128855\n",
            "\n",
            "Test Set : Average Loss : 0.006202, Accuracy : 8433 / 10000 (84%)\n",
            "\n",
            "Epoch [69 / 80], Step [100 / 500], Loss : 0.119322\n",
            "Epoch [69 / 80], Step [200 / 500], Loss : 0.131468\n",
            "Epoch [69 / 80], Step [300 / 500], Loss : 0.116097\n",
            "Epoch [69 / 80], Step [400 / 500], Loss : 0.105515\n",
            "Epoch [69 / 80], Step [500 / 500], Loss : 0.207880\n",
            "\n",
            "Test Set : Average Loss : 0.006332, Accuracy : 8426 / 10000 (84%)\n",
            "\n",
            "Epoch [70 / 80], Step [100 / 500], Loss : 0.109368\n",
            "Epoch [70 / 80], Step [200 / 500], Loss : 0.079484\n",
            "Epoch [70 / 80], Step [300 / 500], Loss : 0.178067\n",
            "Epoch [70 / 80], Step [400 / 500], Loss : 0.119113\n",
            "Epoch [70 / 80], Step [500 / 500], Loss : 0.128321\n",
            "\n",
            "Test Set : Average Loss : 0.006519, Accuracy : 8400 / 10000 (84%)\n",
            "\n",
            "Epoch [71 / 80], Step [100 / 500], Loss : 0.204624\n",
            "Epoch [71 / 80], Step [200 / 500], Loss : 0.195876\n",
            "Epoch [71 / 80], Step [300 / 500], Loss : 0.122269\n",
            "Epoch [71 / 80], Step [400 / 500], Loss : 0.129774\n",
            "Epoch [71 / 80], Step [500 / 500], Loss : 0.161077\n",
            "\n",
            "Test Set : Average Loss : 0.006490, Accuracy : 8402 / 10000 (84%)\n",
            "\n",
            "Epoch [72 / 80], Step [100 / 500], Loss : 0.255429\n",
            "Epoch [72 / 80], Step [200 / 500], Loss : 0.137773\n",
            "Epoch [72 / 80], Step [300 / 500], Loss : 0.149417\n",
            "Epoch [72 / 80], Step [400 / 500], Loss : 0.215016\n",
            "Epoch [72 / 80], Step [500 / 500], Loss : 0.123472\n",
            "\n",
            "Test Set : Average Loss : 0.006510, Accuracy : 8419 / 10000 (84%)\n",
            "\n",
            "Epoch [73 / 80], Step [100 / 500], Loss : 0.079568\n",
            "Epoch [73 / 80], Step [200 / 500], Loss : 0.149197\n",
            "Epoch [73 / 80], Step [300 / 500], Loss : 0.150088\n",
            "Epoch [73 / 80], Step [400 / 500], Loss : 0.117410\n",
            "Epoch [73 / 80], Step [500 / 500], Loss : 0.117287\n",
            "\n",
            "Test Set : Average Loss : 0.006677, Accuracy : 8440 / 10000 (84%)\n",
            "\n",
            "Epoch [74 / 80], Step [100 / 500], Loss : 0.160328\n",
            "Epoch [74 / 80], Step [200 / 500], Loss : 0.089276\n",
            "Epoch [74 / 80], Step [300 / 500], Loss : 0.182565\n",
            "Epoch [74 / 80], Step [400 / 500], Loss : 0.139698\n",
            "Epoch [74 / 80], Step [500 / 500], Loss : 0.110220\n",
            "\n",
            "Test Set : Average Loss : 0.006649, Accuracy : 8439 / 10000 (84%)\n",
            "\n",
            "Epoch [75 / 80], Step [100 / 500], Loss : 0.054876\n",
            "Epoch [75 / 80], Step [200 / 500], Loss : 0.128983\n",
            "Epoch [75 / 80], Step [300 / 500], Loss : 0.153757\n",
            "Epoch [75 / 80], Step [400 / 500], Loss : 0.112819\n",
            "Epoch [75 / 80], Step [500 / 500], Loss : 0.231951\n",
            "\n",
            "Test Set : Average Loss : 0.006922, Accuracy : 8316 / 10000 (83%)\n",
            "\n",
            "Epoch [76 / 80], Step [100 / 500], Loss : 0.152196\n",
            "Epoch [76 / 80], Step [200 / 500], Loss : 0.162566\n",
            "Epoch [76 / 80], Step [300 / 500], Loss : 0.121273\n",
            "Epoch [76 / 80], Step [400 / 500], Loss : 0.117239\n",
            "Epoch [76 / 80], Step [500 / 500], Loss : 0.161513\n",
            "\n",
            "Test Set : Average Loss : 0.006688, Accuracy : 8426 / 10000 (84%)\n",
            "\n",
            "Epoch [77 / 80], Step [100 / 500], Loss : 0.250404\n",
            "Epoch [77 / 80], Step [200 / 500], Loss : 0.076825\n",
            "Epoch [77 / 80], Step [300 / 500], Loss : 0.131027\n",
            "Epoch [77 / 80], Step [400 / 500], Loss : 0.221015\n",
            "Epoch [77 / 80], Step [500 / 500], Loss : 0.186958\n",
            "\n",
            "Test Set : Average Loss : 0.006671, Accuracy : 8403 / 10000 (84%)\n",
            "\n",
            "Epoch [78 / 80], Step [100 / 500], Loss : 0.197284\n",
            "Epoch [78 / 80], Step [200 / 500], Loss : 0.111578\n",
            "Epoch [78 / 80], Step [300 / 500], Loss : 0.153969\n",
            "Epoch [78 / 80], Step [400 / 500], Loss : 0.168479\n",
            "Epoch [78 / 80], Step [500 / 500], Loss : 0.064123\n",
            "\n",
            "Test Set : Average Loss : 0.006604, Accuracy : 8420 / 10000 (84%)\n",
            "\n",
            "Epoch [79 / 80], Step [100 / 500], Loss : 0.178321\n",
            "Epoch [79 / 80], Step [200 / 500], Loss : 0.106445\n",
            "Epoch [79 / 80], Step [300 / 500], Loss : 0.103964\n",
            "Epoch [79 / 80], Step [400 / 500], Loss : 0.137999\n",
            "Epoch [79 / 80], Step [500 / 500], Loss : 0.086095\n",
            "\n",
            "Test Set : Average Loss : 0.006719, Accuracy : 8440 / 10000 (84%)\n",
            "\n",
            "Epoch [80 / 80], Step [100 / 500], Loss : 0.131188\n",
            "Epoch [80 / 80], Step [200 / 500], Loss : 0.175286\n",
            "Epoch [80 / 80], Step [300 / 500], Loss : 0.227780\n",
            "Epoch [80 / 80], Step [400 / 500], Loss : 0.111457\n",
            "Epoch [80 / 80], Step [500 / 500], Loss : 0.132872\n",
            "\n",
            "Test Set : Average Loss : 0.006663, Accuracy : 8396 / 10000 (84%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiIuTtJKai1A",
        "outputId": "2f8f5b61-21fa-4279-9b65-cf29ff47c0ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 80], Step [100 / 500], Loss : 1.887846\n",
            "Epoch [1 / 80], Step [200 / 500], Loss : 1.486607\n",
            "Epoch [1 / 80], Step [300 / 500], Loss : 1.495817\n",
            "Epoch [1 / 80], Step [400 / 500], Loss : 1.324360\n",
            "Epoch [1 / 80], Step [500 / 500], Loss : 1.239718\n",
            "\n",
            "Test Set : Average Loss : 0.015136, Accuracy : 4451 / 10000 (45%)\n",
            "\n",
            "Epoch [2 / 80], Step [100 / 500], Loss : 1.354493\n",
            "Epoch [2 / 80], Step [200 / 500], Loss : 1.299830\n",
            "Epoch [2 / 80], Step [300 / 500], Loss : 1.301095\n",
            "Epoch [2 / 80], Step [400 / 500], Loss : 1.076735\n",
            "Epoch [2 / 80], Step [500 / 500], Loss : 1.009524\n",
            "\n",
            "Test Set : Average Loss : 0.012907, Accuracy : 5466 / 10000 (55%)\n",
            "\n",
            "Epoch [3 / 80], Step [100 / 500], Loss : 1.367111\n",
            "Epoch [3 / 80], Step [200 / 500], Loss : 0.974575\n",
            "Epoch [3 / 80], Step [300 / 500], Loss : 1.070308\n",
            "Epoch [3 / 80], Step [400 / 500], Loss : 1.012188\n",
            "Epoch [3 / 80], Step [500 / 500], Loss : 1.086865\n",
            "\n",
            "Test Set : Average Loss : 0.011967, Accuracy : 5861 / 10000 (59%)\n",
            "\n",
            "Epoch [4 / 80], Step [100 / 500], Loss : 0.873483\n",
            "Epoch [4 / 80], Step [200 / 500], Loss : 0.839765\n",
            "Epoch [4 / 80], Step [300 / 500], Loss : 0.769047\n",
            "Epoch [4 / 80], Step [400 / 500], Loss : 1.040498\n",
            "Epoch [4 / 80], Step [500 / 500], Loss : 0.803025\n",
            "\n",
            "Test Set : Average Loss : 0.011714, Accuracy : 6179 / 10000 (62%)\n",
            "\n",
            "Epoch [5 / 80], Step [100 / 500], Loss : 0.926942\n",
            "Epoch [5 / 80], Step [200 / 500], Loss : 0.697247\n",
            "Epoch [5 / 80], Step [300 / 500], Loss : 0.802753\n",
            "Epoch [5 / 80], Step [400 / 500], Loss : 0.729859\n",
            "Epoch [5 / 80], Step [500 / 500], Loss : 0.697820\n",
            "\n",
            "Test Set : Average Loss : 0.010733, Accuracy : 6394 / 10000 (64%)\n",
            "\n",
            "Epoch [6 / 80], Step [100 / 500], Loss : 0.625154\n",
            "Epoch [6 / 80], Step [200 / 500], Loss : 0.782122\n",
            "Epoch [6 / 80], Step [300 / 500], Loss : 0.741610\n",
            "Epoch [6 / 80], Step [400 / 500], Loss : 0.783423\n",
            "Epoch [6 / 80], Step [500 / 500], Loss : 0.731647\n",
            "\n",
            "Test Set : Average Loss : 0.009031, Accuracy : 6894 / 10000 (69%)\n",
            "\n",
            "Epoch [7 / 80], Step [100 / 500], Loss : 0.696334\n",
            "Epoch [7 / 80], Step [200 / 500], Loss : 0.736294\n",
            "Epoch [7 / 80], Step [300 / 500], Loss : 0.717596\n",
            "Epoch [7 / 80], Step [400 / 500], Loss : 0.918683\n",
            "Epoch [7 / 80], Step [500 / 500], Loss : 0.927917\n",
            "\n",
            "Test Set : Average Loss : 0.011425, Accuracy : 6105 / 10000 (61%)\n",
            "\n",
            "Epoch [8 / 80], Step [100 / 500], Loss : 0.716748\n",
            "Epoch [8 / 80], Step [200 / 500], Loss : 0.788364\n",
            "Epoch [8 / 80], Step [300 / 500], Loss : 0.822005\n",
            "Epoch [8 / 80], Step [400 / 500], Loss : 0.596323\n",
            "Epoch [8 / 80], Step [500 / 500], Loss : 0.803678\n",
            "\n",
            "Test Set : Average Loss : 0.007816, Accuracy : 7312 / 10000 (73%)\n",
            "\n",
            "Epoch [9 / 80], Step [100 / 500], Loss : 0.705424\n",
            "Epoch [9 / 80], Step [200 / 500], Loss : 0.908883\n",
            "Epoch [9 / 80], Step [300 / 500], Loss : 0.662711\n",
            "Epoch [9 / 80], Step [400 / 500], Loss : 0.674180\n",
            "Epoch [9 / 80], Step [500 / 500], Loss : 0.620071\n",
            "\n",
            "Test Set : Average Loss : 0.008205, Accuracy : 7229 / 10000 (72%)\n",
            "\n",
            "Epoch [10 / 80], Step [100 / 500], Loss : 0.737432\n",
            "Epoch [10 / 80], Step [200 / 500], Loss : 0.564440\n",
            "Epoch [10 / 80], Step [300 / 500], Loss : 0.803874\n",
            "Epoch [10 / 80], Step [400 / 500], Loss : 0.464713\n",
            "Epoch [10 / 80], Step [500 / 500], Loss : 0.688837\n",
            "\n",
            "Test Set : Average Loss : 0.010421, Accuracy : 6636 / 10000 (66%)\n",
            "\n",
            "Epoch [11 / 80], Step [100 / 500], Loss : 0.500147\n",
            "Epoch [11 / 80], Step [200 / 500], Loss : 0.750790\n",
            "Epoch [11 / 80], Step [300 / 500], Loss : 0.644193\n",
            "Epoch [11 / 80], Step [400 / 500], Loss : 0.598024\n",
            "Epoch [11 / 80], Step [500 / 500], Loss : 0.735961\n",
            "\n",
            "Test Set : Average Loss : 0.010519, Accuracy : 6600 / 10000 (66%)\n",
            "\n",
            "Epoch [12 / 80], Step [100 / 500], Loss : 0.719060\n",
            "Epoch [12 / 80], Step [200 / 500], Loss : 0.582935\n",
            "Epoch [12 / 80], Step [300 / 500], Loss : 0.676141\n",
            "Epoch [12 / 80], Step [400 / 500], Loss : 0.513992\n",
            "Epoch [12 / 80], Step [500 / 500], Loss : 0.450248\n",
            "\n",
            "Test Set : Average Loss : 0.006888, Accuracy : 7609 / 10000 (76%)\n",
            "\n",
            "Epoch [13 / 80], Step [100 / 500], Loss : 0.426335\n",
            "Epoch [13 / 80], Step [200 / 500], Loss : 0.550216\n",
            "Epoch [13 / 80], Step [300 / 500], Loss : 0.512462\n",
            "Epoch [13 / 80], Step [400 / 500], Loss : 0.570186\n",
            "Epoch [13 / 80], Step [500 / 500], Loss : 0.415768\n",
            "\n",
            "Test Set : Average Loss : 0.008101, Accuracy : 7405 / 10000 (74%)\n",
            "\n",
            "Epoch [14 / 80], Step [100 / 500], Loss : 0.549279\n",
            "Epoch [14 / 80], Step [200 / 500], Loss : 0.629134\n",
            "Epoch [14 / 80], Step [300 / 500], Loss : 0.408570\n",
            "Epoch [14 / 80], Step [400 / 500], Loss : 0.421082\n",
            "Epoch [14 / 80], Step [500 / 500], Loss : 0.600665\n",
            "\n",
            "Test Set : Average Loss : 0.006620, Accuracy : 7748 / 10000 (77%)\n",
            "\n",
            "Epoch [15 / 80], Step [100 / 500], Loss : 0.569543\n",
            "Epoch [15 / 80], Step [200 / 500], Loss : 0.512439\n",
            "Epoch [15 / 80], Step [300 / 500], Loss : 0.492077\n",
            "Epoch [15 / 80], Step [400 / 500], Loss : 0.536132\n",
            "Epoch [15 / 80], Step [500 / 500], Loss : 0.471610\n",
            "\n",
            "Test Set : Average Loss : 0.006482, Accuracy : 7819 / 10000 (78%)\n",
            "\n",
            "Epoch [16 / 80], Step [100 / 500], Loss : 0.527970\n",
            "Epoch [16 / 80], Step [200 / 500], Loss : 0.659820\n",
            "Epoch [16 / 80], Step [300 / 500], Loss : 0.336193\n",
            "Epoch [16 / 80], Step [400 / 500], Loss : 0.526120\n",
            "Epoch [16 / 80], Step [500 / 500], Loss : 0.776242\n",
            "\n",
            "Test Set : Average Loss : 0.006814, Accuracy : 7721 / 10000 (77%)\n",
            "\n",
            "Epoch [17 / 80], Step [100 / 500], Loss : 0.411739\n",
            "Epoch [17 / 80], Step [200 / 500], Loss : 0.525002\n",
            "Epoch [17 / 80], Step [300 / 500], Loss : 0.520044\n",
            "Epoch [17 / 80], Step [400 / 500], Loss : 0.514591\n",
            "Epoch [17 / 80], Step [500 / 500], Loss : 0.439390\n",
            "\n",
            "Test Set : Average Loss : 0.005894, Accuracy : 8053 / 10000 (81%)\n",
            "\n",
            "Epoch [18 / 80], Step [100 / 500], Loss : 0.547848\n",
            "Epoch [18 / 80], Step [200 / 500], Loss : 0.564988\n",
            "Epoch [18 / 80], Step [300 / 500], Loss : 0.584333\n",
            "Epoch [18 / 80], Step [400 / 500], Loss : 0.519838\n",
            "Epoch [18 / 80], Step [500 / 500], Loss : 0.683139\n",
            "\n",
            "Test Set : Average Loss : 0.005965, Accuracy : 7953 / 10000 (80%)\n",
            "\n",
            "Epoch [19 / 80], Step [100 / 500], Loss : 0.562858\n",
            "Epoch [19 / 80], Step [200 / 500], Loss : 0.455185\n",
            "Epoch [19 / 80], Step [300 / 500], Loss : 0.446893\n",
            "Epoch [19 / 80], Step [400 / 500], Loss : 0.423911\n",
            "Epoch [19 / 80], Step [500 / 500], Loss : 0.486841\n",
            "\n",
            "Test Set : Average Loss : 0.006101, Accuracy : 8026 / 10000 (80%)\n",
            "\n",
            "Epoch [20 / 80], Step [100 / 500], Loss : 0.383433\n",
            "Epoch [20 / 80], Step [200 / 500], Loss : 0.414847\n",
            "Epoch [20 / 80], Step [300 / 500], Loss : 0.445944\n",
            "Epoch [20 / 80], Step [400 / 500], Loss : 0.694321\n",
            "Epoch [20 / 80], Step [500 / 500], Loss : 0.760898\n",
            "\n",
            "Test Set : Average Loss : 0.007112, Accuracy : 7700 / 10000 (77%)\n",
            "\n",
            "Epoch [21 / 80], Step [100 / 500], Loss : 0.325237\n",
            "Epoch [21 / 80], Step [200 / 500], Loss : 0.440509\n",
            "Epoch [21 / 80], Step [300 / 500], Loss : 0.270967\n",
            "Epoch [21 / 80], Step [400 / 500], Loss : 0.401577\n",
            "Epoch [21 / 80], Step [500 / 500], Loss : 0.404048\n",
            "\n",
            "Test Set : Average Loss : 0.004942, Accuracy : 8378 / 10000 (84%)\n",
            "\n",
            "Epoch [22 / 80], Step [100 / 500], Loss : 0.415406\n",
            "Epoch [22 / 80], Step [200 / 500], Loss : 0.271256\n",
            "Epoch [22 / 80], Step [300 / 500], Loss : 0.346300\n",
            "Epoch [22 / 80], Step [400 / 500], Loss : 0.289362\n",
            "Epoch [22 / 80], Step [500 / 500], Loss : 0.187536\n",
            "\n",
            "Test Set : Average Loss : 0.004758, Accuracy : 8389 / 10000 (84%)\n",
            "\n",
            "Epoch [23 / 80], Step [100 / 500], Loss : 0.319442\n",
            "Epoch [23 / 80], Step [200 / 500], Loss : 0.345776\n",
            "Epoch [23 / 80], Step [300 / 500], Loss : 0.290296\n",
            "Epoch [23 / 80], Step [400 / 500], Loss : 0.257769\n",
            "Epoch [23 / 80], Step [500 / 500], Loss : 0.364653\n",
            "\n",
            "Test Set : Average Loss : 0.005126, Accuracy : 8290 / 10000 (83%)\n",
            "\n",
            "Epoch [24 / 80], Step [100 / 500], Loss : 0.320775\n",
            "Epoch [24 / 80], Step [200 / 500], Loss : 0.543992\n",
            "Epoch [24 / 80], Step [300 / 500], Loss : 0.333748\n",
            "Epoch [24 / 80], Step [400 / 500], Loss : 0.376024\n",
            "Epoch [24 / 80], Step [500 / 500], Loss : 0.370080\n",
            "\n",
            "Test Set : Average Loss : 0.004858, Accuracy : 8383 / 10000 (84%)\n",
            "\n",
            "Epoch [25 / 80], Step [100 / 500], Loss : 0.206273\n",
            "Epoch [25 / 80], Step [200 / 500], Loss : 0.299211\n",
            "Epoch [25 / 80], Step [300 / 500], Loss : 0.226301\n",
            "Epoch [25 / 80], Step [400 / 500], Loss : 0.212887\n",
            "Epoch [25 / 80], Step [500 / 500], Loss : 0.304060\n",
            "\n",
            "Test Set : Average Loss : 0.005603, Accuracy : 8179 / 10000 (82%)\n",
            "\n",
            "Epoch [26 / 80], Step [100 / 500], Loss : 0.140542\n",
            "Epoch [26 / 80], Step [200 / 500], Loss : 0.299203\n",
            "Epoch [26 / 80], Step [300 / 500], Loss : 0.184650\n",
            "Epoch [26 / 80], Step [400 / 500], Loss : 0.326784\n",
            "Epoch [26 / 80], Step [500 / 500], Loss : 0.463765\n",
            "\n",
            "Test Set : Average Loss : 0.005297, Accuracy : 8317 / 10000 (83%)\n",
            "\n",
            "Epoch [27 / 80], Step [100 / 500], Loss : 0.267941\n",
            "Epoch [27 / 80], Step [200 / 500], Loss : 0.356369\n",
            "Epoch [27 / 80], Step [300 / 500], Loss : 0.299696\n",
            "Epoch [27 / 80], Step [400 / 500], Loss : 0.351879\n",
            "Epoch [27 / 80], Step [500 / 500], Loss : 0.342741\n",
            "\n",
            "Test Set : Average Loss : 0.005086, Accuracy : 8366 / 10000 (84%)\n",
            "\n",
            "Epoch [28 / 80], Step [100 / 500], Loss : 0.445397\n",
            "Epoch [28 / 80], Step [200 / 500], Loss : 0.322071\n",
            "Epoch [28 / 80], Step [300 / 500], Loss : 0.244420\n",
            "Epoch [28 / 80], Step [400 / 500], Loss : 0.361554\n",
            "Epoch [28 / 80], Step [500 / 500], Loss : 0.281672\n",
            "\n",
            "Test Set : Average Loss : 0.004822, Accuracy : 8449 / 10000 (84%)\n",
            "\n",
            "Epoch [29 / 80], Step [100 / 500], Loss : 0.289305\n",
            "Epoch [29 / 80], Step [200 / 500], Loss : 0.133937\n",
            "Epoch [29 / 80], Step [300 / 500], Loss : 0.297486\n",
            "Epoch [29 / 80], Step [400 / 500], Loss : 0.289741\n",
            "Epoch [29 / 80], Step [500 / 500], Loss : 0.269989\n",
            "\n",
            "Test Set : Average Loss : 0.005174, Accuracy : 8418 / 10000 (84%)\n",
            "\n",
            "Epoch [30 / 80], Step [100 / 500], Loss : 0.216948\n",
            "Epoch [30 / 80], Step [200 / 500], Loss : 0.301069\n",
            "Epoch [30 / 80], Step [300 / 500], Loss : 0.357964\n",
            "Epoch [30 / 80], Step [400 / 500], Loss : 0.300146\n",
            "Epoch [30 / 80], Step [500 / 500], Loss : 0.369599\n",
            "\n",
            "Test Set : Average Loss : 0.005092, Accuracy : 8383 / 10000 (84%)\n",
            "\n",
            "Epoch [31 / 80], Step [100 / 500], Loss : 0.248063\n",
            "Epoch [31 / 80], Step [200 / 500], Loss : 0.328551\n",
            "Epoch [31 / 80], Step [300 / 500], Loss : 0.305908\n",
            "Epoch [31 / 80], Step [400 / 500], Loss : 0.327492\n",
            "Epoch [31 / 80], Step [500 / 500], Loss : 0.155736\n",
            "\n",
            "Test Set : Average Loss : 0.005178, Accuracy : 8351 / 10000 (84%)\n",
            "\n",
            "Epoch [32 / 80], Step [100 / 500], Loss : 0.209024\n",
            "Epoch [32 / 80], Step [200 / 500], Loss : 0.319759\n",
            "Epoch [32 / 80], Step [300 / 500], Loss : 0.259816\n",
            "Epoch [32 / 80], Step [400 / 500], Loss : 0.294931\n",
            "Epoch [32 / 80], Step [500 / 500], Loss : 0.190133\n",
            "\n",
            "Test Set : Average Loss : 0.004979, Accuracy : 8450 / 10000 (84%)\n",
            "\n",
            "Epoch [33 / 80], Step [100 / 500], Loss : 0.256406\n",
            "Epoch [33 / 80], Step [200 / 500], Loss : 0.341870\n",
            "Epoch [33 / 80], Step [300 / 500], Loss : 0.233049\n",
            "Epoch [33 / 80], Step [400 / 500], Loss : 0.320294\n",
            "Epoch [33 / 80], Step [500 / 500], Loss : 0.350536\n",
            "\n",
            "Test Set : Average Loss : 0.005253, Accuracy : 8401 / 10000 (84%)\n",
            "\n",
            "Epoch [34 / 80], Step [100 / 500], Loss : 0.197082\n",
            "Epoch [34 / 80], Step [200 / 500], Loss : 0.425313\n",
            "Epoch [34 / 80], Step [300 / 500], Loss : 0.267684\n",
            "Epoch [34 / 80], Step [400 / 500], Loss : 0.293294\n",
            "Epoch [34 / 80], Step [500 / 500], Loss : 0.369801\n",
            "\n",
            "Test Set : Average Loss : 0.005172, Accuracy : 8385 / 10000 (84%)\n",
            "\n",
            "Epoch [35 / 80], Step [100 / 500], Loss : 0.162445\n",
            "Epoch [35 / 80], Step [200 / 500], Loss : 0.286382\n",
            "Epoch [35 / 80], Step [300 / 500], Loss : 0.251155\n",
            "Epoch [35 / 80], Step [400 / 500], Loss : 0.141697\n",
            "Epoch [35 / 80], Step [500 / 500], Loss : 0.161040\n",
            "\n",
            "Test Set : Average Loss : 0.005022, Accuracy : 8459 / 10000 (85%)\n",
            "\n",
            "Epoch [36 / 80], Step [100 / 500], Loss : 0.220672\n",
            "Epoch [36 / 80], Step [200 / 500], Loss : 0.222226\n",
            "Epoch [36 / 80], Step [300 / 500], Loss : 0.178255\n",
            "Epoch [36 / 80], Step [400 / 500], Loss : 0.194818\n",
            "Epoch [36 / 80], Step [500 / 500], Loss : 0.237925\n",
            "\n",
            "Test Set : Average Loss : 0.005179, Accuracy : 8486 / 10000 (85%)\n",
            "\n",
            "Epoch [37 / 80], Step [100 / 500], Loss : 0.157323\n",
            "Epoch [37 / 80], Step [200 / 500], Loss : 0.308775\n",
            "Epoch [37 / 80], Step [300 / 500], Loss : 0.178665\n",
            "Epoch [37 / 80], Step [400 / 500], Loss : 0.233661\n",
            "Epoch [37 / 80], Step [500 / 500], Loss : 0.208632\n",
            "\n",
            "Test Set : Average Loss : 0.005140, Accuracy : 8459 / 10000 (85%)\n",
            "\n",
            "Epoch [38 / 80], Step [100 / 500], Loss : 0.286994\n",
            "Epoch [38 / 80], Step [200 / 500], Loss : 0.229061\n",
            "Epoch [38 / 80], Step [300 / 500], Loss : 0.266512\n",
            "Epoch [38 / 80], Step [400 / 500], Loss : 0.188495\n",
            "Epoch [38 / 80], Step [500 / 500], Loss : 0.316141\n",
            "\n",
            "Test Set : Average Loss : 0.005305, Accuracy : 8441 / 10000 (84%)\n",
            "\n",
            "Epoch [39 / 80], Step [100 / 500], Loss : 0.131429\n",
            "Epoch [39 / 80], Step [200 / 500], Loss : 0.239329\n",
            "Epoch [39 / 80], Step [300 / 500], Loss : 0.274336\n",
            "Epoch [39 / 80], Step [400 / 500], Loss : 0.129059\n",
            "Epoch [39 / 80], Step [500 / 500], Loss : 0.331587\n",
            "\n",
            "Test Set : Average Loss : 0.005365, Accuracy : 8434 / 10000 (84%)\n",
            "\n",
            "Epoch [40 / 80], Step [100 / 500], Loss : 0.227545\n",
            "Epoch [40 / 80], Step [200 / 500], Loss : 0.265063\n",
            "Epoch [40 / 80], Step [300 / 500], Loss : 0.210197\n",
            "Epoch [40 / 80], Step [400 / 500], Loss : 0.215693\n",
            "Epoch [40 / 80], Step [500 / 500], Loss : 0.252823\n",
            "\n",
            "Test Set : Average Loss : 0.005029, Accuracy : 8485 / 10000 (85%)\n",
            "\n",
            "Epoch [41 / 80], Step [100 / 500], Loss : 0.154729\n",
            "Epoch [41 / 80], Step [200 / 500], Loss : 0.174645\n",
            "Epoch [41 / 80], Step [300 / 500], Loss : 0.333777\n",
            "Epoch [41 / 80], Step [400 / 500], Loss : 0.227000\n",
            "Epoch [41 / 80], Step [500 / 500], Loss : 0.244197\n",
            "\n",
            "Test Set : Average Loss : 0.005416, Accuracy : 8442 / 10000 (84%)\n",
            "\n",
            "Epoch [42 / 80], Step [100 / 500], Loss : 0.301076\n",
            "Epoch [42 / 80], Step [200 / 500], Loss : 0.415053\n",
            "Epoch [42 / 80], Step [300 / 500], Loss : 0.138672\n",
            "Epoch [42 / 80], Step [400 / 500], Loss : 0.215972\n",
            "Epoch [42 / 80], Step [500 / 500], Loss : 0.269290\n",
            "\n",
            "Test Set : Average Loss : 0.005487, Accuracy : 8406 / 10000 (84%)\n",
            "\n",
            "Epoch [43 / 80], Step [100 / 500], Loss : 0.268326\n",
            "Epoch [43 / 80], Step [200 / 500], Loss : 0.132925\n",
            "Epoch [43 / 80], Step [300 / 500], Loss : 0.261347\n",
            "Epoch [43 / 80], Step [400 / 500], Loss : 0.183029\n",
            "Epoch [43 / 80], Step [500 / 500], Loss : 0.261497\n",
            "\n",
            "Test Set : Average Loss : 0.005817, Accuracy : 8354 / 10000 (84%)\n",
            "\n",
            "Epoch [44 / 80], Step [100 / 500], Loss : 0.190983\n",
            "Epoch [44 / 80], Step [200 / 500], Loss : 0.159550\n",
            "Epoch [44 / 80], Step [300 / 500], Loss : 0.323075\n",
            "Epoch [44 / 80], Step [400 / 500], Loss : 0.215283\n",
            "Epoch [44 / 80], Step [500 / 500], Loss : 0.241071\n",
            "\n",
            "Test Set : Average Loss : 0.005608, Accuracy : 8409 / 10000 (84%)\n",
            "\n",
            "Epoch [45 / 80], Step [100 / 500], Loss : 0.170817\n",
            "Epoch [45 / 80], Step [200 / 500], Loss : 0.263535\n",
            "Epoch [45 / 80], Step [300 / 500], Loss : 0.116706\n",
            "Epoch [45 / 80], Step [400 / 500], Loss : 0.209473\n",
            "Epoch [45 / 80], Step [500 / 500], Loss : 0.229163\n",
            "\n",
            "Test Set : Average Loss : 0.005542, Accuracy : 8461 / 10000 (85%)\n",
            "\n",
            "Epoch [46 / 80], Step [100 / 500], Loss : 0.163817\n",
            "Epoch [46 / 80], Step [200 / 500], Loss : 0.281599\n",
            "Epoch [46 / 80], Step [300 / 500], Loss : 0.180093\n",
            "Epoch [46 / 80], Step [400 / 500], Loss : 0.111255\n",
            "Epoch [46 / 80], Step [500 / 500], Loss : 0.301807\n",
            "\n",
            "Test Set : Average Loss : 0.005422, Accuracy : 8487 / 10000 (85%)\n",
            "\n",
            "Epoch [47 / 80], Step [100 / 500], Loss : 0.169285\n",
            "Epoch [47 / 80], Step [200 / 500], Loss : 0.130243\n",
            "Epoch [47 / 80], Step [300 / 500], Loss : 0.303196\n",
            "Epoch [47 / 80], Step [400 / 500], Loss : 0.206238\n",
            "Epoch [47 / 80], Step [500 / 500], Loss : 0.159226\n",
            "\n",
            "Test Set : Average Loss : 0.005751, Accuracy : 8407 / 10000 (84%)\n",
            "\n",
            "Epoch [48 / 80], Step [100 / 500], Loss : 0.076538\n",
            "Epoch [48 / 80], Step [200 / 500], Loss : 0.167780\n",
            "Epoch [48 / 80], Step [300 / 500], Loss : 0.147978\n",
            "Epoch [48 / 80], Step [400 / 500], Loss : 0.237672\n",
            "Epoch [48 / 80], Step [500 / 500], Loss : 0.194888\n",
            "\n",
            "Test Set : Average Loss : 0.005571, Accuracy : 8457 / 10000 (85%)\n",
            "\n",
            "Epoch [49 / 80], Step [100 / 500], Loss : 0.264446\n",
            "Epoch [49 / 80], Step [200 / 500], Loss : 0.268547\n",
            "Epoch [49 / 80], Step [300 / 500], Loss : 0.392677\n",
            "Epoch [49 / 80], Step [400 / 500], Loss : 0.122841\n",
            "Epoch [49 / 80], Step [500 / 500], Loss : 0.236473\n",
            "\n",
            "Test Set : Average Loss : 0.005624, Accuracy : 8449 / 10000 (84%)\n",
            "\n",
            "Epoch [50 / 80], Step [100 / 500], Loss : 0.146938\n",
            "Epoch [50 / 80], Step [200 / 500], Loss : 0.119265\n",
            "Epoch [50 / 80], Step [300 / 500], Loss : 0.104447\n",
            "Epoch [50 / 80], Step [400 / 500], Loss : 0.208724\n",
            "Epoch [50 / 80], Step [500 / 500], Loss : 0.129490\n",
            "\n",
            "Test Set : Average Loss : 0.005703, Accuracy : 8449 / 10000 (84%)\n",
            "\n",
            "Epoch [51 / 80], Step [100 / 500], Loss : 0.138743\n",
            "Epoch [51 / 80], Step [200 / 500], Loss : 0.098162\n",
            "Epoch [51 / 80], Step [300 / 500], Loss : 0.222275\n",
            "Epoch [51 / 80], Step [400 / 500], Loss : 0.200727\n",
            "Epoch [51 / 80], Step [500 / 500], Loss : 0.124122\n",
            "\n",
            "Test Set : Average Loss : 0.005677, Accuracy : 8443 / 10000 (84%)\n",
            "\n",
            "Epoch [52 / 80], Step [100 / 500], Loss : 0.214543\n",
            "Epoch [52 / 80], Step [200 / 500], Loss : 0.106238\n",
            "Epoch [52 / 80], Step [300 / 500], Loss : 0.205876\n",
            "Epoch [52 / 80], Step [400 / 500], Loss : 0.150882\n",
            "Epoch [52 / 80], Step [500 / 500], Loss : 0.131953\n",
            "\n",
            "Test Set : Average Loss : 0.006359, Accuracy : 8307 / 10000 (83%)\n",
            "\n",
            "Epoch [53 / 80], Step [100 / 500], Loss : 0.055665\n",
            "Epoch [53 / 80], Step [200 / 500], Loss : 0.178620\n",
            "Epoch [53 / 80], Step [300 / 500], Loss : 0.165755\n",
            "Epoch [53 / 80], Step [400 / 500], Loss : 0.182534\n",
            "Epoch [53 / 80], Step [500 / 500], Loss : 0.135176\n",
            "\n",
            "Test Set : Average Loss : 0.005664, Accuracy : 8457 / 10000 (85%)\n",
            "\n",
            "Epoch [54 / 80], Step [100 / 500], Loss : 0.144622\n",
            "Epoch [54 / 80], Step [200 / 500], Loss : 0.242524\n",
            "Epoch [54 / 80], Step [300 / 500], Loss : 0.118053\n",
            "Epoch [54 / 80], Step [400 / 500], Loss : 0.154442\n",
            "Epoch [54 / 80], Step [500 / 500], Loss : 0.205486\n",
            "\n",
            "Test Set : Average Loss : 0.005558, Accuracy : 8464 / 10000 (85%)\n",
            "\n",
            "Epoch [55 / 80], Step [100 / 500], Loss : 0.140955\n",
            "Epoch [55 / 80], Step [200 / 500], Loss : 0.208371\n",
            "Epoch [55 / 80], Step [300 / 500], Loss : 0.219767\n",
            "Epoch [55 / 80], Step [400 / 500], Loss : 0.178660\n",
            "Epoch [55 / 80], Step [500 / 500], Loss : 0.182851\n",
            "\n",
            "Test Set : Average Loss : 0.005902, Accuracy : 8461 / 10000 (85%)\n",
            "\n",
            "Epoch [56 / 80], Step [100 / 500], Loss : 0.184049\n",
            "Epoch [56 / 80], Step [200 / 500], Loss : 0.121392\n",
            "Epoch [56 / 80], Step [300 / 500], Loss : 0.312902\n",
            "Epoch [56 / 80], Step [400 / 500], Loss : 0.163264\n",
            "Epoch [56 / 80], Step [500 / 500], Loss : 0.151094\n",
            "\n",
            "Test Set : Average Loss : 0.005653, Accuracy : 8479 / 10000 (85%)\n",
            "\n",
            "Epoch [57 / 80], Step [100 / 500], Loss : 0.238266\n",
            "Epoch [57 / 80], Step [200 / 500], Loss : 0.190176\n",
            "Epoch [57 / 80], Step [300 / 500], Loss : 0.256843\n",
            "Epoch [57 / 80], Step [400 / 500], Loss : 0.190860\n",
            "Epoch [57 / 80], Step [500 / 500], Loss : 0.111376\n",
            "\n",
            "Test Set : Average Loss : 0.005902, Accuracy : 8450 / 10000 (84%)\n",
            "\n",
            "Epoch [58 / 80], Step [100 / 500], Loss : 0.094621\n",
            "Epoch [58 / 80], Step [200 / 500], Loss : 0.159045\n",
            "Epoch [58 / 80], Step [300 / 500], Loss : 0.189222\n",
            "Epoch [58 / 80], Step [400 / 500], Loss : 0.232300\n",
            "Epoch [58 / 80], Step [500 / 500], Loss : 0.093510\n",
            "\n",
            "Test Set : Average Loss : 0.006480, Accuracy : 8324 / 10000 (83%)\n",
            "\n",
            "Epoch [59 / 80], Step [100 / 500], Loss : 0.073471\n",
            "Epoch [59 / 80], Step [200 / 500], Loss : 0.113783\n",
            "Epoch [59 / 80], Step [300 / 500], Loss : 0.192856\n",
            "Epoch [59 / 80], Step [400 / 500], Loss : 0.107332\n",
            "Epoch [59 / 80], Step [500 / 500], Loss : 0.071917\n",
            "\n",
            "Test Set : Average Loss : 0.006036, Accuracy : 8463 / 10000 (85%)\n",
            "\n",
            "Epoch [60 / 80], Step [100 / 500], Loss : 0.116359\n",
            "Epoch [60 / 80], Step [200 / 500], Loss : 0.182870\n",
            "Epoch [60 / 80], Step [300 / 500], Loss : 0.151612\n",
            "Epoch [60 / 80], Step [400 / 500], Loss : 0.141406\n",
            "Epoch [60 / 80], Step [500 / 500], Loss : 0.323022\n",
            "\n",
            "Test Set : Average Loss : 0.005991, Accuracy : 8462 / 10000 (85%)\n",
            "\n",
            "Epoch [61 / 80], Step [100 / 500], Loss : 0.151336\n",
            "Epoch [61 / 80], Step [200 / 500], Loss : 0.181743\n",
            "Epoch [61 / 80], Step [300 / 500], Loss : 0.273588\n",
            "Epoch [61 / 80], Step [400 / 500], Loss : 0.110079\n",
            "Epoch [61 / 80], Step [500 / 500], Loss : 0.097826\n",
            "\n",
            "Test Set : Average Loss : 0.005874, Accuracy : 8478 / 10000 (85%)\n",
            "\n",
            "Epoch [62 / 80], Step [100 / 500], Loss : 0.088280\n",
            "Epoch [62 / 80], Step [200 / 500], Loss : 0.146274\n",
            "Epoch [62 / 80], Step [300 / 500], Loss : 0.115799\n",
            "Epoch [62 / 80], Step [400 / 500], Loss : 0.177901\n",
            "Epoch [62 / 80], Step [500 / 500], Loss : 0.105688\n",
            "\n",
            "Test Set : Average Loss : 0.006451, Accuracy : 8342 / 10000 (83%)\n",
            "\n",
            "Epoch [63 / 80], Step [100 / 500], Loss : 0.116443\n",
            "Epoch [63 / 80], Step [200 / 500], Loss : 0.083914\n",
            "Epoch [63 / 80], Step [300 / 500], Loss : 0.086446\n",
            "Epoch [63 / 80], Step [400 / 500], Loss : 0.143336\n",
            "Epoch [63 / 80], Step [500 / 500], Loss : 0.158750\n",
            "\n",
            "Test Set : Average Loss : 0.005939, Accuracy : 8456 / 10000 (85%)\n",
            "\n",
            "Epoch [64 / 80], Step [100 / 500], Loss : 0.183693\n",
            "Epoch [64 / 80], Step [200 / 500], Loss : 0.170141\n",
            "Epoch [64 / 80], Step [300 / 500], Loss : 0.099791\n",
            "Epoch [64 / 80], Step [400 / 500], Loss : 0.099918\n",
            "Epoch [64 / 80], Step [500 / 500], Loss : 0.161910\n",
            "\n",
            "Test Set : Average Loss : 0.005965, Accuracy : 8492 / 10000 (85%)\n",
            "\n",
            "Epoch [65 / 80], Step [100 / 500], Loss : 0.248119\n",
            "Epoch [65 / 80], Step [200 / 500], Loss : 0.136013\n",
            "Epoch [65 / 80], Step [300 / 500], Loss : 0.120671\n",
            "Epoch [65 / 80], Step [400 / 500], Loss : 0.119984\n",
            "Epoch [65 / 80], Step [500 / 500], Loss : 0.203621\n",
            "\n",
            "Test Set : Average Loss : 0.006425, Accuracy : 8412 / 10000 (84%)\n",
            "\n",
            "Epoch [66 / 80], Step [100 / 500], Loss : 0.165045\n",
            "Epoch [66 / 80], Step [200 / 500], Loss : 0.207099\n",
            "Epoch [66 / 80], Step [300 / 500], Loss : 0.163322\n",
            "Epoch [66 / 80], Step [400 / 500], Loss : 0.137222\n",
            "Epoch [66 / 80], Step [500 / 500], Loss : 0.079972\n",
            "\n",
            "Test Set : Average Loss : 0.005764, Accuracy : 8508 / 10000 (85%)\n",
            "\n",
            "Epoch [67 / 80], Step [100 / 500], Loss : 0.117123\n",
            "Epoch [67 / 80], Step [200 / 500], Loss : 0.182127\n",
            "Epoch [67 / 80], Step [300 / 500], Loss : 0.098121\n",
            "Epoch [67 / 80], Step [400 / 500], Loss : 0.142221\n",
            "Epoch [67 / 80], Step [500 / 500], Loss : 0.235535\n",
            "\n",
            "Test Set : Average Loss : 0.006127, Accuracy : 8488 / 10000 (85%)\n",
            "\n",
            "Epoch [68 / 80], Step [100 / 500], Loss : 0.134827\n",
            "Epoch [68 / 80], Step [200 / 500], Loss : 0.084315\n",
            "Epoch [68 / 80], Step [300 / 500], Loss : 0.156267\n",
            "Epoch [68 / 80], Step [400 / 500], Loss : 0.036279\n",
            "Epoch [68 / 80], Step [500 / 500], Loss : 0.224691\n",
            "\n",
            "Test Set : Average Loss : 0.006574, Accuracy : 8449 / 10000 (84%)\n",
            "\n",
            "Epoch [69 / 80], Step [100 / 500], Loss : 0.095422\n",
            "Epoch [69 / 80], Step [200 / 500], Loss : 0.185905\n",
            "Epoch [69 / 80], Step [300 / 500], Loss : 0.209260\n",
            "Epoch [69 / 80], Step [400 / 500], Loss : 0.132721\n",
            "Epoch [69 / 80], Step [500 / 500], Loss : 0.182306\n",
            "\n",
            "Test Set : Average Loss : 0.006231, Accuracy : 8461 / 10000 (85%)\n",
            "\n",
            "Epoch [70 / 80], Step [100 / 500], Loss : 0.140643\n",
            "Epoch [70 / 80], Step [200 / 500], Loss : 0.119988\n",
            "Epoch [70 / 80], Step [300 / 500], Loss : 0.072340\n",
            "Epoch [70 / 80], Step [400 / 500], Loss : 0.144054\n",
            "Epoch [70 / 80], Step [500 / 500], Loss : 0.129521\n",
            "\n",
            "Test Set : Average Loss : 0.007047, Accuracy : 8330 / 10000 (83%)\n",
            "\n",
            "Epoch [71 / 80], Step [100 / 500], Loss : 0.177718\n",
            "Epoch [71 / 80], Step [200 / 500], Loss : 0.116039\n",
            "Epoch [71 / 80], Step [300 / 500], Loss : 0.122066\n",
            "Epoch [71 / 80], Step [400 / 500], Loss : 0.082360\n",
            "Epoch [71 / 80], Step [500 / 500], Loss : 0.108459\n",
            "\n",
            "Test Set : Average Loss : 0.006391, Accuracy : 8411 / 10000 (84%)\n",
            "\n",
            "Epoch [72 / 80], Step [100 / 500], Loss : 0.062435\n",
            "Epoch [72 / 80], Step [200 / 500], Loss : 0.147374\n",
            "Epoch [72 / 80], Step [300 / 500], Loss : 0.059348\n",
            "Epoch [72 / 80], Step [400 / 500], Loss : 0.158996\n",
            "Epoch [72 / 80], Step [500 / 500], Loss : 0.072889\n",
            "\n",
            "Test Set : Average Loss : 0.006383, Accuracy : 8468 / 10000 (85%)\n",
            "\n",
            "Epoch [73 / 80], Step [100 / 500], Loss : 0.076068\n",
            "Epoch [73 / 80], Step [200 / 500], Loss : 0.121612\n",
            "Epoch [73 / 80], Step [300 / 500], Loss : 0.050449\n",
            "Epoch [73 / 80], Step [400 / 500], Loss : 0.079578\n",
            "Epoch [73 / 80], Step [500 / 500], Loss : 0.171801\n",
            "\n",
            "Test Set : Average Loss : 0.006416, Accuracy : 8503 / 10000 (85%)\n",
            "\n",
            "Epoch [74 / 80], Step [100 / 500], Loss : 0.107174\n",
            "Epoch [74 / 80], Step [200 / 500], Loss : 0.109326\n",
            "Epoch [74 / 80], Step [300 / 500], Loss : 0.096943\n",
            "Epoch [74 / 80], Step [400 / 500], Loss : 0.129760\n",
            "Epoch [74 / 80], Step [500 / 500], Loss : 0.251615\n",
            "\n",
            "Test Set : Average Loss : 0.006798, Accuracy : 8364 / 10000 (84%)\n",
            "\n",
            "Epoch [75 / 80], Step [100 / 500], Loss : 0.133642\n",
            "Epoch [75 / 80], Step [200 / 500], Loss : 0.107107\n",
            "Epoch [75 / 80], Step [300 / 500], Loss : 0.184898\n",
            "Epoch [75 / 80], Step [400 / 500], Loss : 0.147376\n",
            "Epoch [75 / 80], Step [500 / 500], Loss : 0.184837\n",
            "\n",
            "Test Set : Average Loss : 0.006570, Accuracy : 8442 / 10000 (84%)\n",
            "\n",
            "Epoch [76 / 80], Step [100 / 500], Loss : 0.194770\n",
            "Epoch [76 / 80], Step [200 / 500], Loss : 0.083496\n",
            "Epoch [76 / 80], Step [300 / 500], Loss : 0.033010\n",
            "Epoch [76 / 80], Step [400 / 500], Loss : 0.059650\n",
            "Epoch [76 / 80], Step [500 / 500], Loss : 0.115915\n",
            "\n",
            "Test Set : Average Loss : 0.006379, Accuracy : 8487 / 10000 (85%)\n",
            "\n",
            "Epoch [77 / 80], Step [100 / 500], Loss : 0.073366\n",
            "Epoch [77 / 80], Step [200 / 500], Loss : 0.157095\n",
            "Epoch [77 / 80], Step [300 / 500], Loss : 0.146358\n",
            "Epoch [77 / 80], Step [400 / 500], Loss : 0.113296\n",
            "Epoch [77 / 80], Step [500 / 500], Loss : 0.092605\n",
            "\n",
            "Test Set : Average Loss : 0.006336, Accuracy : 8516 / 10000 (85%)\n",
            "\n",
            "Epoch [78 / 80], Step [100 / 500], Loss : 0.145455\n",
            "Epoch [78 / 80], Step [200 / 500], Loss : 0.060105\n",
            "Epoch [78 / 80], Step [300 / 500], Loss : 0.205257\n",
            "Epoch [78 / 80], Step [400 / 500], Loss : 0.160339\n",
            "Epoch [78 / 80], Step [500 / 500], Loss : 0.046941\n",
            "\n",
            "Test Set : Average Loss : 0.006529, Accuracy : 8486 / 10000 (85%)\n",
            "\n",
            "Epoch [79 / 80], Step [100 / 500], Loss : 0.130769\n",
            "Epoch [79 / 80], Step [200 / 500], Loss : 0.077398\n",
            "Epoch [79 / 80], Step [300 / 500], Loss : 0.143863\n",
            "Epoch [79 / 80], Step [400 / 500], Loss : 0.034808\n",
            "Epoch [79 / 80], Step [500 / 500], Loss : 0.119063\n",
            "\n",
            "Test Set : Average Loss : 0.006806, Accuracy : 8444 / 10000 (84%)\n",
            "\n",
            "Epoch [80 / 80], Step [100 / 500], Loss : 0.133337\n",
            "Epoch [80 / 80], Step [200 / 500], Loss : 0.075122\n",
            "Epoch [80 / 80], Step [300 / 500], Loss : 0.124760\n",
            "Epoch [80 / 80], Step [400 / 500], Loss : 0.080728\n",
            "Epoch [80 / 80], Step [500 / 500], Loss : 0.105451\n",
            "\n",
            "Test Set : Average Loss : 0.006565, Accuracy : 8469 / 10000 (85%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#2\n",
        "model = ResNet(BasicBlock, [3, 4, 6, 3]).cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range (0, num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rrtRcvco3Jf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "0bb44a59-6d4e-42f3-bac4-5f1b80daca0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 80], Step [100 / 500], Loss : 2.132398\n",
            "Epoch [1 / 80], Step [200 / 500], Loss : 1.680669\n",
            "Epoch [1 / 80], Step [300 / 500], Loss : 2.022648\n",
            "Epoch [1 / 80], Step [400 / 500], Loss : 1.665032\n",
            "Epoch [1 / 80], Step [500 / 500], Loss : 1.806519\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8df0364f9c17>\u001b[0m in \u001b[0;36m<cell line: 38>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-2-74a3736b93bd>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-74a3736b93bd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-8df0364f9c17>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[0;32m--> 171\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2448\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2450\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2451\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2452\u001b[0m     )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.75 GiB total capacity; 13.60 GiB already allocated; 2.81 MiB free; 13.67 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "#3 (Batch Size 1로 해봤는데도 안됩니다...)\n",
        "class BottleNeck(nn.Module):\n",
        "  expansion = 4\n",
        "  def __init__(self, in_channels, out_channels, stride = 1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.residual_function = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels, out_channels * 4, kernel_size = 1, stride = 1, bias = False),\n",
        "        nn.BatchNorm2d(out_channels * 4),\n",
        "    )\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    if stride != 1 or in_channels != out_channels * 4:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_channels, out_channels * 4, kernel_size = 1, stride = stride, bias = False),\n",
        "          nn.BatchNorm2d(out_channels * 4)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.residual_function(x) + self.shortcut(x)\n",
        "    x = self.relu(x)\n",
        "    return x\n",
        "\n",
        "model = ResNet(BottleNeck, [3, 4, 6, 3]).cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range (0, num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4dVRtZYrgte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8eaeb6-3871-42ec-fb3f-84c4dafcd461"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1 / 80], Step [100 / 500], Loss : 1.782318\n",
            "Epoch [1 / 80], Step [200 / 500], Loss : 1.513158\n",
            "Epoch [1 / 80], Step [300 / 500], Loss : 1.599254\n",
            "Epoch [1 / 80], Step [400 / 500], Loss : 1.297476\n",
            "Epoch [1 / 80], Step [500 / 500], Loss : 1.344003\n",
            "\n",
            "Test Set : Average Loss : 0.021745, Accuracy : 3189 / 10000 (32%)\n",
            "\n",
            "Epoch [2 / 80], Step [100 / 500], Loss : 1.367675\n",
            "Epoch [2 / 80], Step [200 / 500], Loss : 1.445504\n",
            "Epoch [2 / 80], Step [300 / 500], Loss : 1.074915\n",
            "Epoch [2 / 80], Step [400 / 500], Loss : 1.070232\n",
            "Epoch [2 / 80], Step [500 / 500], Loss : 1.044274\n",
            "\n",
            "Test Set : Average Loss : 0.019417, Accuracy : 4326 / 10000 (43%)\n",
            "\n",
            "Epoch [3 / 80], Step [100 / 500], Loss : 1.038119\n",
            "Epoch [3 / 80], Step [200 / 500], Loss : 1.056049\n",
            "Epoch [3 / 80], Step [300 / 500], Loss : 1.355870\n",
            "Epoch [3 / 80], Step [400 / 500], Loss : 1.101899\n",
            "Epoch [3 / 80], Step [500 / 500], Loss : 1.188467\n",
            "\n",
            "Test Set : Average Loss : 0.013972, Accuracy : 5164 / 10000 (52%)\n",
            "\n",
            "Epoch [4 / 80], Step [100 / 500], Loss : 0.899509\n",
            "Epoch [4 / 80], Step [200 / 500], Loss : 1.206297\n",
            "Epoch [4 / 80], Step [300 / 500], Loss : 1.000643\n",
            "Epoch [4 / 80], Step [400 / 500], Loss : 0.932281\n",
            "Epoch [4 / 80], Step [500 / 500], Loss : 1.210404\n",
            "\n",
            "Test Set : Average Loss : 0.011267, Accuracy : 6274 / 10000 (63%)\n",
            "\n",
            "Epoch [5 / 80], Step [100 / 500], Loss : 0.933688\n",
            "Epoch [5 / 80], Step [200 / 500], Loss : 0.880514\n",
            "Epoch [5 / 80], Step [300 / 500], Loss : 0.857123\n",
            "Epoch [5 / 80], Step [400 / 500], Loss : 0.730598\n",
            "Epoch [5 / 80], Step [500 / 500], Loss : 0.752486\n",
            "\n",
            "Test Set : Average Loss : 0.008816, Accuracy : 6944 / 10000 (69%)\n",
            "\n",
            "Epoch [6 / 80], Step [100 / 500], Loss : 1.072528\n",
            "Epoch [6 / 80], Step [200 / 500], Loss : 0.717762\n",
            "Epoch [6 / 80], Step [300 / 500], Loss : 0.760435\n",
            "Epoch [6 / 80], Step [400 / 500], Loss : 0.815435\n",
            "Epoch [6 / 80], Step [500 / 500], Loss : 0.970446\n",
            "\n",
            "Test Set : Average Loss : 0.010832, Accuracy : 6277 / 10000 (63%)\n",
            "\n",
            "Epoch [7 / 80], Step [100 / 500], Loss : 0.922582\n",
            "Epoch [7 / 80], Step [200 / 500], Loss : 1.002224\n",
            "Epoch [7 / 80], Step [300 / 500], Loss : 0.886965\n",
            "Epoch [7 / 80], Step [400 / 500], Loss : 0.823800\n",
            "Epoch [7 / 80], Step [500 / 500], Loss : 0.961781\n",
            "\n",
            "Test Set : Average Loss : 0.013597, Accuracy : 5742 / 10000 (57%)\n",
            "\n",
            "Epoch [8 / 80], Step [100 / 500], Loss : 0.804135\n",
            "Epoch [8 / 80], Step [200 / 500], Loss : 0.685921\n",
            "Epoch [8 / 80], Step [300 / 500], Loss : 0.635472\n",
            "Epoch [8 / 80], Step [400 / 500], Loss : 0.827219\n",
            "Epoch [8 / 80], Step [500 / 500], Loss : 0.559971\n",
            "\n",
            "Test Set : Average Loss : 0.008578, Accuracy : 7145 / 10000 (71%)\n",
            "\n",
            "Epoch [9 / 80], Step [100 / 500], Loss : 0.669466\n",
            "Epoch [9 / 80], Step [200 / 500], Loss : 0.656126\n",
            "Epoch [9 / 80], Step [300 / 500], Loss : 0.666784\n",
            "Epoch [9 / 80], Step [400 / 500], Loss : 0.634229\n",
            "Epoch [9 / 80], Step [500 / 500], Loss : 1.015472\n",
            "\n",
            "Test Set : Average Loss : 0.010376, Accuracy : 6642 / 10000 (66%)\n",
            "\n",
            "Epoch [10 / 80], Step [100 / 500], Loss : 0.484323\n",
            "Epoch [10 / 80], Step [200 / 500], Loss : 0.703717\n",
            "Epoch [10 / 80], Step [300 / 500], Loss : 0.718804\n",
            "Epoch [10 / 80], Step [400 / 500], Loss : 0.594339\n",
            "Epoch [10 / 80], Step [500 / 500], Loss : 0.529627\n",
            "\n",
            "Test Set : Average Loss : 0.009946, Accuracy : 6758 / 10000 (68%)\n",
            "\n",
            "Epoch [11 / 80], Step [100 / 500], Loss : 0.697677\n",
            "Epoch [11 / 80], Step [200 / 500], Loss : 0.636594\n",
            "Epoch [11 / 80], Step [300 / 500], Loss : 0.879478\n",
            "Epoch [11 / 80], Step [400 / 500], Loss : 0.605808\n",
            "Epoch [11 / 80], Step [500 / 500], Loss : 0.593132\n",
            "\n",
            "Test Set : Average Loss : 0.007846, Accuracy : 7304 / 10000 (73%)\n",
            "\n",
            "Epoch [12 / 80], Step [100 / 500], Loss : 0.493945\n",
            "Epoch [12 / 80], Step [200 / 500], Loss : 0.557970\n",
            "Epoch [12 / 80], Step [300 / 500], Loss : 0.402160\n",
            "Epoch [12 / 80], Step [400 / 500], Loss : 0.616121\n",
            "Epoch [12 / 80], Step [500 / 500], Loss : 0.590731\n",
            "\n",
            "Test Set : Average Loss : 0.008617, Accuracy : 7177 / 10000 (72%)\n",
            "\n",
            "Epoch [13 / 80], Step [100 / 500], Loss : 1.630684\n",
            "Epoch [13 / 80], Step [200 / 500], Loss : 0.649666\n",
            "Epoch [13 / 80], Step [300 / 500], Loss : 0.715099\n",
            "Epoch [13 / 80], Step [400 / 500], Loss : 0.639959\n",
            "Epoch [13 / 80], Step [500 / 500], Loss : 0.572828\n",
            "\n",
            "Test Set : Average Loss : 0.006733, Accuracy : 7684 / 10000 (77%)\n",
            "\n",
            "Epoch [14 / 80], Step [100 / 500], Loss : 0.538610\n",
            "Epoch [14 / 80], Step [200 / 500], Loss : 0.764722\n",
            "Epoch [14 / 80], Step [300 / 500], Loss : 0.558478\n",
            "Epoch [14 / 80], Step [400 / 500], Loss : 0.517904\n",
            "Epoch [14 / 80], Step [500 / 500], Loss : 0.545108\n",
            "\n",
            "Test Set : Average Loss : 0.006508, Accuracy : 7799 / 10000 (78%)\n",
            "\n",
            "Epoch [15 / 80], Step [100 / 500], Loss : 0.578641\n",
            "Epoch [15 / 80], Step [200 / 500], Loss : 0.652571\n",
            "Epoch [15 / 80], Step [300 / 500], Loss : 0.408509\n",
            "Epoch [15 / 80], Step [400 / 500], Loss : 0.627529\n",
            "Epoch [15 / 80], Step [500 / 500], Loss : 0.548200\n",
            "\n",
            "Test Set : Average Loss : 0.006985, Accuracy : 7720 / 10000 (77%)\n",
            "\n",
            "Epoch [16 / 80], Step [100 / 500], Loss : 0.450804\n",
            "Epoch [16 / 80], Step [200 / 500], Loss : 0.604328\n",
            "Epoch [16 / 80], Step [300 / 500], Loss : 0.562308\n",
            "Epoch [16 / 80], Step [400 / 500], Loss : 0.625433\n",
            "Epoch [16 / 80], Step [500 / 500], Loss : 0.439811\n",
            "\n",
            "Test Set : Average Loss : 0.006234, Accuracy : 7876 / 10000 (79%)\n",
            "\n",
            "Epoch [17 / 80], Step [100 / 500], Loss : 0.475284\n",
            "Epoch [17 / 80], Step [200 / 500], Loss : 0.464874\n",
            "Epoch [17 / 80], Step [300 / 500], Loss : 0.481472\n",
            "Epoch [17 / 80], Step [400 / 500], Loss : 0.409090\n",
            "Epoch [17 / 80], Step [500 / 500], Loss : 0.551545\n",
            "\n",
            "Test Set : Average Loss : 0.005927, Accuracy : 7980 / 10000 (80%)\n",
            "\n",
            "Epoch [18 / 80], Step [100 / 500], Loss : 0.521302\n",
            "Epoch [18 / 80], Step [200 / 500], Loss : 0.606022\n",
            "Epoch [18 / 80], Step [300 / 500], Loss : 0.551428\n",
            "Epoch [18 / 80], Step [400 / 500], Loss : 0.660823\n",
            "Epoch [18 / 80], Step [500 / 500], Loss : 0.378585\n",
            "\n",
            "Test Set : Average Loss : 0.005928, Accuracy : 8007 / 10000 (80%)\n",
            "\n",
            "Epoch [19 / 80], Step [100 / 500], Loss : 0.524455\n",
            "Epoch [19 / 80], Step [200 / 500], Loss : 0.639497\n",
            "Epoch [19 / 80], Step [300 / 500], Loss : 0.412581\n",
            "Epoch [19 / 80], Step [400 / 500], Loss : 0.514879\n",
            "Epoch [19 / 80], Step [500 / 500], Loss : 0.522404\n",
            "\n",
            "Test Set : Average Loss : 0.005754, Accuracy : 8074 / 10000 (81%)\n",
            "\n",
            "Epoch [20 / 80], Step [100 / 500], Loss : 0.519104\n",
            "Epoch [20 / 80], Step [200 / 500], Loss : 0.537283\n",
            "Epoch [20 / 80], Step [300 / 500], Loss : 0.433657\n",
            "Epoch [20 / 80], Step [400 / 500], Loss : 0.511777\n",
            "Epoch [20 / 80], Step [500 / 500], Loss : 0.449575\n",
            "\n",
            "Test Set : Average Loss : 0.006717, Accuracy : 7766 / 10000 (78%)\n",
            "\n",
            "Epoch [21 / 80], Step [100 / 500], Loss : 0.467223\n",
            "Epoch [21 / 80], Step [200 / 500], Loss : 0.504511\n",
            "Epoch [21 / 80], Step [300 / 500], Loss : 0.269120\n",
            "Epoch [21 / 80], Step [400 / 500], Loss : 0.578924\n",
            "Epoch [21 / 80], Step [500 / 500], Loss : 0.431640\n",
            "\n",
            "Test Set : Average Loss : 0.004914, Accuracy : 8326 / 10000 (83%)\n",
            "\n",
            "Epoch [22 / 80], Step [100 / 500], Loss : 0.378341\n",
            "Epoch [22 / 80], Step [200 / 500], Loss : 0.394448\n",
            "Epoch [22 / 80], Step [300 / 500], Loss : 0.369605\n",
            "Epoch [22 / 80], Step [400 / 500], Loss : 0.269141\n",
            "Epoch [22 / 80], Step [500 / 500], Loss : 0.395975\n",
            "\n",
            "Test Set : Average Loss : 0.005083, Accuracy : 8300 / 10000 (83%)\n",
            "\n",
            "Epoch [23 / 80], Step [100 / 500], Loss : 0.323849\n",
            "Epoch [23 / 80], Step [200 / 500], Loss : 0.388935\n",
            "Epoch [23 / 80], Step [300 / 500], Loss : 0.295833\n",
            "Epoch [23 / 80], Step [400 / 500], Loss : 0.439576\n",
            "Epoch [23 / 80], Step [500 / 500], Loss : 0.269514\n",
            "\n",
            "Test Set : Average Loss : 0.004800, Accuracy : 8429 / 10000 (84%)\n",
            "\n",
            "Epoch [24 / 80], Step [100 / 500], Loss : 0.287222\n",
            "Epoch [24 / 80], Step [200 / 500], Loss : 0.431482\n",
            "Epoch [24 / 80], Step [300 / 500], Loss : 0.309118\n",
            "Epoch [24 / 80], Step [400 / 500], Loss : 0.326454\n",
            "Epoch [24 / 80], Step [500 / 500], Loss : 0.350010\n",
            "\n",
            "Test Set : Average Loss : 0.005066, Accuracy : 8370 / 10000 (84%)\n",
            "\n",
            "Epoch [25 / 80], Step [100 / 500], Loss : 0.441736\n",
            "Epoch [25 / 80], Step [200 / 500], Loss : 0.403577\n",
            "Epoch [25 / 80], Step [300 / 500], Loss : 0.198639\n",
            "Epoch [25 / 80], Step [400 / 500], Loss : 0.361361\n",
            "Epoch [25 / 80], Step [500 / 500], Loss : 0.341849\n",
            "\n",
            "Test Set : Average Loss : 0.005047, Accuracy : 8370 / 10000 (84%)\n",
            "\n",
            "Epoch [26 / 80], Step [100 / 500], Loss : 0.250916\n",
            "Epoch [26 / 80], Step [200 / 500], Loss : 0.235146\n",
            "Epoch [26 / 80], Step [300 / 500], Loss : 0.278597\n",
            "Epoch [26 / 80], Step [400 / 500], Loss : 0.420884\n",
            "Epoch [26 / 80], Step [500 / 500], Loss : 0.273064\n",
            "\n",
            "Test Set : Average Loss : 0.004871, Accuracy : 8450 / 10000 (84%)\n",
            "\n",
            "Epoch [27 / 80], Step [100 / 500], Loss : 0.322225\n",
            "Epoch [27 / 80], Step [200 / 500], Loss : 0.289566\n",
            "Epoch [27 / 80], Step [300 / 500], Loss : 0.310003\n",
            "Epoch [27 / 80], Step [400 / 500], Loss : 0.286804\n",
            "Epoch [27 / 80], Step [500 / 500], Loss : 0.282886\n",
            "\n",
            "Test Set : Average Loss : 0.005010, Accuracy : 8383 / 10000 (84%)\n",
            "\n",
            "Epoch [28 / 80], Step [100 / 500], Loss : 0.201895\n",
            "Epoch [28 / 80], Step [200 / 500], Loss : 0.230418\n",
            "Epoch [28 / 80], Step [300 / 500], Loss : 0.243025\n",
            "Epoch [28 / 80], Step [400 / 500], Loss : 0.353498\n",
            "Epoch [28 / 80], Step [500 / 500], Loss : 0.468122\n",
            "\n",
            "Test Set : Average Loss : 0.005552, Accuracy : 8258 / 10000 (83%)\n",
            "\n",
            "Epoch [29 / 80], Step [100 / 500], Loss : 0.236004\n",
            "Epoch [29 / 80], Step [200 / 500], Loss : 0.688932\n",
            "Epoch [29 / 80], Step [300 / 500], Loss : 0.293220\n",
            "Epoch [29 / 80], Step [400 / 500], Loss : 0.318234\n",
            "Epoch [29 / 80], Step [500 / 500], Loss : 0.359344\n",
            "\n",
            "Test Set : Average Loss : 0.004788, Accuracy : 8499 / 10000 (85%)\n",
            "\n",
            "Epoch [30 / 80], Step [100 / 500], Loss : 0.260865\n",
            "Epoch [30 / 80], Step [200 / 500], Loss : 0.284487\n",
            "Epoch [30 / 80], Step [300 / 500], Loss : 0.208858\n",
            "Epoch [30 / 80], Step [400 / 500], Loss : 0.256159\n",
            "Epoch [30 / 80], Step [500 / 500], Loss : 0.192226\n",
            "\n",
            "Test Set : Average Loss : 0.004870, Accuracy : 8496 / 10000 (85%)\n",
            "\n",
            "Epoch [31 / 80], Step [100 / 500], Loss : 0.204683\n",
            "Epoch [31 / 80], Step [200 / 500], Loss : 0.395102\n",
            "Epoch [31 / 80], Step [300 / 500], Loss : 0.239414\n",
            "Epoch [31 / 80], Step [400 / 500], Loss : 0.386305\n",
            "Epoch [31 / 80], Step [500 / 500], Loss : 0.234173\n",
            "\n",
            "Test Set : Average Loss : 0.004726, Accuracy : 8510 / 10000 (85%)\n",
            "\n",
            "Epoch [32 / 80], Step [100 / 500], Loss : 0.349797\n",
            "Epoch [32 / 80], Step [200 / 500], Loss : 0.320063\n",
            "Epoch [32 / 80], Step [300 / 500], Loss : 0.345007\n",
            "Epoch [32 / 80], Step [400 / 500], Loss : 0.371221\n",
            "Epoch [32 / 80], Step [500 / 500], Loss : 0.269430\n",
            "\n",
            "Test Set : Average Loss : 0.005066, Accuracy : 8393 / 10000 (84%)\n",
            "\n",
            "Epoch [33 / 80], Step [100 / 500], Loss : 0.291284\n",
            "Epoch [33 / 80], Step [200 / 500], Loss : 0.231276\n",
            "Epoch [33 / 80], Step [300 / 500], Loss : 0.248744\n",
            "Epoch [33 / 80], Step [400 / 500], Loss : 0.170523\n",
            "Epoch [33 / 80], Step [500 / 500], Loss : 0.304909\n",
            "\n",
            "Test Set : Average Loss : 0.004810, Accuracy : 8479 / 10000 (85%)\n",
            "\n",
            "Epoch [34 / 80], Step [100 / 500], Loss : 0.231537\n",
            "Epoch [34 / 80], Step [200 / 500], Loss : 0.180200\n",
            "Epoch [34 / 80], Step [300 / 500], Loss : 0.247569\n",
            "Epoch [34 / 80], Step [400 / 500], Loss : 0.251341\n",
            "Epoch [34 / 80], Step [500 / 500], Loss : 0.246999\n",
            "\n",
            "Test Set : Average Loss : 0.004943, Accuracy : 8490 / 10000 (85%)\n",
            "\n",
            "Epoch [35 / 80], Step [100 / 500], Loss : 0.312708\n",
            "Epoch [35 / 80], Step [200 / 500], Loss : 0.274898\n",
            "Epoch [35 / 80], Step [300 / 500], Loss : 0.280213\n",
            "Epoch [35 / 80], Step [400 / 500], Loss : 0.366036\n",
            "Epoch [35 / 80], Step [500 / 500], Loss : 0.225850\n",
            "\n",
            "Test Set : Average Loss : 0.005040, Accuracy : 8459 / 10000 (85%)\n",
            "\n",
            "Epoch [36 / 80], Step [100 / 500], Loss : 0.284306\n",
            "Epoch [36 / 80], Step [200 / 500], Loss : 0.311588\n",
            "Epoch [36 / 80], Step [300 / 500], Loss : 0.145215\n",
            "Epoch [36 / 80], Step [400 / 500], Loss : 0.249561\n",
            "Epoch [36 / 80], Step [500 / 500], Loss : 0.290019\n",
            "\n",
            "Test Set : Average Loss : 0.005084, Accuracy : 8488 / 10000 (85%)\n",
            "\n",
            "Epoch [37 / 80], Step [100 / 500], Loss : 0.455527\n",
            "Epoch [37 / 80], Step [200 / 500], Loss : 0.262238\n",
            "Epoch [37 / 80], Step [300 / 500], Loss : 0.209153\n",
            "Epoch [37 / 80], Step [400 / 500], Loss : 0.241241\n",
            "Epoch [37 / 80], Step [500 / 500], Loss : 0.153539\n",
            "\n",
            "Test Set : Average Loss : 0.004941, Accuracy : 8478 / 10000 (85%)\n",
            "\n",
            "Epoch [38 / 80], Step [100 / 500], Loss : 0.260612\n",
            "Epoch [38 / 80], Step [200 / 500], Loss : 0.192143\n",
            "Epoch [38 / 80], Step [300 / 500], Loss : 0.270939\n",
            "Epoch [38 / 80], Step [400 / 500], Loss : 0.174134\n",
            "Epoch [38 / 80], Step [500 / 500], Loss : 0.182505\n",
            "\n",
            "Test Set : Average Loss : 0.004764, Accuracy : 8542 / 10000 (85%)\n",
            "\n",
            "Epoch [39 / 80], Step [100 / 500], Loss : 0.147652\n",
            "Epoch [39 / 80], Step [200 / 500], Loss : 0.250336\n",
            "Epoch [39 / 80], Step [300 / 500], Loss : 0.303562\n",
            "Epoch [39 / 80], Step [400 / 500], Loss : 0.171199\n",
            "Epoch [39 / 80], Step [500 / 500], Loss : 0.240450\n",
            "\n",
            "Test Set : Average Loss : 0.005297, Accuracy : 8397 / 10000 (84%)\n",
            "\n",
            "Epoch [40 / 80], Step [100 / 500], Loss : 0.238213\n",
            "Epoch [40 / 80], Step [200 / 500], Loss : 0.170622\n",
            "Epoch [40 / 80], Step [300 / 500], Loss : 0.198168\n",
            "Epoch [40 / 80], Step [400 / 500], Loss : 0.314490\n",
            "Epoch [40 / 80], Step [500 / 500], Loss : 0.203158\n",
            "\n",
            "Test Set : Average Loss : 0.005081, Accuracy : 8481 / 10000 (85%)\n",
            "\n",
            "Epoch [41 / 80], Step [100 / 500], Loss : 0.287724\n",
            "Epoch [41 / 80], Step [200 / 500], Loss : 0.239850\n",
            "Epoch [41 / 80], Step [300 / 500], Loss : 0.119550\n",
            "Epoch [41 / 80], Step [400 / 500], Loss : 0.223824\n",
            "Epoch [41 / 80], Step [500 / 500], Loss : 0.264008\n",
            "\n",
            "Test Set : Average Loss : 0.005227, Accuracy : 8457 / 10000 (85%)\n",
            "\n",
            "Epoch [42 / 80], Step [100 / 500], Loss : 0.230891\n",
            "Epoch [42 / 80], Step [200 / 500], Loss : 0.297745\n",
            "Epoch [42 / 80], Step [300 / 500], Loss : 0.239276\n",
            "Epoch [42 / 80], Step [400 / 500], Loss : 0.170372\n",
            "Epoch [42 / 80], Step [500 / 500], Loss : 0.286242\n",
            "\n",
            "Test Set : Average Loss : 0.005510, Accuracy : 8411 / 10000 (84%)\n",
            "\n",
            "Epoch [43 / 80], Step [100 / 500], Loss : 0.199479\n",
            "Epoch [43 / 80], Step [200 / 500], Loss : 0.202112\n",
            "Epoch [43 / 80], Step [300 / 500], Loss : 0.344815\n",
            "Epoch [43 / 80], Step [400 / 500], Loss : 0.178781\n",
            "Epoch [43 / 80], Step [500 / 500], Loss : 0.284053\n",
            "\n",
            "Test Set : Average Loss : 0.004990, Accuracy : 8536 / 10000 (85%)\n",
            "\n",
            "Epoch [44 / 80], Step [100 / 500], Loss : 0.190787\n",
            "Epoch [44 / 80], Step [200 / 500], Loss : 0.267935\n",
            "Epoch [44 / 80], Step [300 / 500], Loss : 0.111919\n",
            "Epoch [44 / 80], Step [400 / 500], Loss : 0.126313\n",
            "Epoch [44 / 80], Step [500 / 500], Loss : 0.259373\n",
            "\n",
            "Test Set : Average Loss : 0.005003, Accuracy : 8554 / 10000 (86%)\n",
            "\n",
            "Epoch [45 / 80], Step [100 / 500], Loss : 0.143531\n",
            "Epoch [45 / 80], Step [200 / 500], Loss : 0.150197\n",
            "Epoch [45 / 80], Step [300 / 500], Loss : 0.153026\n",
            "Epoch [45 / 80], Step [400 / 500], Loss : 0.139464\n",
            "Epoch [45 / 80], Step [500 / 500], Loss : 0.203937\n",
            "\n",
            "Test Set : Average Loss : 0.005097, Accuracy : 8489 / 10000 (85%)\n",
            "\n",
            "Epoch [46 / 80], Step [100 / 500], Loss : 0.190154\n",
            "Epoch [46 / 80], Step [200 / 500], Loss : 0.213523\n",
            "Epoch [46 / 80], Step [300 / 500], Loss : 0.222998\n",
            "Epoch [46 / 80], Step [400 / 500], Loss : 0.164319\n",
            "Epoch [46 / 80], Step [500 / 500], Loss : 0.277711\n",
            "\n",
            "Test Set : Average Loss : 0.005102, Accuracy : 8545 / 10000 (85%)\n",
            "\n",
            "Epoch [47 / 80], Step [100 / 500], Loss : 0.197352\n",
            "Epoch [47 / 80], Step [200 / 500], Loss : 0.223352\n",
            "Epoch [47 / 80], Step [300 / 500], Loss : 0.345939\n",
            "Epoch [47 / 80], Step [400 / 500], Loss : 0.209941\n",
            "Epoch [47 / 80], Step [500 / 500], Loss : 0.180734\n",
            "\n",
            "Test Set : Average Loss : 0.004897, Accuracy : 8533 / 10000 (85%)\n",
            "\n",
            "Epoch [48 / 80], Step [100 / 500], Loss : 0.156806\n",
            "Epoch [48 / 80], Step [200 / 500], Loss : 0.211296\n",
            "Epoch [48 / 80], Step [300 / 500], Loss : 0.129215\n",
            "Epoch [48 / 80], Step [400 / 500], Loss : 0.180709\n",
            "Epoch [48 / 80], Step [500 / 500], Loss : 0.307390\n",
            "\n",
            "Test Set : Average Loss : 0.005319, Accuracy : 8515 / 10000 (85%)\n",
            "\n",
            "Epoch [49 / 80], Step [100 / 500], Loss : 0.187700\n",
            "Epoch [49 / 80], Step [200 / 500], Loss : 0.213459\n",
            "Epoch [49 / 80], Step [300 / 500], Loss : 0.163860\n",
            "Epoch [49 / 80], Step [400 / 500], Loss : 0.185925\n",
            "Epoch [49 / 80], Step [500 / 500], Loss : 0.257949\n",
            "\n",
            "Test Set : Average Loss : 0.005239, Accuracy : 8505 / 10000 (85%)\n",
            "\n",
            "Epoch [50 / 80], Step [100 / 500], Loss : 0.113139\n",
            "Epoch [50 / 80], Step [200 / 500], Loss : 0.127649\n",
            "Epoch [50 / 80], Step [300 / 500], Loss : 0.204947\n",
            "Epoch [50 / 80], Step [400 / 500], Loss : 0.306304\n",
            "Epoch [50 / 80], Step [500 / 500], Loss : 0.223129\n",
            "\n",
            "Test Set : Average Loss : 0.005407, Accuracy : 8438 / 10000 (84%)\n",
            "\n",
            "Epoch [51 / 80], Step [100 / 500], Loss : 0.181477\n",
            "Epoch [51 / 80], Step [200 / 500], Loss : 0.182924\n",
            "Epoch [51 / 80], Step [300 / 500], Loss : 0.173936\n",
            "Epoch [51 / 80], Step [400 / 500], Loss : 0.221161\n",
            "Epoch [51 / 80], Step [500 / 500], Loss : 0.125559\n",
            "\n",
            "Test Set : Average Loss : 0.005298, Accuracy : 8508 / 10000 (85%)\n",
            "\n",
            "Epoch [52 / 80], Step [100 / 500], Loss : 0.229690\n",
            "Epoch [52 / 80], Step [200 / 500], Loss : 0.236325\n",
            "Epoch [52 / 80], Step [300 / 500], Loss : 0.117496\n",
            "Epoch [52 / 80], Step [400 / 500], Loss : 0.289588\n",
            "Epoch [52 / 80], Step [500 / 500], Loss : 0.193814\n",
            "\n",
            "Test Set : Average Loss : 0.005380, Accuracy : 8503 / 10000 (85%)\n",
            "\n",
            "Epoch [53 / 80], Step [100 / 500], Loss : 0.222897\n",
            "Epoch [53 / 80], Step [200 / 500], Loss : 0.183105\n",
            "Epoch [53 / 80], Step [300 / 500], Loss : 0.111928\n",
            "Epoch [53 / 80], Step [400 / 500], Loss : 0.195801\n",
            "Epoch [53 / 80], Step [500 / 500], Loss : 0.132308\n",
            "\n",
            "Test Set : Average Loss : 0.005328, Accuracy : 8491 / 10000 (85%)\n",
            "\n",
            "Epoch [54 / 80], Step [100 / 500], Loss : 0.259645\n",
            "Epoch [54 / 80], Step [200 / 500], Loss : 0.242522\n",
            "Epoch [54 / 80], Step [300 / 500], Loss : 0.138670\n",
            "Epoch [54 / 80], Step [400 / 500], Loss : 0.222142\n",
            "Epoch [54 / 80], Step [500 / 500], Loss : 0.209359\n",
            "\n",
            "Test Set : Average Loss : 0.005218, Accuracy : 8533 / 10000 (85%)\n",
            "\n",
            "Epoch [55 / 80], Step [100 / 500], Loss : 0.124849\n",
            "Epoch [55 / 80], Step [200 / 500], Loss : 0.276414\n",
            "Epoch [55 / 80], Step [300 / 500], Loss : 0.052164\n",
            "Epoch [55 / 80], Step [400 / 500], Loss : 0.198179\n",
            "Epoch [55 / 80], Step [500 / 500], Loss : 0.148312\n",
            "\n",
            "Test Set : Average Loss : 0.005470, Accuracy : 8469 / 10000 (85%)\n",
            "\n",
            "Epoch [56 / 80], Step [100 / 500], Loss : 0.147757\n",
            "Epoch [56 / 80], Step [200 / 500], Loss : 0.095922\n",
            "Epoch [56 / 80], Step [300 / 500], Loss : 0.267613\n",
            "Epoch [56 / 80], Step [400 / 500], Loss : 0.235929\n",
            "Epoch [56 / 80], Step [500 / 500], Loss : 0.154357\n",
            "\n",
            "Test Set : Average Loss : 0.005766, Accuracy : 8415 / 10000 (84%)\n",
            "\n",
            "Epoch [57 / 80], Step [100 / 500], Loss : 0.116540\n",
            "Epoch [57 / 80], Step [200 / 500], Loss : 0.125423\n",
            "Epoch [57 / 80], Step [300 / 500], Loss : 0.146273\n",
            "Epoch [57 / 80], Step [400 / 500], Loss : 0.195905\n",
            "Epoch [57 / 80], Step [500 / 500], Loss : 0.253412\n",
            "\n",
            "Test Set : Average Loss : 0.005746, Accuracy : 8433 / 10000 (84%)\n",
            "\n",
            "Epoch [58 / 80], Step [100 / 500], Loss : 0.171069\n",
            "Epoch [58 / 80], Step [200 / 500], Loss : 0.086704\n",
            "Epoch [58 / 80], Step [300 / 500], Loss : 0.160180\n",
            "Epoch [58 / 80], Step [400 / 500], Loss : 0.126432\n",
            "Epoch [58 / 80], Step [500 / 500], Loss : 0.389635\n",
            "\n",
            "Test Set : Average Loss : 0.005674, Accuracy : 8405 / 10000 (84%)\n",
            "\n",
            "Epoch [59 / 80], Step [100 / 500], Loss : 0.252904\n",
            "Epoch [59 / 80], Step [200 / 500], Loss : 0.160604\n",
            "Epoch [59 / 80], Step [300 / 500], Loss : 0.177753\n",
            "Epoch [59 / 80], Step [400 / 500], Loss : 0.136157\n",
            "Epoch [59 / 80], Step [500 / 500], Loss : 0.089191\n",
            "\n",
            "Test Set : Average Loss : 0.005849, Accuracy : 8453 / 10000 (85%)\n",
            "\n",
            "Epoch [60 / 80], Step [100 / 500], Loss : 0.146880\n",
            "Epoch [60 / 80], Step [200 / 500], Loss : 0.152182\n",
            "Epoch [60 / 80], Step [300 / 500], Loss : 0.179295\n",
            "Epoch [60 / 80], Step [400 / 500], Loss : 0.119065\n",
            "Epoch [60 / 80], Step [500 / 500], Loss : 0.118265\n",
            "\n",
            "Test Set : Average Loss : 0.005595, Accuracy : 8516 / 10000 (85%)\n",
            "\n",
            "Epoch [61 / 80], Step [100 / 500], Loss : 0.099941\n",
            "Epoch [61 / 80], Step [200 / 500], Loss : 0.152273\n",
            "Epoch [61 / 80], Step [300 / 500], Loss : 0.193142\n",
            "Epoch [61 / 80], Step [400 / 500], Loss : 0.152644\n",
            "Epoch [61 / 80], Step [500 / 500], Loss : 0.143689\n",
            "\n",
            "Test Set : Average Loss : 0.005753, Accuracy : 8489 / 10000 (85%)\n",
            "\n",
            "Epoch [62 / 80], Step [100 / 500], Loss : 0.129003\n",
            "Epoch [62 / 80], Step [200 / 500], Loss : 0.154158\n",
            "Epoch [62 / 80], Step [300 / 500], Loss : 0.121599\n",
            "Epoch [62 / 80], Step [400 / 500], Loss : 0.132461\n",
            "Epoch [62 / 80], Step [500 / 500], Loss : 0.113278\n",
            "\n",
            "Test Set : Average Loss : 0.006262, Accuracy : 8334 / 10000 (83%)\n",
            "\n",
            "Epoch [63 / 80], Step [100 / 500], Loss : 0.227848\n",
            "Epoch [63 / 80], Step [200 / 500], Loss : 0.149872\n",
            "Epoch [63 / 80], Step [300 / 500], Loss : 0.156066\n",
            "Epoch [63 / 80], Step [400 / 500], Loss : 0.234535\n",
            "Epoch [63 / 80], Step [500 / 500], Loss : 0.158537\n",
            "\n",
            "Test Set : Average Loss : 0.006157, Accuracy : 8419 / 10000 (84%)\n",
            "\n",
            "Epoch [64 / 80], Step [100 / 500], Loss : 0.086278\n",
            "Epoch [64 / 80], Step [200 / 500], Loss : 0.244924\n",
            "Epoch [64 / 80], Step [300 / 500], Loss : 0.167275\n",
            "Epoch [64 / 80], Step [400 / 500], Loss : 0.234771\n",
            "Epoch [64 / 80], Step [500 / 500], Loss : 0.139153\n",
            "\n",
            "Test Set : Average Loss : 0.005740, Accuracy : 8502 / 10000 (85%)\n",
            "\n",
            "Epoch [65 / 80], Step [100 / 500], Loss : 0.306750\n",
            "Epoch [65 / 80], Step [200 / 500], Loss : 0.145463\n",
            "Epoch [65 / 80], Step [300 / 500], Loss : 0.307259\n",
            "Epoch [65 / 80], Step [400 / 500], Loss : 0.127471\n",
            "Epoch [65 / 80], Step [500 / 500], Loss : 0.151315\n",
            "\n",
            "Test Set : Average Loss : 0.006282, Accuracy : 8440 / 10000 (84%)\n",
            "\n",
            "Epoch [66 / 80], Step [100 / 500], Loss : 0.167916\n",
            "Epoch [66 / 80], Step [200 / 500], Loss : 0.156699\n",
            "Epoch [66 / 80], Step [300 / 500], Loss : 0.189824\n",
            "Epoch [66 / 80], Step [400 / 500], Loss : 0.119775\n",
            "Epoch [66 / 80], Step [500 / 500], Loss : 0.195589\n",
            "\n",
            "Test Set : Average Loss : 0.005794, Accuracy : 8481 / 10000 (85%)\n",
            "\n",
            "Epoch [67 / 80], Step [100 / 500], Loss : 0.125127\n",
            "Epoch [67 / 80], Step [200 / 500], Loss : 0.203140\n",
            "Epoch [67 / 80], Step [300 / 500], Loss : 0.126908\n",
            "Epoch [67 / 80], Step [400 / 500], Loss : 0.055207\n",
            "Epoch [67 / 80], Step [500 / 500], Loss : 0.101551\n",
            "\n",
            "Test Set : Average Loss : 0.006281, Accuracy : 8354 / 10000 (84%)\n",
            "\n",
            "Epoch [68 / 80], Step [100 / 500], Loss : 0.124857\n",
            "Epoch [68 / 80], Step [200 / 500], Loss : 0.082952\n",
            "Epoch [68 / 80], Step [300 / 500], Loss : 0.135672\n",
            "Epoch [68 / 80], Step [400 / 500], Loss : 0.094271\n",
            "Epoch [68 / 80], Step [500 / 500], Loss : 0.190187\n",
            "\n",
            "Test Set : Average Loss : 0.005670, Accuracy : 8552 / 10000 (86%)\n",
            "\n",
            "Epoch [69 / 80], Step [100 / 500], Loss : 0.238829\n",
            "Epoch [69 / 80], Step [200 / 500], Loss : 0.095543\n",
            "Epoch [69 / 80], Step [300 / 500], Loss : 0.181310\n",
            "Epoch [69 / 80], Step [400 / 500], Loss : 0.123559\n",
            "Epoch [69 / 80], Step [500 / 500], Loss : 0.243918\n",
            "\n",
            "Test Set : Average Loss : 0.006224, Accuracy : 8486 / 10000 (85%)\n",
            "\n",
            "Epoch [70 / 80], Step [100 / 500], Loss : 0.241360\n",
            "Epoch [70 / 80], Step [200 / 500], Loss : 0.145555\n",
            "Epoch [70 / 80], Step [300 / 500], Loss : 0.163806\n",
            "Epoch [70 / 80], Step [400 / 500], Loss : 0.126359\n",
            "Epoch [70 / 80], Step [500 / 500], Loss : 0.115609\n",
            "\n",
            "Test Set : Average Loss : 0.006065, Accuracy : 8468 / 10000 (85%)\n",
            "\n",
            "Epoch [71 / 80], Step [100 / 500], Loss : 0.191299\n",
            "Epoch [71 / 80], Step [200 / 500], Loss : 0.069529\n",
            "Epoch [71 / 80], Step [300 / 500], Loss : 0.062430\n",
            "Epoch [71 / 80], Step [400 / 500], Loss : 0.137455\n",
            "Epoch [71 / 80], Step [500 / 500], Loss : 0.168346\n",
            "\n",
            "Test Set : Average Loss : 0.006085, Accuracy : 8503 / 10000 (85%)\n",
            "\n",
            "Epoch [72 / 80], Step [100 / 500], Loss : 0.269145\n",
            "Epoch [72 / 80], Step [200 / 500], Loss : 0.076209\n",
            "Epoch [72 / 80], Step [300 / 500], Loss : 0.148331\n",
            "Epoch [72 / 80], Step [400 / 500], Loss : 0.103774\n",
            "Epoch [72 / 80], Step [500 / 500], Loss : 0.178181\n",
            "\n",
            "Test Set : Average Loss : 0.005992, Accuracy : 8543 / 10000 (85%)\n",
            "\n",
            "Epoch [73 / 80], Step [100 / 500], Loss : 0.083095\n",
            "Epoch [73 / 80], Step [200 / 500], Loss : 0.252569\n",
            "Epoch [73 / 80], Step [300 / 500], Loss : 0.131442\n",
            "Epoch [73 / 80], Step [400 / 500], Loss : 0.063509\n",
            "Epoch [73 / 80], Step [500 / 500], Loss : 0.168507\n",
            "\n",
            "Test Set : Average Loss : 0.007984, Accuracy : 8102 / 10000 (81%)\n",
            "\n",
            "Epoch [74 / 80], Step [100 / 500], Loss : 0.061277\n",
            "Epoch [74 / 80], Step [200 / 500], Loss : 0.059528\n",
            "Epoch [74 / 80], Step [300 / 500], Loss : 0.085744\n",
            "Epoch [74 / 80], Step [400 / 500], Loss : 0.043911\n",
            "Epoch [74 / 80], Step [500 / 500], Loss : 0.188917\n",
            "\n",
            "Test Set : Average Loss : 0.005849, Accuracy : 8539 / 10000 (85%)\n",
            "\n",
            "Epoch [75 / 80], Step [100 / 500], Loss : 0.107348\n",
            "Epoch [75 / 80], Step [200 / 500], Loss : 0.090028\n",
            "Epoch [75 / 80], Step [300 / 500], Loss : 0.158034\n",
            "Epoch [75 / 80], Step [400 / 500], Loss : 0.126738\n",
            "Epoch [75 / 80], Step [500 / 500], Loss : 0.103763\n",
            "\n",
            "Test Set : Average Loss : 0.006210, Accuracy : 8470 / 10000 (85%)\n",
            "\n",
            "Epoch [76 / 80], Step [100 / 500], Loss : 0.069556\n",
            "Epoch [76 / 80], Step [200 / 500], Loss : 0.092734\n",
            "Epoch [76 / 80], Step [300 / 500], Loss : 0.151759\n",
            "Epoch [76 / 80], Step [400 / 500], Loss : 0.245322\n",
            "Epoch [76 / 80], Step [500 / 500], Loss : 0.204080\n",
            "\n",
            "Test Set : Average Loss : 0.006115, Accuracy : 8478 / 10000 (85%)\n",
            "\n",
            "Epoch [77 / 80], Step [100 / 500], Loss : 0.097923\n",
            "Epoch [77 / 80], Step [200 / 500], Loss : 0.041286\n",
            "Epoch [77 / 80], Step [300 / 500], Loss : 0.106870\n",
            "Epoch [77 / 80], Step [400 / 500], Loss : 0.069221\n",
            "Epoch [77 / 80], Step [500 / 500], Loss : 0.145644\n",
            "\n",
            "Test Set : Average Loss : 0.006355, Accuracy : 8504 / 10000 (85%)\n",
            "\n",
            "Epoch [78 / 80], Step [100 / 500], Loss : 0.055507\n",
            "Epoch [78 / 80], Step [200 / 500], Loss : 0.145509\n",
            "Epoch [78 / 80], Step [300 / 500], Loss : 0.183441\n",
            "Epoch [78 / 80], Step [400 / 500], Loss : 0.177926\n",
            "Epoch [78 / 80], Step [500 / 500], Loss : 0.101006\n",
            "\n",
            "Test Set : Average Loss : 0.006097, Accuracy : 8474 / 10000 (85%)\n",
            "\n",
            "Epoch [79 / 80], Step [100 / 500], Loss : 0.075088\n",
            "Epoch [79 / 80], Step [200 / 500], Loss : 0.082784\n",
            "Epoch [79 / 80], Step [300 / 500], Loss : 0.097213\n",
            "Epoch [79 / 80], Step [400 / 500], Loss : 0.131935\n",
            "Epoch [79 / 80], Step [500 / 500], Loss : 0.185527\n",
            "\n",
            "Test Set : Average Loss : 0.006079, Accuracy : 8528 / 10000 (85%)\n",
            "\n",
            "Epoch [80 / 80], Step [100 / 500], Loss : 0.153206\n",
            "Epoch [80 / 80], Step [200 / 500], Loss : 0.070625\n",
            "Epoch [80 / 80], Step [300 / 500], Loss : 0.096713\n",
            "Epoch [80 / 80], Step [400 / 500], Loss : 0.073030\n",
            "Epoch [80 / 80], Step [500 / 500], Loss : 0.068096\n",
            "\n",
            "Test Set : Average Loss : 0.006606, Accuracy : 8425 / 10000 (84%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#4\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes = 10, init_weights = True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels = 64\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.Conv2d(3, 64, kernel_size = 7, stride = 2, padding = 3, bias = False),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
        "    )\n",
        "\n",
        "    self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
        "    self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
        "    self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
        "    self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "    self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "  def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "     strides = [stride] + [1] * (num_blocks - 1)\n",
        "     layers = []\n",
        "     for stride in strides:\n",
        "       layers.append(block(self.in_channels, out_channels, stride))\n",
        "       self.in_channels = out_channels\n",
        "\n",
        "     return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x = self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.xavier_normal_(m.weight, mode = 'fan_out', nonlinearity = 'relu')\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "          nn.init.constant_(m.weight, 1)\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "          nn.init.normal_(m.weight, 0, 0.01)\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "\n",
        "model = ResNet(BasicBlock, [3, 4, 6, 3]).cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "for epoch in range (0, num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPm9Utj-SysI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}